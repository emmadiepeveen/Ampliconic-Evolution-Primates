{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed60146-ecb1-4db6-994a-9880839fa06f",
   "metadata": {},
   "source": [
    "# PAML site test submit sbatch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a7196-a128-4760-84d7-2ddcc1e59b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import random, shutil, subprocess, re\n",
    "from io import StringIO\n",
    "from typing import List, Tuple\n",
    "from Bio import AlignIO, SeqIO, Phylo\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9aea8-d7d7-4da3-9109-3c417e3295b0",
   "metadata": {},
   "source": [
    "## Workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d33e97-9dfe-4a91-b560-82931e45e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the output files will look: \n",
    "# {data_dir}/PAML/x_chromosome/{family}/{cluster}/\n",
    "#   ├─ {cluster}_nogaps.fa         (once per cluster)\n",
    "#   ├─ iter_01/\n",
    "#   │    ├─ subset_species.fasta\n",
    "#   │    ├─ subset.phy\n",
    "#   │    ├─ subset_fullID_to_species.tsv\n",
    "#   │    ├─ tree_pruned.nwk\n",
    "#   │    ├─ codeml.ctl\n",
    "#   │    └─ mlc.txt                (codeml output)\n",
    "#   ├─ iter_02/  (same files)\n",
    "#   └─ iter_03/  (same files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36675404-d503-4993-b227-4dc58bce8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clusters \n",
    "# set the family names for the X chromosome\n",
    "# families = ['CSF2RA', 'SPANX', 'TBL1X' ,'VCX' ,'TMSB' ,'MAGEB',\n",
    "#  'TCEAL8' ,'H2A','endogenous','SPACA5',\n",
    "#  'SSX' ,'GAGE' ,'NUDT10' ,'CENPVL',\n",
    "#  'FLJ39060' ,'XAGE1' ,'FAM156', 'SPIN',\n",
    "#  'ZXD' ,'CXorf49' ,'DMRTC1' ,'FAM236', 'PABPC', 'RPL36A', 'ARMCX' ,'NXF',\n",
    "#  'TCP11X2' ,'GPRASP', 'RAB40A' ,'H2BW', 'CT47' ,'RHOXF2' ,'SMIM10' ,'ETD',\n",
    "#  'INTS6L', 'CT45A', 'CXorf51', 'EOLA' ,'HSFX' ,'TMEM185A', 'CSAG', 'PNMA',\n",
    "#  'PWWP4', 'OPN1LW', 'TEX28', 'LAGE3', 'IKBKG' ,'F8A1',\n",
    "#  'collagen' ,'LOC129475109','LOC115932372']\n",
    "\n",
    "# set the family names for the Y chromosome\n",
    "families = ['CDY1', 'glutamate', 'TSPY8' ,'DAZ1',\n",
    " 'BPY2', 'RBMY1B', 'MTRNR2', 'proline', 'VCY1B',\n",
    " 'HSFY1', 'keratin' ,'FRG1',\n",
    " 'centriole','FAM47A', 'zinc','isoenzyme',\n",
    " 'retrovirus','TATA-box']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b5fe6-6425-4eee-88f6-9be902c2cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = Path(\"/home/emma/Amplicons/Workspaces/emma/downloaded_data\")\n",
    "\n",
    "# species codes + fixed species tree (all taxa; Will be pruned per iteration)\n",
    "species_targets = [\"HomSap\",\"PanTro\",\"PanPan\",\"GorGor\",\"PonAbe\",\"PonPyg\",\"SymSyn\",\"MacFas\"]\n",
    "# Unrooted tree\n",
    "tree_newick = \"(((((PanTro,PanPan), HomSap), GorGor), (PonPyg,PonAbe)), SymSyn, MacFas);\"\n",
    "\n",
    "# tools\n",
    "perl_fasta2phy = data_dir / \"PAML\" / \"FASTAtoPHYL.pl\"   # your Perl converter\n",
    "codeml_bin = \"codeml\"                                    # or Path(\"/full/path/to/codeml\")\n",
    "\n",
    "# iterations\n",
    "n_iters = 6 \n",
    "base_seed = None \n",
    "\n",
    "# base output dir\n",
    "PAML_ROOT = data_dir / \"PAML\" / \"x_chromosome\" # for the X chromosome\n",
    "#PAML_ROOT = data_dir / \"PAML\" / \"y_chromosome\" # for the y chromosome\n",
    "\n",
    "PAML_ROOT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f1cdf-0e87-4be2-8601-d826d85fa280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the clusters per family\n",
    "# this dict will hold, for each family, the list of multi-seq clusters\n",
    "# change the directory sequences_x to sequences_y when doing one or the other. \n",
    "\n",
    "cluster_list_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    # ensure the alignments directory exists\n",
    "    cluster_alignments = f\"{data_dir}/sequences_y/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "    os.makedirs(cluster_alignments, exist_ok=True)\n",
    "\n",
    "    # grab every .fa basename in the cluster_fastas dir\n",
    "    cluster_dir = f\"{data_dir}/sequences_y/{family}_selected_isoform/blastdb/cluster_fastas\"\n",
    "    all_clusters = [\n",
    "        os.path.splitext(fn)[0]\n",
    "        for fn in os.listdir(cluster_dir)\n",
    "        if fn.endswith(\".fa\")\n",
    "    ]\n",
    "\n",
    "    # filter out FASTAs with only one sequence\n",
    "    filtered = []\n",
    "    for name in all_clusters:\n",
    "        path = os.path.join(cluster_dir, f\"{name}.fa\")\n",
    "        with open(path) as f:\n",
    "            nseq = sum(1 for line in f if line.startswith(\">\"))\n",
    "        if nseq > 1:\n",
    "            filtered.append(name)\n",
    "\n",
    "    # check for duplicate IDs\n",
    "    for name in filtered:\n",
    "        path = os.path.join(cluster_dir, f\"{name}.fa\")\n",
    "        seen, dups = set(), set()\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\">\"):\n",
    "                    seqid = line[1:].split()[0]\n",
    "                    if seqid in seen:\n",
    "                        dups.add(seqid)\n",
    "                    else:\n",
    "                        seen.add(seqid)\n",
    "        if dups:\n",
    "            print(f\"[{family}] {name}.fa has duplicate IDs: {', '.join(dups)}\")\n",
    "\n",
    "    # store the filtered list for later\n",
    "    cluster_list_per_family[family] = filtered\n",
    "\n",
    "    print(f\"{family}: keeping {len(filtered)} clusters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c329a1-477f-4157-bff0-5bf751ce7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All functions\n",
    "# Clean up the alignment -> codeml has a hard time with gaps. So drop entire codons if any sequence has a gap inside that codon\n",
    "def make_codonwise_nogap_alignment(inp_path, out_path, gap_chars=\"-\"):\n",
    "    from Bio import AlignIO\n",
    "    from Bio.Align import MultipleSeqAlignment\n",
    "    from Bio.SeqRecord import SeqRecord\n",
    "    from Bio.Seq import Seq\n",
    "\n",
    "    aln = AlignIO.read(str(inp_path), \"fasta\")\n",
    "    L = aln.get_alignment_length()\n",
    "    floorL = (L // 3) * 3\n",
    "\n",
    "    keep_idx = []\n",
    "    gapset = set(gap_chars)\n",
    "    for start in range(0, floorL, 3):\n",
    "        # drop codon if ANY '-' occurs in its 3 columns (in ANY sequence)\n",
    "        if any(any(ch in gapset for ch in aln[:, start + k]) for k in range(3)):\n",
    "            continue\n",
    "        keep_idx.extend([start, start+1, start+2])\n",
    "\n",
    "    if not keep_idx:\n",
    "        raise ValueError(\"No codon columns left after codon-wise gap removal.\")\n",
    "\n",
    "    trimmed = MultipleSeqAlignment([\n",
    "        SeqRecord(Seq(''.join(str(rec.seq)[i] for i in keep_idx)), id=rec.id, description=\"\")\n",
    "        for rec in aln\n",
    "    ])\n",
    "\n",
    "    if trimmed.get_alignment_length() % 3 != 0:\n",
    "        raise AssertionError(\"Trimmed length not divisible by 3 (unexpected).\")\n",
    "\n",
    "    AlignIO.write(trimmed, str(out_path), \"fasta\")\n",
    "    kept_codons = len(keep_idx) // 3\n",
    "    total_codons = floorL // 3\n",
    "    print(f\"codonwise nogaps -> {out_path.name} (kept {kept_codons}/{total_codons} codons)\")\n",
    "\n",
    "def pick_one_per_species(fasta_path: Path, targets: List[str], rng: random.Random) -> Tuple[List[SeqRecord], dict, int, int]:\n",
    "    records = list(SeqIO.parse(str(fasta_path), \"fasta\"))\n",
    "    buckets = {sp: [] for sp in targets}\n",
    "    for r in records:\n",
    "        sp = r.id.split(\"_\")[-1]\n",
    "        if sp in buckets:\n",
    "            r.seq = r.seq.upper()\n",
    "            buckets[sp].append(r)\n",
    "    picked, id_map = [], {}\n",
    "    for sp in targets:\n",
    "        if buckets[sp]:\n",
    "            r = rng.choice(buckets[sp])\n",
    "            picked.append(r)\n",
    "            id_map[r.id] = sp\n",
    "    if len(picked) < 2:\n",
    "        raise ValueError(\"Need at least 2 target species in this cluster.\")\n",
    "    lens = {len(r.seq) for r in picked}\n",
    "    if len(lens) != 1:\n",
    "        raise ValueError(f\"Unequal lengths after nogaps: {sorted(lens)}\")\n",
    "    return picked, id_map, len(picked), next(iter(lens))\n",
    "\n",
    "def write_species_fasta(picked: List[SeqRecord], out_fa: Path):\n",
    "    with open(out_fa, \"w\") as out:\n",
    "        for r in picked:\n",
    "            sp = r.id.split(\"_\")[-1]\n",
    "            out.write(f\">{sp}\\n{str(r.seq)}\\n\")\n",
    "\n",
    "def prune_tree_to_species(tree_newick: str, present: List[str], out_tree: Path):\n",
    "    tree = Phylo.read(StringIO(tree_newick), \"newick\")\n",
    "    names = {t.name for t in tree.get_terminals()}\n",
    "    missing = sorted(set(present) - names)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Tree missing taxa present in alignment: {missing}\")\n",
    "    for term in list(tree.get_terminals()):\n",
    "        if term.name not in present:\n",
    "            tree.prune(term)\n",
    "    Phylo.write(tree, str(out_tree), \"newick\")\n",
    "\n",
    "\n",
    "def fasta_to_phylip_with_perl(perl_script: Path, species_fa: Path, nseq: int, length: int, out_phy: Path):\n",
    "    # run in the iteration folder so the .phy is created there\n",
    "    cwd = species_fa.parent\n",
    "    cmd = [\"perl\", str(perl_script), species_fa.name, str(nseq), str(length)]\n",
    "    subprocess.run(cmd, check=True, cwd=str(cwd))\n",
    "    tmp = cwd / (species_fa.stem + \".phy\")\n",
    "    if not tmp.exists():\n",
    "        raise FileNotFoundError(f\"Expected {tmp} not found after Perl conversion.\")\n",
    "    shutil.move(str(tmp), str(out_phy))\n",
    "\n",
    "def write_ctl(ctl_path: Path, seqfile: str, treefile: str, outfile: str):\n",
    "    ctl = f\"\"\"seqfile = {seqfile}\n",
    "treefile = {treefile}\n",
    "outfile = {outfile}\n",
    "\n",
    "noisy = 3                              * Display moderate amount of information on the screen\n",
    "verbose = 1                            * Detailed output file\n",
    "seqtype = 1                            * Codon data\n",
    "ndata = 1                              * One gene alignment\n",
    "icode = 0                              * Universal genetic code\n",
    "cleandata = 0                          * Do not remove sites with ambiguity data (because gaps already removed before)\n",
    "model = 0                              * One ω for all branches (M0 and site models)\n",
    "NSsites = 0 1 2 7 8                    * Models M0 (0), M1a (1), M2a (2), M7 (7), and M8 (8)\n",
    "CodonFreq = 7                          * Use mutation-selection model\n",
    "estFreq = 0                            * Use observed frequencies to calculate fitness/freq pars\n",
    "clock = 0                              * Assume no clock\n",
    "fix_omega = 0                          * Enables option to estimate omega\n",
    "omega = 0.5                            * Initial omega value\n",
    "\n",
    "\"\"\"\n",
    "    ctl_path.write_text(ctl)\n",
    "\n",
    "def run_codeml(codeml_bin, ctl_path: Path, workdir: Path):\n",
    "    subprocess.run([str(codeml_bin), ctl_path.name], cwd=str(workdir), check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e051926-0421-4245-bd1e-9c9c7a60d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the Workflow\n",
    "\n",
    "if shutil.which(\"perl\") is None:\n",
    "    raise SystemExit(\"Perl not found. Install perl or add it to PATH.\")\n",
    "if shutil.which(str(codeml_bin)) is None:\n",
    "    raise SystemExit(\"codeml not found. Set 'codeml_bin' to its full path or add to PATH.\")\n",
    "if not perl_fasta2phy.exists():\n",
    "    raise SystemExit(f\"Perl converter not found: {perl_fasta2phy}\")\n",
    "\n",
    "for family in families:\n",
    "    clusters = cluster_list_per_family.get(family, [])\n",
    "    print(f\"\\n=== FAMILY: {family} ({len(clusters)} clusters) ===\")\n",
    "    for cluster in clusters:\n",
    "        # input alignment to clean (your trimmed alignments live here) # SEQUENCES_X HAS TO BE CHANGED TO SEQUENCES_Y WHEN Y CHROM\n",
    "        inp = data_dir / \"sequences_y_longestisoform\" / f\"{family}_selected_isoform\" / \"blastdb\" / \"cluster_alignments\" / f\"{cluster}_NT.fa\"\n",
    "        if not inp.exists():\n",
    "            print(f\"  [skip] missing alignment: {inp}\")\n",
    "            continue\n",
    "\n",
    "        cluster_dir = PAML_ROOT / family / cluster\n",
    "        cluster_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 1) no-gap alignment once per cluster\n",
    "        nogap = cluster_dir / f\"{cluster}_nogaps.fa\"\n",
    "        if not nogap.exists():\n",
    "            make_codonwise_nogap_alignment(inp, nogap)\n",
    "\n",
    "        # RNG for this cluster\n",
    "        rng = random.Random(base_seed) if base_seed is not None else random.Random()\n",
    "\n",
    "        # 2) iterations\n",
    "        for it in range(1, n_iters+1):\n",
    "            iter_dir = cluster_dir / f\"iter_{it:02d}\"\n",
    "            iter_dir.mkdir(exist_ok=True)\n",
    "\n",
    "            try:\n",
    "                # pick one seq per species\n",
    "                picked, id_map, nseq, length = pick_one_per_species(nogap, species_targets, rng)\n",
    "                present = sorted({r.id.split(\"_\")[-1] for r in picked})\n",
    "\n",
    "                # write subset files\n",
    "                subset_fa   = iter_dir / \"subset_species.fasta\"\n",
    "                subset_phy  = iter_dir / \"subset.phy\"\n",
    "                subset_map  = iter_dir / \"subset_fullID_to_species.tsv\"\n",
    "                subset_tree = iter_dir / \"tree_pruned.nwk\"\n",
    "\n",
    "                write_species_fasta(picked, subset_fa)\n",
    "                with open(subset_map, \"w\") as f:\n",
    "                    f.write(\"full_id\\tspecies\\n\")\n",
    "                    for full, sp in id_map.items():\n",
    "                        f.write(f\"{full}\\t{sp}\\n\")\n",
    "\n",
    "                prune_tree_to_species(tree_newick, present, subset_tree)\n",
    "\n",
    "                # FASTA -> PHYLIP\n",
    "                fasta_to_phylip_with_perl(perl_fasta2phy, subset_fa, nseq, length, subset_phy)\n",
    "\n",
    "                # codeml control + run\n",
    "                ctl = iter_dir / \"codeml.ctl\"\n",
    "                out_mlc = iter_dir / \"mlc.txt\"\n",
    "                write_ctl(ctl, \"subset.phy\", \"tree_pruned.nwk\", \"mlc.txt\")\n",
    "                run_codeml(codeml_bin, ctl, iter_dir)\n",
    "\n",
    "                print(f\"  {family}/{cluster} iter {it:02d}: OK ({nseq} spp × {length} bp)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  {family}/{cluster} iter {it:02d}: SKIP -> {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344eaa6-1378-40ca-8e93-d3b8c4aa32a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
