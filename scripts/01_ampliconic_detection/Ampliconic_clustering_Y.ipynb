{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "735104dc-95a0-4f45-aeb4-716ca5da1833",
   "metadata": {},
   "source": [
    "# Y chromosome ampliconic clustering updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85cab59-b807-454f-981d-2881c83195a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import Phylo\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import re\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c988aff-6975-465b-9d18-61710684697c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PanTro',\n",
       " 'HomSap',\n",
       " 'PanPan',\n",
       " 'GorGor',\n",
       " 'PonPyg',\n",
       " 'PonAbe',\n",
       " 'SymSyn',\n",
       " 'MacFas']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1. Define species information\n",
    "\n",
    "# Define base directories\n",
    "data_dir = \"/home/emma/Amplicons/Workspaces/emma/downloaded_data\"\n",
    "work_dir = os.path.join(data_dir, \"work_dir\", \"y_multicopy\")\n",
    "\n",
    "#Define the list of dictionaries (data) containing genome information for different species\n",
    "data = [\n",
    "    {'species':'PanTro',\n",
    "     'data': {'chr_y': \"NC_072422.2\",\n",
    "              'chr_x': \"NC_072421.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic.gff\", #annotation file \n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic_chrY.gff\", #Y specific annotation\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028858775.2.gff3\", #path to an alternate annotation format (generated by CAT pipeline)\n",
    "              'ref':  f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/GCF_028858775.2_NHGRI_mPanTro3-v2.0_pri_genomic.fna\", # primary reference genome file\n",
    "              'rna':  f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/rna.fna\", #RNA sequences \n",
    "              'prot': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/protein.faa\", #protein sequences (FASTA format)\n",
    "              'cds': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/cds_from_genomic.fna\", #coding DNA seq derived from genome\n",
    "              'gff_x': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic_chrX.gff\", # chrX annotation file\n",
    "              'fasta_x': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/PanTro_X.fasta\", # only X reference genome\n",
    "              'fasta_y': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/PanTro_Y.fasta\", # only Y reference genome\n",
    "              'gff_x_cds': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic_chrX_cds_isoform.gff\", # gff file with only CDS annotation filtered\n",
    "              'gff_y_cds': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic_chrY_cds_isoform.gff\", # gff file with only CDS annotation filtered\n",
    " }},\n",
    "    {'species':'HomSap',\n",
    "     'data': {'chr_y': \"NC_060948.1\",\n",
    "              'chr_x': \"NC_060947.1\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/hg38.gff3\",\n",
    "              'ref': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/GCF_009914755.1_T2T-CHM13v2.0_genomic.fna\",\n",
    "              'cds': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/cds_from_genomic.fna\",\n",
    "              'prot': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/protein.faa\",\n",
    "              'gff_x': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/HomSap_X.fasta\",\n",
    "              'fasta_y': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/HomSap_Y.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic_chrX_cds_isoform.gff\",\n",
    "              'gff_y_cds': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic_chrY_cds_isoform.gff\",\n",
    "              }},\n",
    "     {'species':'PanPan',\n",
    "     'data': {'chr_y': \"NC_073273.2\",\n",
    "              'chr_x': \"NC_073272.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_029289425.2.gff3\",\n",
    "              'ref': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/GCF_029289425.2_NHGRI_mPanPan1-v2.0_pri_genomic.fna\",\n",
    "              'cds': f'{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/protein.faa',\n",
    "              'gff_x': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/PanPan_X.fasta\",\n",
    "              'fasta_y': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/PanPan_Y.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic_chrX_cds_isoform.gff\",\n",
    "              'gff_y_cds': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic_chrY_cds_isoform.gff\",\n",
    "              }},\n",
    "      {'species':'GorGor',\n",
    "     'data': {'chr_y': \"NC_073248.2\",\n",
    "              'chr_x': \"NC_073247.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_029281585.2.gff3\",\n",
    "              'ref': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/GCF_029281585.2_NHGRI_mGorGor1-v2.0_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/protein.faa',\n",
    "              'gff_x': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/GorGor_X.fasta\",\n",
    "              'fasta_y': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/GorGor_Y.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic_chrX_cds_isoform.gff\",\n",
    "              'gff_y_cds': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic_chrY_cds_isoform.gff\",\n",
    "              }},\n",
    "    {'species':'PonPyg',\n",
    "     'data': {'chr_y': \"NC_072397.2\",\n",
    "              'chr_x': \"NC_072396.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028885625.2.gff3\",\n",
    "              'ref': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/GCF_028885625.2_NHGRI_mPonPyg2-v2.0_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/protein.faa',\n",
    "              'gff_x': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/PonPyg_X.fasta\",\n",
    "              'fasta_y': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/PonPyg_Y.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic_chrX_cds_isoform.gff\",\n",
    "              'gff_y_cds': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic_chrY_cds_isoform.gff\",\n",
    "              }},\n",
    "    {'species':'PonAbe',\n",
    "     'data': {'chr_y': \"NC_072009.2\",\n",
    "              'chr_x': \"NC_072008.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028885655.2.gff3\",\n",
    "              'ref': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/GCF_028885655.2_NHGRI_mPonAbe1-v2.0_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/protein.faa',\n",
    "              'gff_x': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/PonAbe_X.fasta\",\n",
    "              'fasta_y': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/PonAbe_Y.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic_chrX_cds_isoform.gff\",\n",
    "              'gff_y_cds': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic_chrY_cds_isoform.gff\",\n",
    "              }},    \n",
    "    {'species':'SymSyn',\n",
    "      'data': {'chr_y': \"NC_072448.2\",\n",
    "               'chr_x': \"NC_072447.2\",\n",
    "               'ref': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/GCF_028878055.3_NHGRI_mSymSyn1-v2.1_pri_genomic.fna',\n",
    "               'path_to_annotation_NCBI': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic.gff\",\n",
    "               'path_to_annotation_NCBI_chry': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic_chrY.gff\",\n",
    "               'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028878055.3.gff3\",\n",
    "               'cds': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/cds_from_genomic.fna',\n",
    "               'prot': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/protein.faa',\n",
    "               'gff_x': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic_chrX.gff\",\n",
    "               'fasta_x': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/SymSyn_X.fasta\",\n",
    "               'fasta_y': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/SymSyn_Y.fasta\",\n",
    "               'gff_x_cds': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic_chrX_cds_isoform.gff\",\n",
    "               'gff_y_cds': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic_chrY_cds_isoform.gff\",\n",
    "               }},\n",
    "    {'species':'MacFas',\n",
    "      'data': {'chr_y': \"NC_132903.1\",\n",
    "               'chr_x': \"NC_088395.1\",\n",
    "               'ref': f'{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/GCF_037993035.2_T2T-MFA8v1.1_genomic.fna',\n",
    "               'path_to_annotation_NCBI': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/genomic.gff\",\n",
    "               'cds': f'{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/cds_from_genomic.fna',\n",
    "               'prot': f'{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/protein.faa',\n",
    "               'gff_x': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/genomic_chrX.gff\",\n",
    "               'fasta_x': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/MacFas_X.fasta\",\n",
    "               'fasta_y': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/MacFas_Y.fasta\",\n",
    "               'gff_x_cds': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/genomic_chrX_cds_isoform.gff\",\n",
    "               'gff_y_cds': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/genomic_chrY_cds_isoform.gff\"\n",
    "               }},\n",
    "]\n",
    "\n",
    "# Maps species identifiers to their common name\n",
    "species_to_sequence_spec = {\n",
    "    'PanTro': 'chimpanzee',\n",
    "    'HomSap': 'human',\n",
    "    'PanPan': 'bonobo',\n",
    "    'GorGor': 'gorilla',\n",
    "    'PonPyg': 'b-orang',\n",
    "    'PonAbe': 's-orang',\n",
    "    'SymSyn': 'siamang',\n",
    "    'MacFas': 'macaque'\n",
    "\n",
    "}\n",
    "# Extracting species names -> list of species identifiers by iterating t\n",
    "species_info = {item['species']: item['data'] for item in data}\n",
    "species_list = [d['species'] for d in data]\n",
    "species_info\n",
    "species_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fed44d-4481-4173-985a-32370a6d6324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Gene_symbol</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Class</th>\n",
       "      <th>gene_family_symbol</th>\n",
       "      <th>in_palindrome</th>\n",
       "      <th>palindrome_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>testis-specific chromodomain protein Y 1</td>\n",
       "      <td>LOC745547</td>\n",
       "      <td>5358723</td>\n",
       "      <td>5360941</td>\n",
       "      <td>+</td>\n",
       "      <td>AMPLICONIC</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>yes</td>\n",
       "      <td>Q1B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>glutamate dehydrogenase 1, mitochondrial-like</td>\n",
       "      <td>LOC750007</td>\n",
       "      <td>5539042</td>\n",
       "      <td>5540684</td>\n",
       "      <td>+</td>\n",
       "      <td>AMPLICONIC</td>\n",
       "      <td>glutamate dehydrogenase 1, mitochondrial-like</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>testis-specific Y-encoded protein 3-like</td>\n",
       "      <td>LOC129135297</td>\n",
       "      <td>6661276</td>\n",
       "      <td>6664016</td>\n",
       "      <td>+</td>\n",
       "      <td>ANCESTRAL</td>\n",
       "      <td>TSPY8</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>testis-specific Y-encoded protein 3</td>\n",
       "      <td>LOC107973386</td>\n",
       "      <td>6672036</td>\n",
       "      <td>6674778</td>\n",
       "      <td>+</td>\n",
       "      <td>ANCESTRAL</td>\n",
       "      <td>TSPY8</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>testis-specific Y-encoded protein 3</td>\n",
       "      <td>LOC112207446</td>\n",
       "      <td>6682798</td>\n",
       "      <td>6685540</td>\n",
       "      <td>+</td>\n",
       "      <td>ANCESTRAL</td>\n",
       "      <td>TSPY8</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>testis-specific Y-encoded protein 2-like</td>\n",
       "      <td>LOC141409530</td>\n",
       "      <td>11981124</td>\n",
       "      <td>11983881</td>\n",
       "      <td>-</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>TSPY8</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>testis-specific Y-encoded protein 2-like</td>\n",
       "      <td>LOC141409557</td>\n",
       "      <td>12091184</td>\n",
       "      <td>12093921</td>\n",
       "      <td>+</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>TSPY8</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>deleted in azoospermia protein 1-like</td>\n",
       "      <td>LOC141409531</td>\n",
       "      <td>12794702</td>\n",
       "      <td>12850544</td>\n",
       "      <td>+</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DAZ1</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>testis-specific chromodomain protein Y 2-like</td>\n",
       "      <td>LOC141409533</td>\n",
       "      <td>13091147</td>\n",
       "      <td>13093961</td>\n",
       "      <td>-</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>testis-specific chromodomain protein Y 2-like</td>\n",
       "      <td>LOC141409534</td>\n",
       "      <td>13181606</td>\n",
       "      <td>13183887</td>\n",
       "      <td>+</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species                                           Gene   Gene_symbol  \\\n",
       "0    PanTro       testis-specific chromodomain protein Y 1     LOC745547   \n",
       "1    PanTro  glutamate dehydrogenase 1, mitochondrial-like     LOC750007   \n",
       "2    PanTro       testis-specific Y-encoded protein 3-like  LOC129135297   \n",
       "3    PanTro            testis-specific Y-encoded protein 3  LOC107973386   \n",
       "4    PanTro            testis-specific Y-encoded protein 3  LOC112207446   \n",
       "..      ...                                            ...           ...   \n",
       "399  MacFas       testis-specific Y-encoded protein 2-like  LOC141409530   \n",
       "400  MacFas       testis-specific Y-encoded protein 2-like  LOC141409557   \n",
       "401  MacFas          deleted in azoospermia protein 1-like  LOC141409531   \n",
       "402  MacFas  testis-specific chromodomain protein Y 2-like  LOC141409533   \n",
       "403  MacFas  testis-specific chromodomain protein Y 2-like  LOC141409534   \n",
       "\n",
       "        Start       End Strand       Class  \\\n",
       "0     5358723   5360941      +  AMPLICONIC   \n",
       "1     5539042   5540684      +  AMPLICONIC   \n",
       "2     6661276   6664016      +   ANCESTRAL   \n",
       "3     6672036   6674778      +   ANCESTRAL   \n",
       "4     6682798   6685540      +   ANCESTRAL   \n",
       "..        ...       ...    ...         ...   \n",
       "399  11981124  11983881      -     Unknown   \n",
       "400  12091184  12093921      +     Unknown   \n",
       "401  12794702  12850544      +     Unknown   \n",
       "402  13091147  13093961      -     Unknown   \n",
       "403  13181606  13183887      +     Unknown   \n",
       "\n",
       "                                gene_family_symbol in_palindrome  \\\n",
       "0                                             CDY1           yes   \n",
       "1    glutamate dehydrogenase 1, mitochondrial-like            no   \n",
       "2                                            TSPY8            no   \n",
       "3                                            TSPY8            no   \n",
       "4                                            TSPY8            no   \n",
       "..                                             ...           ...   \n",
       "399                                          TSPY8            no   \n",
       "400                                          TSPY8            no   \n",
       "401                                           DAZ1            no   \n",
       "402                                           CDY1            no   \n",
       "403                                           CDY1            no   \n",
       "\n",
       "    palindrome_name  \n",
       "0               Q1B  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "..              ...  \n",
       "399             NaN  \n",
       "400             NaN  \n",
       "401             NaN  \n",
       "402             NaN  \n",
       "403             NaN  \n",
       "\n",
       "[404 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Load dataframes with Gene coordinates and Family information\n",
    "genes = pd.read_csv(f\"{work_dir}/protein_extracted_longest/clusters_merged/gene_details_updated_with_palindromes_coordinates.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2868ae6-a1e1-4573-9d29-bbaab9903bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CDY1' 'glutamate dehydrogenase 1, mitochondrial-like' 'TSPY8' 'DAZ1'\n",
      " 'BPY2' 'RBMY1B' 'MTRNR2-like 17' 'proline-rich protein, Y-linked' 'VCY1B'\n",
      " 'HSFY1' 'keratin, type I cytoskeletal 18-like' 'protein FRG1-like'\n",
      " 'centriole and centriolar satellite protein OFD1-like'\n",
      " 'protein FAM47A-like' 'zinc finger protein 285-like'\n",
      " 'adenylate kinase isoenzyme 6-like'\n",
      " 'endogenous retrovirus group K member 19 Env polyprotein-like'\n",
      " 'TATA-box binding protein associated factor 11 like protein 2-like']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vals = genes['gene_family_symbol'].unique()\n",
    "print(unique_vals)\n",
    "len(unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a7645-e920-46d5-9454-bb7be4f05ff6",
   "metadata": {},
   "source": [
    "## Extract coding sequences per family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db4421c-1bfb-436c-a8fc-820241b7a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left out because not ampliconic (looked at these individually before and are not ampliconic when 95% identity over 80% of their coverage) : 'uncharacterized LOC129138873\n",
    "\n",
    "# notes: \n",
    "# 'glutamate dehydrogenase 1, mitochondrial-like' glutamate\n",
    "# 'MTRNR2-like 17' is called MTRNR2\n",
    "# 'proline-rich protein, Y-linked' is named proline\n",
    "#  'keratin, type I cytoskeletal 18-like' is called keratin\n",
    "# 'protein FRG1-like' is named FRG1\n",
    "# 'centriole and centriolar satellite protein OFD1-like' is called centriole \n",
    "# 'protein FAM47A-like' is called FAM47A\n",
    "# 'zinc finger protein 285-like' is called zinc\n",
    "# 'adenylate kinase isoenzyme 6-like' is called isoenzyme\n",
    "# 'endogenous retrovirus group K member 19 Env polyprotein-like' is called retrovirus\n",
    "# 'TATA-box binding protein associated factor 11 like protein 2-like' is called TATAbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3453807e-2e6d-43d7-805e-34197a50e9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if only want certain families:\n",
    "families = ['CDY1', 'glutamate', 'TSPY8' ,'DAZ1',\n",
    " 'BPY2', 'RBMY1B', 'MTRNR2', 'proline', 'VCY1B',\n",
    " 'HSFY1', 'keratin' ,'FRG1',\n",
    " 'centriole','FAM47A', 'zinc','isoenzyme',\n",
    " 'retrovirus','TATA-box']\n",
    "len(families)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727c577-7976-4487-919c-5c34aab2c14d",
   "metadata": {},
   "source": [
    "### Extract the coding Regions\n",
    "From each gene extract the CDS and merge all the species together in one large fasta file. <br>\n",
    "Translate the sequence at the end so that the sequences can be checked with the protein files in the references genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d448325-0cb2-4121-8cbc-aac9bccefc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing family 'CDY1' ===\n",
      "  • PanTro: wrote 4/4 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/CDY1_selected_isoform/PanTro_CDY1.fa\n",
      "  • HomSap: wrote 4/4 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/CDY1_selected_isoform/HomSap_CDY1.fa\n",
      "  • PanPan: wrote 2/2 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/CDY1_selected_isoform/PanPan_CDY1.fa\n",
      "  • GorGor: wrote 1/1 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/CDY1_selected_isoform/GorGor_CDY1.fa\n",
      "  • PonPyg: wrote 13/13 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/CDY1_selected_isoform/PonPyg_CDY1.fa\n",
      "  • PonAbe: wrote 22/22 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/CDY1_selected_isoform/PonAbe_CDY1.fa\n",
      "  • SymSyn: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/CDY1_selected_isoform/SymSyn_CDY1.fa\n",
      "  • MacFas: wrote 2/2 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/CDY1_selected_isoform/MacFas_CDY1.fa\n"
     ]
    }
   ],
   "source": [
    "# Extract the sequences\n",
    "\n",
    "def parse_attributes(attr_str):\n",
    "    attrs = {}\n",
    "    for part in attr_str.strip().split(\";\"):\n",
    "        if \"=\" in part:\n",
    "            k, v = part.split(\"=\", 1)\n",
    "            attrs[k.strip().lower()] = v.strip()\n",
    "    return attrs\n",
    "\n",
    "def get_isoform(attrs):\n",
    "    \"\"\"Extract isoform identifier from attributes.\"\"\"\n",
    "    prod = attrs.get(\"product\", \"\")\n",
    "    m = re.search(r'isoform\\s+(X\\d+|\\d+|[a-z])\\b', prod, re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).upper()  # normalize to uppercase\n",
    "    \n",
    "    for key in (\"transcript_id\", \"protein_id\"):\n",
    "        if key in attrs:\n",
    "            return attrs[key]\n",
    "    \n",
    "    return \"NA\"\n",
    "\n",
    "def select_best_isoform(isoforms_dict, refseq_iso):\n",
    "    \"\"\"Select best isoform according to priority rules.\"\"\"\n",
    "    cands = list(isoforms_dict.keys())\n",
    "    \n",
    "    # Priority 1: RefSeq Select\n",
    "    if refseq_iso and refseq_iso in cands:\n",
    "        return refseq_iso\n",
    "    \n",
    "    # Priority 2: NA (unnamed isoform)\n",
    "    if \"NA\" in cands:\n",
    "        return \"NA\"\n",
    "    \n",
    "    # Priority 3: X1 (exact match only!)\n",
    "    if \"X1\" in cands:\n",
    "        return \"X1\"\n",
    "    \n",
    "    # Priority 4: 1 or A\n",
    "    for iso in (\"1\", \"A\"):\n",
    "        if iso in cands:\n",
    "            return iso\n",
    "    \n",
    "    # Priority 5: Lowest number or alphabetically first\n",
    "    # Separate X-prefixed numbers, plain numbers, and alphabetic\n",
    "    x_numeric = []\n",
    "    plain_numeric = []\n",
    "    alpha_isos = []\n",
    "    \n",
    "    for iso in cands:\n",
    "        m_x = re.match(r'^X(\\d+)$', iso, re.IGNORECASE)\n",
    "        if m_x:\n",
    "            x_numeric.append((int(m_x.group(1)), iso))\n",
    "            continue\n",
    "        \n",
    "        m_plain = re.match(r'^(\\d+)$', iso)\n",
    "        if m_plain:\n",
    "            plain_numeric.append((int(m_plain.group(1)), iso))\n",
    "            continue\n",
    "        \n",
    "        alpha_isos.append(iso)\n",
    "    \n",
    "    if x_numeric:\n",
    "        x_numeric.sort()\n",
    "        return x_numeric[0][1]\n",
    "    \n",
    "    if plain_numeric:\n",
    "        plain_numeric.sort()\n",
    "        return plain_numeric[0][1]\n",
    "    \n",
    "    if alpha_isos:\n",
    "        alpha_isos.sort()\n",
    "        return alpha_isos[0]\n",
    "    \n",
    "    return sorted(cands)[0]\n",
    "\n",
    "def extract_cds(genome_fasta, gff_file, gene_name):\n",
    "    \"\"\"Extract CDS for gene, selecting best isoform.\"\"\"\n",
    "    genome = SeqIO.to_dict(SeqIO.parse(genome_fasta, \"fasta\"))\n",
    "    records = {}     \n",
    "    attrs_map = {}    \n",
    "    refseq_iso = None\n",
    "    \n",
    "    # Collect all CDS features for this gene\n",
    "    with open(gff_file) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            cols = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            if len(cols) < 9 or cols[2] != \"CDS\":\n",
    "                continue\n",
    "            \n",
    "            seqid, _, _, start, end, _, strand, frame, attr_str = cols[:9]\n",
    "            attrs = parse_attributes(attr_str)\n",
    "            \n",
    "            if attrs.get(\"gene\") != gene_name:\n",
    "                continue\n",
    "            \n",
    "            iso = get_isoform(attrs)\n",
    "            \n",
    "            fragment = (seqid, int(start) - 1, int(end), int(frame), strand)\n",
    "            \n",
    "            if iso not in records:\n",
    "                records[iso] = []\n",
    "            \n",
    "            fragment_coords = (fragment[0], fragment[1], fragment[2], fragment[4])  \n",
    "            existing_coords = [(f[0], f[1], f[2], f[4]) for f in records[iso]]\n",
    "            \n",
    "            if fragment_coords not in existing_coords:\n",
    "                records[iso].append(fragment)\n",
    "            \n",
    "            attrs_map[iso] = attrs\n",
    "            \n",
    "            if \"tag\" in attrs and \"refseq select\" in attrs[\"tag\"].lower():\n",
    "                refseq_iso = iso\n",
    "    \n",
    "    if not records:\n",
    "        return {}\n",
    "    \n",
    "    # Assemble CDS sequence for each isoform\n",
    "    isoform_sequences = {}\n",
    "    for iso, frags in records.items():\n",
    "        rev = (frags[0][4] == \"-\")\n",
    "        frags.sort(key=lambda x: x[1], reverse=rev)\n",
    "        \n",
    "        pieces = []\n",
    "        first = True\n",
    "        for sid, s, e, frm, strand in frags:\n",
    "            subseq = genome[sid].seq[s:e]\n",
    "            if strand == \"-\":\n",
    "                subseq = subseq.reverse_complement()\n",
    "            if first:\n",
    "                subseq = subseq[frm:]  \n",
    "                first = False\n",
    "            pieces.append(str(subseq))\n",
    "        \n",
    "        isoform_sequences[iso] = \"\".join(pieces)\n",
    "    \n",
    "    # Select best isoform\n",
    "    best_iso = select_best_isoform(isoform_sequences, refseq_iso)\n",
    "    \n",
    "    return {best_iso: (isoform_sequences[best_iso], attrs_map[best_iso])}\n",
    "\n",
    "# ========== Main processing loop ================\n",
    "for family in families:\n",
    "    print(f\"\\n=== Processing family {family!r} ===\")\n",
    "    filtered_genes = genes[\n",
    "        genes[\"gene_family_symbol\"].str.contains(family, na=False)\n",
    "    ]\n",
    "    \n",
    "    intermediate_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform\"\n",
    "    os.makedirs(intermediate_dir, exist_ok=True)\n",
    "    \n",
    "    for species in species_list:\n",
    "        info = species_info[species]\n",
    "        genome = info[\"fasta_y\"]\n",
    "        gff_file = info[\"gff_y_cds\"]\n",
    "        out_fa = f\"{intermediate_dir}/{species}_{family}.fa\"\n",
    "        \n",
    "        with open(out_fa, \"w\") as fout:\n",
    "            sp_genes = filtered_genes[filtered_genes[\"Species\"] == species]\n",
    "            written = 0\n",
    "            \n",
    "            for gene in sp_genes[\"Gene_symbol\"]:\n",
    "                iso_dict = extract_cds(genome, gff_file, gene)\n",
    "                \n",
    "                if not iso_dict:\n",
    "                    print(f\"    [!] No CDS for {gene} in {species}\")\n",
    "                    continue\n",
    "                \n",
    "                for iso, (seq, attrs) in iso_dict.items():\n",
    "                    pid = attrs.get(\"protein_id\", \"\")\n",
    "                    header = f\">{gene}_isoform_{iso}\"\n",
    "                    if pid:\n",
    "                        header += f\";protein_id={pid}\"\n",
    "                    fout.write(header + \"\\n\" + seq + \"\\n\")\n",
    "                    written += 1\n",
    "            \n",
    "            print(f\"  • {species}: wrote {written}/{len(sp_genes)} genes → {out_fa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193bef1d-5ae4-4351-86fe-0075eadb3372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing family 'CSF2RA'\n",
      "\n",
      "→ Combined FASTA for CSF2RA at /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/all_species_CSF2RA.fa\n"
     ]
    }
   ],
   "source": [
    "# combine fasta files\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing family {family!r}\\n\")\n",
    "\n",
    "    # combine step\n",
    "    intermediate_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform\"\n",
    "    combined_fasta   = f\"{intermediate_dir}/all_species_{family}.fa\"\n",
    "    with open(combined_fasta, \"w\") as outfile:\n",
    "        for species in species_list:\n",
    "            species_fasta = f\"{intermediate_dir}/{species}_{family}.fa\"\n",
    "            try:\n",
    "                with open(species_fasta) as infile:\n",
    "                    for line in infile:\n",
    "                        if line.startswith(\">\"):\n",
    "                            header = line.strip()\n",
    "                            if not header.endswith(f\"_{species}\"):\n",
    "                                header += f\"_{species}\"\n",
    "                            outfile.write(header + \"\\n\")\n",
    "                        else:\n",
    "                            outfile.write(line)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"[Warning] {species_fasta} not found.\")\n",
    "    print(f\"→ Combined FASTA for {family} at {combined_fasta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b542c68-7372-48b8-abd2-3aedd9b3c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/all_species_CSF2RA.fa → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/all_species_CSF2RA_translated.fa\n"
     ]
    }
   ],
   "source": [
    "##TRANSLATE \n",
    "def translate_record(record, frame=0):\n",
    "    \"\"\"\n",
    "    Translates a SeqRecord's nucleotide sequence into a protein sequence.\n",
    "    \n",
    "    :param record: A SeqRecord object containing the nucleotide sequence.\n",
    "    :param frame: The reading frame (0, 1, or 2) to start translation.\n",
    "    :return: A new SeqRecord with the translated protein sequence.\n",
    "    \"\"\"\n",
    "    # Adjust the sequence for the reading frame\n",
    "    trimmed_seq = record.seq[frame:]\n",
    "    # Translate into protein (keeps '*' for stop codons)\n",
    "    protein_seq = trimmed_seq.translate(to_stop=False)\n",
    "    # Create a new SeqRecord for the protein\n",
    "    return SeqRecord(protein_seq, id=record.id, description=\"translated\")\n",
    "\n",
    "def translate_fasta(input_file, output_file, frame=0):\n",
    "    \"\"\"\n",
    "    Reads a FASTA file with nucleotide sequences, translates each sequence, \n",
    "    and writes the protein sequences to an output FASTA file.\n",
    "    \n",
    "    :param input_file: Path to the input FASTA file.\n",
    "    :param output_file: Path to the output FASTA file.\n",
    "    :param frame: The reading frame (0, 1, or 2) to start translation.\n",
    "    \"\"\"\n",
    "    # Parse the input FASTA file and translate each record\n",
    "    translated_records = []\n",
    "    for record in SeqIO.parse(input_file, \"fasta\"):\n",
    "        translated_records.append(translate_record(record, frame))\n",
    "    \n",
    "    # Write the translated records to the output FASTA file\n",
    "    SeqIO.write(translated_records, output_file, \"fasta\")\n",
    "\n",
    "for family in families:\n",
    "    # 1) make the per-family directory\n",
    "    intermediate_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform\"\n",
    "    os.makedirs(intermediate_dir, exist_ok=True)\n",
    "\n",
    "    # 2) build input/output paths\n",
    "    in_fasta  = f\"{intermediate_dir}/all_species_{family}.fa\"\n",
    "    out_fasta = f\"{intermediate_dir}/all_species_{family}_translated.fa\"\n",
    "\n",
    "    # 3) translate\n",
    "    print(f\"Translating {in_fasta} → {out_fasta}\")\n",
    "    translate_fasta(in_fasta, out_fasta, frame=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a77913-5f0d-49a2-8b76-87ef4c80f3aa",
   "metadata": {},
   "source": [
    "## Create Ampliconic clustering across species using BLAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8624ca3-cfde-4b91-bb12-2116b90241ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ makeblastdb for 'CSF2RA'\n",
      "\n",
      "\n",
      "Building a new DB, current time: 10/31/2025 14:52:06\n",
      "New DB name:   /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/blastdb\n",
      "New DB title:  /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/all_species_CSF2RA.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 9 sequences in 0.08725 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create ampliconic clusters based on Identity using BLASTN\n",
    "for family in families:\n",
    "    print(f\"▶ makeblastdb for {family!r}\")\n",
    "    cmd = f\"makeblastdb \\\n",
    "            -in {data_dir}/sequences_y_updated/{family}_selected_isoform/all_species_{family}.fa \\\n",
    "            -dbtype nucl \\\n",
    "            -out {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/blastdb\"\n",
    "    subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2122e25-998c-4ce6-b36c-247a3905f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing family: CSF2RA\n"
     ]
    }
   ],
   "source": [
    "# pairwise comparison of each gene coding sequence against all other genes in the database \n",
    "for family in families:\n",
    "    print(f\"Processing family: {family}\")\n",
    "    cmd = f\"blastn -query {data_dir}/sequences_y_updated/{family}_selected_isoform/all_species_{family}.fa \\\n",
    "    -db {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/blastdb \\\n",
    "    -out {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/results.blastp.tsv \\\n",
    "    -outfmt \\\"6 qseqid sseqid pident mismatch gapopen gaps qcovs qcovshsp evalue\\\" \"\n",
    "\n",
    "    subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "88aa070b-a32a-4a02-8895-203ee58e0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing family: CSF2RA\n"
     ]
    }
   ],
   "source": [
    "# # Collect edges for each protein with species-specific thresholds\n",
    "edges = {}\n",
    "identity_default = 95\n",
    "identity_macfas = 90  # More lenient threshold for MacFas because it is already 5% sequence identity away from the other species\n",
    "coverage = 80\n",
    "score = 0.001\n",
    "\n",
    "edges_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    print(f\"Processing family: {family}\")\n",
    "    edges = {}\n",
    "    file = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/results.blastp.tsv\"\n",
    "    \n",
    "    with open(file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            cols = line.strip().split(\"\\t\")\n",
    "            \n",
    "            # Determine which identity threshold to use\n",
    "            query_id = cols[0]\n",
    "            subject_id = cols[1]\n",
    "            \n",
    "            is_macfas_comparison = \"MacFas\" in query_id or \"MacFas\" in subject_id\n",
    "            \n",
    "            # Use appropriate identity threshold\n",
    "            identity_threshold = identity_macfas if is_macfas_comparison else identity_default\n",
    "            \n",
    "            # Apply filtering with the appropriate threshold\n",
    "            if (float(cols[2]) >= identity_threshold\n",
    "                and int(cols[6]) >= coverage\n",
    "                and float(cols[7]) < score):\n",
    "                \n",
    "                if cols[0] in edges:\n",
    "                    edges[cols[0]].append(cols[1])\n",
    "                else:\n",
    "                    edges[cols[0]] = [cols[1]]\n",
    "    \n",
    "    edges_per_family[family] = edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7587555-7cba-4faf-9920-ffc1107d6b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing family: CSF2RA\n"
     ]
    }
   ],
   "source": [
    "two_way_per_family = {}\n",
    "vertices_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    print(f\"Processing family: {family}\")\n",
    "    edges     = edges_per_family[family]\n",
    "    edges_2way = []\n",
    "    vertices   = set()\n",
    "\n",
    "    for node_A in edges:\n",
    "        for node_B in edges[node_A]:\n",
    "            if node_B in edges and node_A in edges[node_B]:\n",
    "                pair = tuple(sorted((node_A, node_B)))\n",
    "                if pair in edges_2way:\n",
    "                    continue\n",
    "                edges_2way.append(pair)\n",
    "                vertices.add(node_A)\n",
    "                vertices.add(node_B)\n",
    "\n",
    "    two_way_per_family[family] = edges_2way\n",
    "    vertices_per_family[family]   = vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "050f77e4-820d-441d-8ed7-c3ed01a76676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Clustering for family 'CSF2RA'\n"
     ]
    }
   ],
   "source": [
    "clusters_per_family = {}\n",
    "merged_clusters_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    print(f\"→ Clustering for family {family!r}\")\n",
    "    edges_2way = two_way_per_family[family]\n",
    "\n",
    "    # 1) transitive clustering\n",
    "    clusters = []\n",
    "    for edge in edges_2way:\n",
    "        found = False\n",
    "        for cluster in clusters:\n",
    "            if edge[0] in cluster or edge[1] in cluster:\n",
    "                cluster.add(edge[0])\n",
    "                cluster.add(edge[1])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            clusters.append(set(edge))\n",
    "\n",
    "    # 2) merge overlapping clusters\n",
    "    merged_clusters = []\n",
    "    for cluster in clusters:\n",
    "        found = False\n",
    "        for m in merged_clusters:\n",
    "            if cluster & m:       # any intersection?\n",
    "                m.update(cluster)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            merged_clusters.append(cluster)\n",
    "\n",
    "    # store and/or print\n",
    "    merged_clusters_per_family[family] = merged_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2fc1cf1-35b2-40be-b6c9-0111b1cb7c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  • Saved clustering table for 'CSF2RA' → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/gene_clustering_CSF2RA.csv\n"
     ]
    }
   ],
   "source": [
    "# Define which sequences belong into cluster together\n",
    "for family in families:\n",
    "    clusters = merged_clusters_per_family.get(family, [])\n",
    "    if not clusters:\n",
    "        print(f\"No clusters for family {family!r}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    rows = [\n",
    "        (\n",
    "            gene,\n",
    "            gene.rsplit('_', 1)[1],      # species is the suffix after the last underscore\n",
    "            cluster_id\n",
    "        )\n",
    "        for cluster_id, cluster in enumerate(clusters, start=1)\n",
    "        for gene in cluster\n",
    "    ]\n",
    "\n",
    "    # Create  DataFrame\n",
    "    df = pd.DataFrame(rows, columns=['gene_name', 'species', 'cluster'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    out_csv = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/gene_clustering_{family}.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"  • Saved clustering table for {family!r} → {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ce2e383d-76e0-41cb-be51-1c0799b6f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Naming clusters for family 'CSF2RA'\n",
      "  • Saved auto-named clusters → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/CSF2RA_clusters_named_auto.csv\n"
     ]
    }
   ],
   "source": [
    "# gives cluster names automatically based on overal recognizable cluster name \n",
    "for family in families:\n",
    "    print(f\"→ Naming clusters for family {family!r}\")\n",
    "\n",
    "    # 1) Load the per-family clustering table\n",
    "    csv_in = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/gene_clustering_{family}.csv\"\n",
    "    df = pd.read_csv(csv_in)\n",
    "\n",
    "    # 2) Auto-name each cluster\n",
    "    cluster_name = {}\n",
    "    species_combo_counts = {}\n",
    "\n",
    "    for cid, grp in df.groupby('cluster'):\n",
    "        # prefer non-LOC genes\n",
    "        non_loc = grp[~grp['gene_name'].str.startswith('LOC')]\n",
    "        if not non_loc.empty:\n",
    "            # take the shortest prefix before first '_'\n",
    "            prefs = non_loc['gene_name'].str.partition('_')[0]\n",
    "            base = prefs.loc[prefs.str.len().idxmin()]\n",
    "        else:\n",
    "            # fallback: name by species combination\n",
    "            combo = \"_\".join(sorted(grp['species'].unique()))\n",
    "            cnt = species_combo_counts.get(combo, 0) + 1\n",
    "            species_combo_counts[combo] = cnt\n",
    "            base = f\"{combo}_cluster{cnt}\"\n",
    "\n",
    "        cluster_name[cid] = base\n",
    "\n",
    "    # 3)  big clusters keep the base name\n",
    "    sizes = df.groupby('cluster').size().to_dict()\n",
    "    dups = defaultdict(list)\n",
    "    for cid, name in cluster_name.items():\n",
    "        dups[name].append(cid)\n",
    "\n",
    "    for name, cids in dups.items():\n",
    "        if len(cids) > 1:\n",
    "            # largest cluster keeps the base name\n",
    "            cids.sort(key=lambda x: sizes[x], reverse=True)\n",
    "            for idx, cid in enumerate(cids[1:], start=2):\n",
    "                cluster_name[cid] = f\"{name}_{idx}\"\n",
    "\n",
    "    # 4) Map back and save\n",
    "    df['cluster_name'] = df['cluster'].map(cluster_name)\n",
    "    out_csv = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/{family}_clusters_named_auto.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"  • Saved auto-named clusters → {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e31494-f1b8-4097-aa89-dd59edb6a54b",
   "metadata": {},
   "source": [
    "## Show the cluster counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c8affeb-c5b9-4837-867b-eed293dd6a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Building species×cluster matrix for 'CSF2RA'\n",
      "  • Saved species×cluster counts → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/species_cluster_counts_CSF2RA.csv\n"
     ]
    }
   ],
   "source": [
    "for family in families:\n",
    "    print(f\"\\n→ Building species×cluster matrix for {family!r}\")\n",
    "\n",
    "    # 1) load the named‐cluster table\n",
    "    in_csv = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/{family}_clusters_named_auto.csv\"\n",
    "    df = pd.read_csv(in_csv)\n",
    "\n",
    "    # 2) count genes per (species, cluster)\n",
    "    grouped = (df.groupby(['species', 'cluster_name']).size().reset_index(name='count'))\n",
    "\n",
    "    # 3) pivot\n",
    "    cluster_species_df = (grouped.pivot(index='species', columns='cluster_name', values='count').fillna(0).sort_index().sort_index(axis=1))\n",
    "\n",
    "    # 4) save\n",
    "    #print(cluster_species_df)  # or display(...) in Jupyter\n",
    "    out_csv = (f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/species_cluster_counts_{family}.csv\")\n",
    "    cluster_species_df.to_csv(out_csv)\n",
    "    print(f\"  • Saved species×cluster counts → {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06084e1e-4cee-4c7c-9747-8b5ff2d3c2d7",
   "metadata": {},
   "source": [
    "## Subset the fasta file of a gene family into its clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0375ec81-02bb-4281-b92f-38c5d77a50d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing family 'CSF2RA'\n",
      "  Cluster: CSF2RA, Number of genes: 7\n",
      "  Cluster: CSF2RA_2, Number of genes: 1\n",
      "  Cluster: PonPyg_cluster1, Number of genes: 1\n",
      "  Loaded 9 FASTA records\n",
      "    • Wrote 7 records → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/cluster_fastas/CSF2RA_cluster_CSF2RA.fa\n",
      "    • Wrote 1 records → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/cluster_fastas/CSF2RA_cluster_CSF2RA_2.fa\n",
      "    • Wrote 1 records → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/cluster_fastas/CSF2RA_cluster_PonPyg_cluster1.fa\n"
     ]
    }
   ],
   "source": [
    "for family in families:\n",
    "    print(f\"\\n→ Processing family {family!r}\")\n",
    "\n",
    "    # 1) Load the auto‐named clusters table\n",
    "    csv_in = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/{family}_clusters_named_auto.csv\"\n",
    "    df = pd.read_csv(csv_in)\n",
    "\n",
    "    # 2) Build the cluster→genes map\n",
    "    cluster_to_genes = df.groupby(\"cluster_name\")[\"gene_name\"].apply(list).to_dict()\n",
    "\n",
    "    #  summary\n",
    "    for cluster, genes in cluster_to_genes.items():\n",
    "        print(f\"  Cluster: {cluster}, Number of genes: {len(genes)}\")\n",
    "\n",
    "    # 3) Load the full family FASTA \n",
    "    fasta_in = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/all_species_{family}.fa\"\n",
    "    records = list(SeqIO.parse(fasta_in, \"fasta\"))\n",
    "    record_dict = {rec.id: rec for rec in records}\n",
    "    print(f\"  Loaded {len(record_dict)} FASTA records\")\n",
    "\n",
    "    # 4) Make output dir for per‐cluster FASTAs\n",
    "    cluster_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_fastas\"\n",
    "    os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "    # 5) Write one FASTA per cluster\n",
    "    for cluster, gene_list in cluster_to_genes.items():\n",
    "        selected = [record_dict[g] for g in gene_list if g in record_dict]\n",
    "        out_fa = f\"{cluster_dir}/{family}_cluster_{cluster}.fa\"\n",
    "        SeqIO.write(selected, out_fa, \"fasta\")\n",
    "        print(f\"    • Wrote {len(selected)} records → {out_fa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbd0f6-a98d-4e9f-9b28-2af88c61c8a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94cd63c1-d929-4c23-b9d2-ff7793e9c993",
   "metadata": {},
   "source": [
    "##  Make sure the correct gene names are in the coordinate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b4e827e-0440-4b36-a0e8-00c317c4102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Updating gene details for family 'CSF2RA'\n",
      "  9 rows after merge (with new ‘cluster’ col)\n",
      "  • Saved → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/CSF2RA_compl_gene_details_updated_with_palindromes_coordinates.tsv\n"
     ]
    }
   ],
   "source": [
    "# 1) Read once and filter out everything with no gene_family_symbol\n",
    "gene_details_file = f\"{work_dir}/protein_extracted_longest/clusters_merged/gene_details_updated_with_palindromes_coordinates.tsv\"\n",
    "\n",
    "master_df = pd.read_csv(gene_details_file, sep=\"\\t\")\n",
    "master_df = master_df.dropna(subset=[\"gene_family_symbol\"])\n",
    "\n",
    "# 2) Loop over each family\n",
    "for family in families:\n",
    "    print(f\"\\n→ Updating gene details for family {family!r}\")\n",
    "\n",
    "    # Load family's auto-named clusters\n",
    "    cluster_file = os.path.join(\n",
    "        data_dir,\n",
    "        \"sequences_y_updated\",\n",
    "        f\"{family}_selected_isoform\",\n",
    "        \"blastdb\",\n",
    "        f\"{family}_clusters_named_auto.csv\"\n",
    "    )\n",
    "    cluster_df = pd.read_csv(cluster_file, sep=\",\")\n",
    "\n",
    "    # Subset the master table to only genes in this family\n",
    "    filt = master_df[\n",
    "        master_df['gene_family_symbol'].str.contains(family, na=False)\n",
    "    ]\n",
    "\n",
    "    #  merge keys\n",
    "    cluster_df['gene_prefix'] = cluster_df['gene_name'].str.split('_').str[0]\n",
    "    mapping = cluster_df[['gene_prefix', 'species', 'cluster_name']]\n",
    "\n",
    "    # Merge on Gene_symbol + Species → gene_prefix + species\n",
    "    merged = filt.merge(\n",
    "        mapping,\n",
    "        left_on=['Gene_symbol', 'Species'],\n",
    "        right_on=['gene_prefix', 'species'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Rename and drop helper columns\n",
    "    merged.rename(columns={'cluster_name': 'cluster'}, inplace=True)\n",
    "    drop_cols = [c for c in ('gene_prefix', 'species_y') if c in merged.columns]\n",
    "    if drop_cols:\n",
    "        merged.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    print(f\"  {len(merged)} rows after merge (with new ‘cluster’ col)\")\n",
    "\n",
    "    # Write out the updated table\n",
    "    out_tsv = os.path.join(\n",
    "        data_dir,\n",
    "        \"sequences_y_updated\",\n",
    "        f\"{family}_selected_isoform\",\n",
    "        \"blastdb\",\n",
    "        f\"{family}_compl_gene_details_updated_with_palindromes_coordinates.tsv\"\n",
    "    )\n",
    "    merged.to_csv(out_tsv, sep=\"\\t\", index=False)\n",
    "    print(f\"  • Saved → {out_tsv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d033ea4d-9620-4c0d-bad2-5ca28cbe0d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Wrote combined table with cluster info for all families → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/all_families_gene_details_with_clusters.tsv\n"
     ]
    }
   ],
   "source": [
    "## one big file with all the information\n",
    "\n",
    "# 1) Load & pre-filter your master gene_details\n",
    "gene_details_file = f\"{work_dir}/protein_extracted_longest/clusters_merged/gene_details_updated_with_palindromes_coordinates.tsv\"\n",
    "\n",
    "master_df = pd.read_csv(gene_details_file, sep=\"\\t\")\n",
    "master_df = master_df.dropna(subset=[\"gene_family_symbol\"])\n",
    "\n",
    "\n",
    "# 2) Collect all per‐family cluster maps into one DataFrame\n",
    "maps = []\n",
    "for family in families:\n",
    "    fn = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/{family}_clusters_named_auto.csv\"\n",
    "    if not os.path.exists(fn):\n",
    "        print(f\"[!] missing cluster file for {family}, skipping\")\n",
    "        continue\n",
    "\n",
    "    cf = pd.read_csv(fn)\n",
    "    cf[\"gene_prefix\"] = cf[\"gene_name\"].str.split(\"_\").str[0]\n",
    "    maps.append(cf[[\"gene_prefix\", \"species\", \"cluster_name\"]].rename(\n",
    "        columns={\"species\": \"Species\", \"cluster_name\": \"cluster\"}\n",
    "    ))\n",
    "\n",
    "# one big mapping table\n",
    "map_df = pd.concat(maps, ignore_index=True).drop_duplicates(\n",
    "    subset=[\"gene_prefix\", \"Species\"]\n",
    ")\n",
    "\n",
    "# Merge once onto master_df\n",
    "merged_all = master_df.merge(map_df,\n",
    "    left_on=[\"Gene_symbol\", \"Species\"],\n",
    "    right_on=[\"gene_prefix\", \"Species\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# clean up helper columns\n",
    "if \"gene_prefix\" in merged_all.columns:\n",
    "    merged_all.drop(columns=[\"gene_prefix\"], inplace=True)\n",
    "\n",
    "# Save table\n",
    "out_file = f\"{data_dir}/sequences_y_updated/all_families_gene_details_with_clusters.tsv\"\n",
    "\n",
    "merged_all.to_csv(out_file, sep=\"\\t\", index=False)\n",
    "print(f\"→ Wrote combined table with cluster info for all families → {out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726fa19-d55c-4c8f-bbe3-8721c3c5144c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40fc278a-bd72-450d-9aff-4d6897868be8",
   "metadata": {},
   "source": [
    "## Do MEGA analysis dN & dS calculation per cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f6745-a866-4feb-8811-219b481a2e85",
   "metadata": {},
   "source": [
    "### Define all the clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76e5b9f3-0908-4b6e-b3f9-8c578e707507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSF2RA: keeping 1 clusters\n"
     ]
    }
   ],
   "source": [
    "cluster_list_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    # ensure the alignments directory exists\n",
    "    cluster_alignments = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "    os.makedirs(cluster_alignments, exist_ok=True)\n",
    "\n",
    "    # grab every .fa basename in the cluster_fastas dir\n",
    "    cluster_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_fastas\"\n",
    "    all_clusters = [\n",
    "        os.path.splitext(fn)[0]\n",
    "        for fn in os.listdir(cluster_dir)\n",
    "        if fn.endswith(\".fa\")\n",
    "    ]\n",
    "\n",
    "    # filter out FASTAs with only one sequence\n",
    "    filtered = []\n",
    "    for name in all_clusters:\n",
    "        path = os.path.join(cluster_dir, f\"{name}.fa\")\n",
    "        with open(path) as f:\n",
    "            nseq = sum(1 for line in f if line.startswith(\">\"))\n",
    "        if nseq > 1:\n",
    "            filtered.append(name)\n",
    "\n",
    "    for name in filtered:\n",
    "        path = os.path.join(cluster_dir, f\"{name}.fa\")\n",
    "        seen, dups = set(), set()\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\">\"):\n",
    "                    seqid = line[1:].split()[0]\n",
    "                    if seqid in seen:\n",
    "                        dups.add(seqid)\n",
    "                    else:\n",
    "                        seen.add(seqid)\n",
    "        if dups:\n",
    "            print(f\"[{family}] {name}.fa has duplicate IDs: {', '.join(dups)}\")\n",
    "\n",
    "    # store the filtered list for later\n",
    "    cluster_list_per_family[family] = filtered\n",
    "\n",
    "    print(f\"{family}: keeping {len(filtered)} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc2730-cf2c-4e2d-93f1-0900e50de9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6166fcd6-e4d1-4920-a1ef-479c6be38e81",
   "metadata": {},
   "source": [
    "### Make a Codon based Multi-Sequence Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7b78ed5d-a4c4-47c5-9ca6-141dd530feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Aligning 1 clusters for family 'CSF2RA'\n",
      "→ Done family 'CSF2RA'\n"
     ]
    }
   ],
   "source": [
    "### Make a codon-based alignment\n",
    "# STEP 1: Align with MACSE\n",
    "\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "    \n",
    "for family, cluster_list in cluster_list_per_family.items():\n",
    "    print(f\"\\n→ Aligning {len(cluster_list)} clusters for family {family!r}\")\n",
    "    cluster_alignments = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "\n",
    "    for cluster in cluster_list:\n",
    "        cmd = (\n",
    "            f\"macse -prog alignSequences \"\n",
    "            f\"-seq {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_fastas/{cluster}.fa \"\n",
    "            f\"-out_NT {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-out_AA {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_AA.fa\"\n",
    "        )\n",
    "        subprocess.run(cmd, shell=True, check=True,stdout=subprocess.DEVNULL,stderr=subprocess.DEVNULL)\n",
    "\n",
    "    print(f\"→ Done family {family!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb502220-f599-4759-893f-eae6126e42b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Aligning 1 clusters for family 'CSF2RA'\n",
      "→ Done family 'CSF2RA'\n"
     ]
    }
   ],
   "source": [
    "## refine alignment in MACSE \n",
    "## to make the alignment better \n",
    "# run secondly+ seperately!! takes very long to run it at the same time\n",
    "\n",
    "for family, cluster_list in cluster_list_per_family.items():\n",
    "    print(f\"\\n→ Aligning {len(cluster_list)} clusters for family {family!r}\")\n",
    "    cluster_alignments = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "\n",
    "    # # Refine made alignment: for alignments that are difficult\n",
    "    for cluster in cluster_list:\n",
    "         cmd = (\n",
    "             f\"macse -prog refineAlignment \"\n",
    "             f\"-align {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "             f\"-out_NT {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "             f\"-out_AA {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_AA.fa\"\n",
    "         )\n",
    "         subprocess.run(cmd, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # run quietly \n",
    "    \n",
    "    print(f\"→ Done family {family!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86197499-f0e3-465d-a71f-70fd7863fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Aligning 1 clusters for family 'CSF2RA'\n",
      "→ Done family 'CSF2RA'\n"
     ]
    }
   ],
   "source": [
    "## clean alignment in MACSE \n",
    "## to make the alignment useable for after \n",
    "\n",
    "for family, cluster_list in cluster_list_per_family.items():\n",
    "    print(f\"\\n→ Aligning {len(cluster_list)} clusters for family {family!r}\")\n",
    "    cluster_alignments = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "\n",
    "    # # clean alignments with stopcodons in the middle of the sequence (MACSE output \"!\" with frameshift/stop codons. Replace by \"NNN\" for analysis:)\n",
    "    for cluster in cluster_list:\n",
    "         cmd = (\n",
    "             f\"macse -prog exportAlignment \"\n",
    "             f\"-align {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "             f\"-codonForInternalStop NNN \"\n",
    "             f\"-codonForInternalFS --- \"\n",
    "             f\"-charForRemainingFS --- \"\n",
    "             f\"-out_NT {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "             f\"-out_AA {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_AA.fa\"\n",
    "         )\n",
    "         subprocess.run(cmd, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # run quietly \n",
    "    \n",
    "    print(f\"→ Done family {family!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea14aa5-dd33-4a8d-af0d-7c5988f0fd1b",
   "metadata": {},
   "source": [
    "### Calculate dN & dS and N & S counts for each pairwise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "705d677f-72fb-4fd0-bbd2-164cdd402c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate SYNonymous substitutions rate\n",
    "# Modified Nei-Gojobori with complete deletion\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dS\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    # 2) list of clusters for this family\n",
    "    clusters = cluster_list_per_family[family]\n",
    "\n",
    "    # 3) megacc command for each cluster\n",
    "    for cluster in clusters:\n",
    "        cmd = (\n",
    "            f\"megacc \"\n",
    "            f\"-a {data_dir}/gene_family/sequences/MAGE_isoform_X1/blastdb/compute_ds_modNG_compldel.mao \"\n",
    "            f\"-d {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-o {ds_dir}/{cluster}\"\n",
    "        )\n",
    "        subprocess.run(cmd,shell=True, check=True,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1d8b4fd-822c-4e3c-9889-6506c23ced93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate NONsynonymous substitutions rate\n",
    "# Modified Nei-Gojobori with complete deletion\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dN\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    # 2) list of clusters for this family\n",
    "    clusters = cluster_list_per_family[family]\n",
    "\n",
    "    # 3) megacc command for each cluster\n",
    "    for cluster in clusters:\n",
    "        cmd = (\n",
    "            f\"megacc \"\n",
    "            f\"-a {data_dir}/gene_family/sequences/MAGE_isoform_X1/blastdb/compute_dN_modNG_compldel.mao \"\n",
    "            f\"-d {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-o {ds_dir}/{cluster}\"\n",
    "        )\n",
    "        subprocess.run(cmd,shell=True, check=True,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2c8ad309-64fc-4451-bc47-f2c58666c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate SYNonymous substitution COUNTS\n",
    "#actual counts of synonymous differences\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_syn_count\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    # 2) list of clusters for this family\n",
    "    clusters = cluster_list_per_family[family]\n",
    "\n",
    "    # 3) megacc command for each cluster\n",
    "    for cluster in clusters:\n",
    "        cmd = (\n",
    "            f\"megacc \"\n",
    "            f\"-a {data_dir}/gene_family/sequences/MAGE_isoform_X1/blastdb/compute_syn_count_modNG_compldel.mao \"\n",
    "            f\"-d {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-o {ds_dir}/{cluster}\"\n",
    "        )\n",
    "        subprocess.run(cmd,shell=True, check=True,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "783253c8-5454-490f-a331-e633e095cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate NONSYNonymous substitution COUNTS\n",
    "#actual counts of nonsynonymous differences\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_nonsyn_count\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    # 2) list of clusters for this family\n",
    "    clusters = cluster_list_per_family[family]\n",
    "\n",
    "    # 3) megacc command for each cluster\n",
    "    for cluster in clusters:\n",
    "        cmd = (\n",
    "            f\"megacc \"\n",
    "            f\"-a {data_dir}/gene_family/sequences/MAGE_isoform_X1/blastdb/compute_nonsyn_count_modNG_compldel.mao \"\n",
    "            f\"-d {data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-o {ds_dir}/{cluster}\"\n",
    "        )\n",
    "        subprocess.run(cmd,shell=True, check=True,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ea256-5455-4ed9-a7f0-d8d13bd32698",
   "metadata": {},
   "source": [
    "### Turn .meg files into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ae73b078-be73-4c66-aaea-1df19c2911e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser \n",
    "def parse_meg_file(path: Path) -> pd.DataFrame:\n",
    "    text = path.read_text().splitlines()\n",
    "    labels = []\n",
    "    for line in text:\n",
    "        s = line.strip()\n",
    "        if re.match(r\"^\\[\\s*\\d\", s) and \"#\" not in s:\n",
    "            break\n",
    "        m = re.match(r\"^\\[\\s*(\\d+)\\]\\s*#\\s*(.+)$\", s)\n",
    "        if m:\n",
    "            labels.append(m.group(2).strip())\n",
    "    n = len(labels)\n",
    "    full = np.zeros((n, n), float)\n",
    "    for line in text:\n",
    "        s = line.strip()\n",
    "        m = re.match(r\"^\\[\\s*(\\d+)\\]\\s*(.*)$\", s)\n",
    "        if not m: continue\n",
    "        i = int(m.group(1))\n",
    "        if not (1 <= i <= n): continue\n",
    "        rest = m.group(2)\n",
    "        nums = re.findall(r\"[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?\", rest)\n",
    "        if len(nums) != i - 1: continue\n",
    "        for k, tok in enumerate(nums):\n",
    "            j = k + 1\n",
    "            v = float(tok)\n",
    "            full[i-1, j-1] = full[j-1, i-1] = v\n",
    "    np.fill_diagonal(full, 0.0)\n",
    "    df = pd.DataFrame(full, index=labels, columns=labels)\n",
    "    mask = np.tril(np.ones(df.shape, bool), k=-1)\n",
    "    return df.where(mask)\n",
    "\n",
    "# base data directory\n",
    "data_dir = Path(\"/home/emma/Amplicons/Workspaces/emma/downloaded_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4c74c6ac-61dd-4ad3-8350-42ef638c8189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing dS matrices for family 'CSF2RA'\n"
     ]
    }
   ],
   "source": [
    "# the per‐family loop SYNONYMOUS RATE\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing dS matrices for family {family!r}\")\n",
    "    \n",
    "    in_dir  = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dS\"\n",
    "    out_dir = in_dir / \"matrix_csvs\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for meg in sorted(in_dir.glob(\"*.meg\")):\n",
    "        df_lower = parse_meg_file(meg)\n",
    "        out_file = out_dir / f\"{meg.stem}_dS.csv\"\n",
    "        df_lower.to_csv(out_file)\n",
    "        #print(f\"   • wrote {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "58f43800-20ef-42e7-8d38-78b997b96316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing dN matrices for family 'CSF2RA'\n"
     ]
    }
   ],
   "source": [
    "# the per‐family loop NONSYNONYMOUS RATE\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing dN matrices for family {family!r}\")\n",
    "    \n",
    "    in_dir  = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dN\"\n",
    "    out_dir = in_dir / \"matrix_csvs\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for meg in sorted(in_dir.glob(\"*.meg\")):\n",
    "        df_lower = parse_meg_file(meg)\n",
    "        out_file = out_dir / f\"{meg.stem}_dN.csv\"\n",
    "        df_lower.to_csv(out_file)\n",
    "        #print(f\"   • wrote {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1ab2c0e3-86d5-4fc4-a73c-ebc312418932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing dS matrices for family 'CSF2RA'\n"
     ]
    }
   ],
   "source": [
    "#  the per‐family loop SYNONYMOUS RATE\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing dS matrices for family {family!r}\")\n",
    "    \n",
    "    in_dir  = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_syn_count\"\n",
    "    out_dir = in_dir / \"matrix_csvs\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for meg in sorted(in_dir.glob(\"*.meg\")):\n",
    "        df_lower = parse_meg_file(meg)\n",
    "        out_file = out_dir / f\"{meg.stem}_S_count.csv\"\n",
    "        df_lower.to_csv(out_file)\n",
    "        #print(f\"   • wrote {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d71e89da-aa2b-45a7-ba68-22e5bf3227e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing dS matrices for family 'CSF2RA'\n"
     ]
    }
   ],
   "source": [
    "# now, the per‐family loop NONSYNONYMOUS RATE\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing dS matrices for family {family!r}\")\n",
    "    \n",
    "    in_dir  = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_nonsyn_count\"\n",
    "    out_dir = in_dir / \"matrix_csvs\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for meg in sorted(in_dir.glob(\"*.meg\")):\n",
    "        df_lower = parse_meg_file(meg)\n",
    "        out_file = out_dir / f\"{meg.stem}_N_count.csv\"\n",
    "        df_lower.to_csv(out_file)\n",
    "        #print(f\"   • wrote {out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec97d9df-2a31-4cee-a008-7d208fe4a2b8",
   "metadata": {},
   "source": [
    "### Combine all the synonymous and nonsynonymous tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e5e3e2b0-fc61-421e-aae5-214811615124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the number of codons \n",
    "def get_num_sites(cluster):\n",
    "    \"\"\"\n",
    "    Try to pull the reported “No. of Sites=” from the .meg file.\n",
    "    If that fails, parse the alignment itself and return length/3.\n",
    "    \"\"\"\n",
    "    meg_path = (\n",
    "        data_dir\n",
    "        / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dN\"\n",
    "        / f\"{family}_cluster_{cluster}.meg\"\n",
    "    )\n",
    "    text = meg_path.read_text()\n",
    "    m = re.search(r\"No\\.?\\s*of\\s*Sites\\s*=\\s*(\\d+)\", text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    try:\n",
    "        aln = AlignIO.read(str(meg_path), \"mega\")\n",
    "        return aln.get_alignment_length() // 3\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b3582-8f83-4888-bd43-297af1bb7ece",
   "metadata": {},
   "source": [
    "### Between species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c83d8a1b-f9b3-4950-8fb3-d6b5ebb24b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing between‐species stats for family CSF2RA\n",
      "  Found clusters: ['CSF2RA']\n",
      "  → saved /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/CSF2RA_dN_dS_betweenspecies.tsv\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing between‐species stats for family {family}\")\n",
    "\n",
    "    # 1) define syn/nonsyn CSV directories\n",
    "    syn_dir    = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dS/matrix_csvs\"\n",
    "    nonsyn_dir = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dN/matrix_csvs\"\n",
    "\n",
    "    # 2) cluster IDs\n",
    "    clusters = []\n",
    "    for f in syn_dir.glob(f\"{family}_cluster_*_dS.csv\"):\n",
    "        m = re.match(rf\"{family}_cluster_(.+)_dS\\.csv\", f.name)\n",
    "        if m:\n",
    "            clusters.append(m.group(1))\n",
    "    clusters = sorted(set(clusters))\n",
    "    print(\"  Found clusters:\", clusters)\n",
    "\n",
    "    # compute stats for a species pair in a lower‐triangle df\n",
    "    def pair_stats(df, a, b):\n",
    "        r = df.index.to_series().str.contains\n",
    "        c = df.columns.to_series().str.contains\n",
    "        mask = np.outer(r(a), c(b)) | np.outer(r(b), c(a))\n",
    "        vals = df.where(mask).stack()\n",
    "        return vals.mean(), vals.std(ddof=1)\n",
    "\n",
    "    # 3) load syn/nonsyn matrices and compute mean/SD\n",
    "    records = []\n",
    "    for cluster in clusters:\n",
    "        syn_df    = (pd.read_csv(syn_dir/f\"{family}_cluster_{cluster}_dS.csv\", index_col=0)\n",
    "                       .sort_index().sort_index(axis=1))\n",
    "        nonsyn_df = (pd.read_csv(nonsyn_dir/f\"{family}_cluster_{cluster}_dN.csv\", index_col=0)\n",
    "                       .sort_index().sort_index(axis=1))\n",
    "        for sp1, sp2 in itertools.combinations(species_list, 2):\n",
    "            m_s, sd_s = pair_stats(syn_df,    sp1, sp2)\n",
    "            m_n, sd_n = pair_stats(nonsyn_df, sp1, sp2)\n",
    "            records.append({\n",
    "                \"Cluster\":      cluster,\n",
    "                \"Species1\":     sp1,\n",
    "                \"Species2\":     sp2,\n",
    "                \"Mean_Syn\":     m_s,\n",
    "                \"SD_Syn\":       sd_s,\n",
    "                \"Mean_Nonsyn\":  m_n,\n",
    "                \"SD_Nonsyn\":    sd_n\n",
    "            })\n",
    "\n",
    "    master = pd.DataFrame(records)\n",
    "    cols = [\"Mean_Syn\",\"SD_Syn\",\"Mean_Nonsyn\",\"SD_Nonsyn\"]\n",
    "    master_clean = master.dropna(subset=cols, how=\"all\")\n",
    "\n",
    "    # 4) pull “No. of Sites” (codons) from each cluster's .meg\n",
    "    site_map = {cl: get_num_sites(cl) for cl in master_clean[\"Cluster\"].unique()}\n",
    "    master_clean[\"No_of_Codon\"] = master_clean[\"Cluster\"].map(site_map)\n",
    "\n",
    "    # 5) compute dN/dS ratio\n",
    "    master_clean[\"dNdS\"] = master_clean[\"Mean_Nonsyn\"] / master_clean[\"Mean_Syn\"]\n",
    "\n",
    "    # 6) annotate copy‐numbers\n",
    "    counts_csv = (\n",
    "        data_dir\n",
    "        / f\"sequences_y_updated/{family}_selected_isoform/blastdb/species_cluster_counts_{family}.csv\"\n",
    "    )\n",
    "    counts_df = pd.read_csv(counts_csv).set_index(\"species\")\n",
    "    master_clean[\"Species1_num_copies\"] = [\n",
    "        counts_df.at[s, c]\n",
    "        for s, c in zip(master_clean[\"Species1\"], master_clean[\"Cluster\"])\n",
    "    ]\n",
    "    master_clean[\"Species2_num_copies\"] = [\n",
    "        counts_df.at[s, c]\n",
    "        for s, c in zip(master_clean[\"Species2\"], master_clean[\"Cluster\"])\n",
    "    ]\n",
    "\n",
    "    # 7) build S/N counts table and merge\n",
    "    rec2 = []\n",
    "    syn_cnt_dir    = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_syn_count/matrix_csvs\"\n",
    "    nonsyn_cnt_dir = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_nonsyn_count/matrix_csvs\"\n",
    "    for cluster in clusters:\n",
    "        s_df = (pd.read_csv(syn_cnt_dir/f\"{family}_cluster_{cluster}_S_count.csv\", index_col=0)\n",
    "                  .sort_index().sort_index(axis=1))\n",
    "        n_df = (pd.read_csv(nonsyn_cnt_dir/f\"{family}_cluster_{cluster}_N_count.csv\", index_col=0)\n",
    "                  .sort_index().sort_index(axis=1))\n",
    "        for sp1, sp2 in itertools.combinations(species_list, 2):\n",
    "            ms, ss = pair_stats(s_df, sp1, sp2)\n",
    "            mn, sn = pair_stats(n_df, sp1, sp2)\n",
    "            rec2.append({\n",
    "                \"Cluster\":           cluster,\n",
    "                \"Species1\":          sp1,\n",
    "                \"Species2\":          sp2,\n",
    "                \"Mean_Syn_count\":    ms,\n",
    "                \"SD_Syn_count\":      ss,\n",
    "                \"Mean_Nonsyn_count\": mn,\n",
    "                \"SD_Nonsyn_count\":   sn\n",
    "            })\n",
    "\n",
    "    counts_total = (\n",
    "        pd.DataFrame(rec2)\n",
    "        .dropna(subset=[\"Mean_Syn_count\",\"SD_Syn_count\",\"Mean_Nonsyn_count\",\"SD_Nonsyn_count\"], how=\"all\")\n",
    "    )\n",
    "\n",
    "    final = (\n",
    "        master_clean\n",
    "        .merge(counts_total, on=[\"Cluster\",\"Species1\",\"Species2\"], how=\"left\")\n",
    "        .round(4)\n",
    "    )\n",
    "    final[[\"Species1_num_copies\",\"Species2_num_copies\"]] = final[[\"Species1_num_copies\",\"Species2_num_copies\"]].astype(int)\n",
    "\n",
    "    # 8) compute “potential synonymous sites” and adjusted dN/dS\n",
    "    final[\"pot_syn_sites\"] = final[\"Mean_Syn_count\"] / final[\"Mean_Syn\"]\n",
    "    final[\"adj_dNdS\"]      = (final[\"Mean_Nonsyn\"]) / (\n",
    "        (final[\"Mean_Syn_count\"] + 1) / final[\"pot_syn_sites\"]\n",
    "    )\n",
    "    \n",
    "    # 9) save\n",
    "    out_tsv = (\n",
    "        data_dir\n",
    "        / f\"sequences_y_updated/{family}_selected_isoform/blastdb/{family}_dN_dS_betweenspecies.tsv\"\n",
    "    )\n",
    "    final.to_csv(out_tsv, sep=\"\\t\", index=False)\n",
    "    print(f\"  → saved {out_tsv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a11b15-6a34-46f2-bc63-ceec140adf12",
   "metadata": {},
   "source": [
    "### Within species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b700e508-cfd5-4eb5-8250-66ef10c95891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Within‐species summary for family 'CSF2RA'\n",
      "  clusters: ['CSF2RA']\n",
      "  • saved combined within‐species table → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/CSF2RA_selected_isoform/blastdb/CSF2RA_dN_dS_withinspecies.tsv\n"
     ]
    }
   ],
   "source": [
    "for family in families:\n",
    "    print(f\"\\n→ Within‐species summary for family {family!r}\")\n",
    "\n",
    "    # 1) Directories for dS and dN matrices\n",
    "    syn_dir    = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dS/matrix_csvs\"\n",
    "    nonsyn_dir = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_dN/matrix_csvs\"\n",
    "\n",
    "    # 2) cluster IDs from the dS filenames\n",
    "    clusters = sorted({\n",
    "        re.match(rf\"{family}_cluster_(.+)_dS\\.csv\", p.name).group(1)\n",
    "        for p in syn_dir.glob(f\"{family}_cluster_*_dS.csv\")\n",
    "        if re.match(rf\"{family}_cluster_(.+)_dS\\.csv\", p.name)\n",
    "    })\n",
    "    print(\"  clusters:\", clusters)\n",
    "\n",
    "    # get mean & SD for a species in a lower‐triangle matrix\n",
    "    def pair_stats(df, a, b):\n",
    "        idx0 = df.index.to_series().str.contains\n",
    "        idx1 = df.columns.to_series().str.contains\n",
    "        mask = np.outer(idx0(a), idx1(b)) | np.outer(idx0(b), idx1(a))\n",
    "        vals = df.where(mask).stack()\n",
    "        return vals.mean(), vals.std(ddof=1)\n",
    "\n",
    "    # 3) Build within‐species dS/dN rates table\n",
    "    rate_records = []\n",
    "    for cluster in clusters:\n",
    "        s_df = (pd.read_csv(syn_dir/f\"{family}_cluster_{cluster}_dS.csv\", index_col=0)\n",
    "                  .sort_index().sort_index(axis=1))\n",
    "        n_df = (pd.read_csv(nonsyn_dir/f\"{family}_cluster_{cluster}_dN.csv\", index_col=0)\n",
    "                  .sort_index().sort_index(axis=1))\n",
    "        for sp in species_list:\n",
    "            m_s, sd_s = pair_stats(s_df, sp, sp)\n",
    "            m_n, sd_n = pair_stats(n_df, sp, sp)\n",
    "            rate_records.append({\n",
    "                \"Cluster\":      cluster,\n",
    "                \"Species\":      sp,\n",
    "                \"Mean_Syn\":     m_s,\n",
    "                \"SD_Syn\":       sd_s,\n",
    "                \"Mean_Nonsyn\":  m_n,\n",
    "                \"SD_Nonsyn\":    sd_n\n",
    "            })\n",
    "    within_rates = pd.DataFrame(rate_records).dropna(\n",
    "        subset=[\"Mean_Syn\",\"SD_Syn\",\"Mean_Nonsyn\",\"SD_Nonsyn\"],\n",
    "        how=\"all\"\n",
    "    )\n",
    "\n",
    "    # 4) Extract “No. of Sites” (codons) from each cluster’s .meg\n",
    "    site_map = {c: get_num_sites(c) for c in within_rates[\"Cluster\"].unique()}\n",
    "    within_rates[\"No_of_Codon\"] = within_rates[\"Cluster\"].map(site_map)\n",
    "\n",
    "    # 5) Compute dN/dS ratio\n",
    "    within_rates[\"dNdS\"] = within_rates[\"Mean_Nonsyn\"] / within_rates[\"Mean_Syn\"]\n",
    "\n",
    "    # 6) Annotate copy‐number from species×cluster counts\n",
    "    cnt_csv = (data_dir\n",
    "               / f\"sequences_y_updated/{family}_selected_isoform/blastdb/\"\n",
    "               / f\"species_cluster_counts_{family}.csv\")\n",
    "    cnt_df = pd.read_csv(cnt_csv).set_index(\"species\")\n",
    "    within_rates[\"num_copies\"] = [\n",
    "        cnt_df.at[row.Species, row.Cluster]\n",
    "        for _, row in within_rates.iterrows()\n",
    "    ]\n",
    "\n",
    "    # 7) Build within‐species raw count table (S_count / N_count)\n",
    "    count_records = []\n",
    "    syn_cnt_dir    = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_syn_count/matrix_csvs\"\n",
    "    nonsyn_cnt_dir = data_dir / f\"sequences_y_updated/{family}_selected_isoform/blastdb/cluster_nonsyn_count/matrix_csvs\"\n",
    "    for cluster in clusters:\n",
    "        sf = syn_cnt_dir   / f\"{family}_cluster_{cluster}_S_count.csv\"\n",
    "        nf = nonsyn_cnt_dir/ f\"{family}_cluster_{cluster}_N_count.csv\"\n",
    "        if not (sf.exists() and nf.exists()):\n",
    "            print(f\"  ⚠ skipping counts for {cluster}: missing file\")\n",
    "            continue\n",
    "        s_df = pd.read_csv(sf, index_col=0).sort_index().sort_index(axis=1)\n",
    "        n_df = pd.read_csv(nf, index_col=0).sort_index().sort_index(axis=1)\n",
    "        for sp in species_list:\n",
    "            ms, ss = pair_stats(s_df, sp, sp)\n",
    "            mn, sn = pair_stats(n_df, sp, sp)\n",
    "            count_records.append({\n",
    "                \"Cluster\":           cluster,\n",
    "                \"Species\":           sp,\n",
    "                \"Mean_Syn_count\":    ms,\n",
    "                \"SD_Syn_count\":      ss,\n",
    "                \"Mean_Nonsyn_count\": mn,\n",
    "                \"SD_Nonsyn_count\":   sn\n",
    "            })\n",
    "    within_counts = pd.DataFrame(count_records).dropna(\n",
    "        subset=[\"Mean_Syn_count\",\"SD_Syn_count\",\"Mean_Nonsyn_count\",\"SD_Nonsyn_count\"],\n",
    "        how=\"all\"\n",
    "    )\n",
    "\n",
    "    # 8) Merge rates + counts into one within‐species table\n",
    "    within_species = within_rates.merge(\n",
    "        within_counts,\n",
    "        on=[\"Cluster\",\"Species\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "     # 9) Round decimals to 4 places, integers for codons & copies\n",
    "    dec_cols = [\n",
    "        \"Mean_Syn\",\"SD_Syn\",\"Mean_Nonsyn\",\"SD_Nonsyn\",\n",
    "        \"Mean_Syn_count\",\"SD_Syn_count\",\n",
    "        \"Mean_Nonsyn_count\",\"SD_Nonsyn_count\",\"dNdS\"\n",
    "    ]\n",
    "    within_species[dec_cols] = within_species[dec_cols].round(4)\n",
    "    int_cols = [\"No_of_Codon\",\"num_copies\"]\n",
    "    within_species[int_cols] = within_species[int_cols].round(0).astype(int)\n",
    "\n",
    "    # 10) Save the combined table\n",
    "    out_file = (data_dir\n",
    "                / f\"sequences_y_updated/{family}_selected_isoform/blastdb/\"\n",
    "                / f\"{family}_dN_dS_withinspecies.tsv\")\n",
    "    within_species.to_csv(out_file, sep=\"\\t\", index=False)\n",
    "    print(f\"  • saved combined within‐species table → {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb91991-34cf-4074-8e3e-e5c52446aeec",
   "metadata": {},
   "source": [
    "### Combine all tables together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7db1a6a5-fbe1-4cf8-a4a2-d27725a3dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Wrote combined table with 15 rows to /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/all_families_dN_dS_betweenspecies.tsv\n"
     ]
    }
   ],
   "source": [
    "# BETWEEN SPECIES \n",
    "\n",
    "# 1) Read each per-family TSV, add a \"Family\" column, collect into a list\n",
    "tables = []\n",
    "for family in families:\n",
    "    path = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/{family}_dN_dS_betweenspecies.tsv\"\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    df[\"Family\"] = family\n",
    "    tables.append(df)\n",
    "\n",
    "# 2) Concatenate  all into one DataFrame\n",
    "combined = pd.concat(tables, ignore_index=True)\n",
    "\n",
    "# 3) Save \n",
    "out = f\"{data_dir}/sequences_y_updated/all_families_dN_dS_betweenspecies.tsv\"\n",
    "combined.to_csv(out, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"→ Wrote combined table with {len(combined)} rows to {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "17dbefcd-c0a1-4083-906f-1d02f630b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Wrote combined table with 1 rows to /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/all_families_dN_dS_withinspecies.tsv\n"
     ]
    }
   ],
   "source": [
    "# WITHIN SPECIES \n",
    "# 1) Read each per-family TSV, add a \"Family\" column, collect into a list\n",
    "tables = []\n",
    "for family in families:\n",
    "    path = f\"{data_dir}/sequences_y_updated/{family}_selected_isoform/blastdb/{family}_dN_dS_withinspecies.tsv\"\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    df[\"Family\"] = family\n",
    "    tables.append(df)\n",
    "\n",
    "# 2) Concatenate them all into one DataFrame\n",
    "combined = pd.concat(tables, ignore_index=True)\n",
    "\n",
    "# 3) Save \n",
    "out = f\"{data_dir}/sequences_y_updated/all_families_dN_dS_withinspecies.tsv\"\n",
    "combined.to_csv(out, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"→ Wrote combined table with {len(combined)} rows to {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659b778-a6c0-44ea-87a2-f2e0e4790078",
   "metadata": {},
   "source": [
    "## Merge dNdS dataframes with bootstrapped dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813fbc02-a584-4a71-9a04-68003a137f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/10751321/ipykernel_1505588/3233866660.py:31: RuntimeWarning: Mean of empty slice\n",
      "  mean_dnds = np.nanmean(ratios)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>cluster</th>\n",
       "      <th>species1</th>\n",
       "      <th>species2</th>\n",
       "      <th>dS_rates</th>\n",
       "      <th>dN_rates</th>\n",
       "      <th>dN_fraction_zeros</th>\n",
       "      <th>dS_fraction_zeros</th>\n",
       "      <th>mean_dNdS</th>\n",
       "      <th>mean_dN</th>\n",
       "      <th>mean_dS</th>\n",
       "      <th>dNdS_count_below1</th>\n",
       "      <th>dNdS_count_above1</th>\n",
       "      <th>frac_below1</th>\n",
       "      <th>frac_above1</th>\n",
       "      <th>frac_equal1</th>\n",
       "      <th>selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>CDY1_cluster_PonAbe_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>CDY1_cluster_MacFas_cluster1</td>\n",
       "      <td>MacFas</td>\n",
       "      <td>MacFas</td>\n",
       "      <td>0.00216435,0.00211715,0.00849678,0.00447861,0....</td>\n",
       "      <td>0.0024692,0.00500556,0.0,0.00245011,0.00751001...</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.889887</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>3508</td>\n",
       "      <td>6492</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.6492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>CDY1_cluster_CDY1</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>PanPan</td>\n",
       "      <td>0.028284592499999997,0.0302337325,0.024942645,...</td>\n",
       "      <td>0.012828775,0.013636295,0.01277519,0.010479885...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.687893</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>8824</td>\n",
       "      <td>1176</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>CDY1_cluster_CDY1</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>PanPan</td>\n",
       "      <td>0.01331115,0.03492027,0.0209043,0.02752504,0.0...</td>\n",
       "      <td>0.01061712,0.01363079,0.00968765,0.00911549,0....</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.459232</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>9765</td>\n",
       "      <td>235</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>CDY1_cluster_CDY1</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>0.020523384999999998,0.0186310075,0.0191644125...</td>\n",
       "      <td>0.01105862,0.01362904,0.011008205,0.0122820249...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.546812</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.022559</td>\n",
       "      <td>9532</td>\n",
       "      <td>468</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>isoenzyme</td>\n",
       "      <td>isoenzyme_cluster_PonAbe_PonPyg_cluster2</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>0.00122474,0.0,0.0012729133333333335,0.0012300...</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>6374</td>\n",
       "      <td>3626</td>\n",
       "      <td>0.6374</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>isoenzyme</td>\n",
       "      <td>isoenzyme_cluster_PonAbe_PonPyg_cluster2</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.00244948,0.0,0.002545826666666667,0.00246002...</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>6374</td>\n",
       "      <td>3626</td>\n",
       "      <td>0.6374</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>retrovirus</td>\n",
       "      <td>retrovirus_cluster_PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>retrovirus</td>\n",
       "      <td>retrovirus_cluster_PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>0.00130599,0.00262513,0.00138077,0.00543626,0....</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>TATA-box</td>\n",
       "      <td>TATA-box_cluster_SymSyn_cluster2</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>0.01259657,0.01264009,0.00247647,0.00503778,0....</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         family                                    cluster species1 species2  \\\n",
       "0          CDY1               CDY1_cluster_PonAbe_cluster1   PonAbe   PonAbe   \n",
       "1          CDY1               CDY1_cluster_MacFas_cluster1   MacFas   MacFas   \n",
       "2          CDY1                          CDY1_cluster_CDY1   HomSap   PanPan   \n",
       "3          CDY1                          CDY1_cluster_CDY1   GorGor   PanPan   \n",
       "4          CDY1                          CDY1_cluster_CDY1   GorGor   HomSap   \n",
       "..          ...                                        ...      ...      ...   \n",
       "185   isoenzyme   isoenzyme_cluster_PonAbe_PonPyg_cluster2   PonAbe   PonPyg   \n",
       "186   isoenzyme   isoenzyme_cluster_PonAbe_PonPyg_cluster2   PonAbe   PonAbe   \n",
       "187  retrovirus  retrovirus_cluster_PonAbe_PonPyg_cluster1   PonAbe   PonAbe   \n",
       "188  retrovirus  retrovirus_cluster_PonAbe_PonPyg_cluster1   PonAbe   PonPyg   \n",
       "189    TATA-box           TATA-box_cluster_SymSyn_cluster2   SymSyn   SymSyn   \n",
       "\n",
       "                                              dS_rates  \\\n",
       "0    0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....   \n",
       "1    0.00216435,0.00211715,0.00849678,0.00447861,0....   \n",
       "2    0.028284592499999997,0.0302337325,0.024942645,...   \n",
       "3    0.01331115,0.03492027,0.0209043,0.02752504,0.0...   \n",
       "4    0.020523384999999998,0.0186310075,0.0191644125...   \n",
       "..                                                 ...   \n",
       "185  0.00122474,0.0,0.0012729133333333335,0.0012300...   \n",
       "186  0.00244948,0.0,0.002545826666666667,0.00246002...   \n",
       "187  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....   \n",
       "188  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....   \n",
       "189  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....   \n",
       "\n",
       "                                              dN_rates  dN_fraction_zeros  \\\n",
       "0    0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....             1.0000   \n",
       "1    0.0024692,0.00500556,0.0,0.00245011,0.00751001...             0.3675   \n",
       "2    0.012828775,0.013636295,0.01277519,0.010479885...             0.0000   \n",
       "3    0.01061712,0.01363079,0.00968765,0.00911549,0....             0.0000   \n",
       "4    0.01105862,0.01362904,0.011008205,0.0122820249...             0.0000   \n",
       "..                                                 ...                ...   \n",
       "185  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....             1.0000   \n",
       "186  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....             1.0000   \n",
       "187  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....             1.0000   \n",
       "188  0.00130599,0.00262513,0.00138077,0.00543626,0....             0.3695   \n",
       "189  0.01259657,0.01264009,0.00247647,0.00503778,0....             0.0521   \n",
       "\n",
       "     dS_fraction_zeros  mean_dNdS   mean_dN   mean_dS  dNdS_count_below1  \\\n",
       "0               1.0000        NaN  0.000000  0.000000                  0   \n",
       "1               0.3626   0.889887  0.002494  0.002151               3508   \n",
       "2               0.0000   0.687893  0.014729  0.023736               8824   \n",
       "3               0.0000   0.459232  0.011556  0.027731               9765   \n",
       "4               0.0000   0.546812  0.011145  0.022559               9532   \n",
       "..                 ...        ...       ...       ...                ...   \n",
       "185             0.3626   0.000000  0.000000  0.001233               6374   \n",
       "186             0.3626   0.000000  0.000000  0.002465               6374   \n",
       "187             1.0000        NaN  0.000000  0.000000                  0   \n",
       "188             1.0000        NaN  0.001367  0.000000                  0   \n",
       "189             1.0000        NaN  0.007596  0.000000                  0   \n",
       "\n",
       "     dNdS_count_above1  frac_below1  frac_above1  frac_equal1       selection  \n",
       "0                10000       0.0000       1.0000          0.0        positive  \n",
       "1                 6492       0.3508       0.6492          0.0  nonsignificant  \n",
       "2                 1176       0.8824       0.1176          0.0  nonsignificant  \n",
       "3                  235       0.9765       0.0235          0.0       purifying  \n",
       "4                  468       0.9532       0.0468          0.0       purifying  \n",
       "..                 ...          ...          ...          ...             ...  \n",
       "185               3626       0.6374       0.3626          0.0  nonsignificant  \n",
       "186               3626       0.6374       0.3626          0.0  nonsignificant  \n",
       "187              10000       0.0000       1.0000          0.0        positive  \n",
       "188              10000       0.0000       1.0000          0.0        positive  \n",
       "189              10000       0.0000       1.0000          0.0        positive  \n",
       "\n",
       "[190 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## bootstrap information\n",
    "bootstrap_y = pd.read_csv(f'/home/emma/Amplicons/Workspaces/emma/downloaded_data/Y_updated_bootstrap_results_20251101_140447/bootstrap_results.csv',sep=\",\")\n",
    "bootstrap_y\n",
    "\n",
    "bootstrap = bootstrap_y\n",
    "\n",
    "def frac_zeros(val):\n",
    "    # split by comma, convert to float\n",
    "    arr = np.array([float(x) for x in val.split(\",\")])\n",
    "    return np.mean(arr == 0)\n",
    "\n",
    "# Apply to each column\n",
    "bootstrap[\"dN_fraction_zeros\"] = bootstrap[\"dN_rates\"].apply(frac_zeros)\n",
    "bootstrap[\"dS_fraction_zeros\"] = bootstrap[\"dS_rates\"].apply(frac_zeros)\n",
    "\n",
    "# calculate mean dNdS + mean dS + mean dN\n",
    "def calc_bootstrap_stats(dn_str, ds_str):\n",
    "    # Parse strings into float arrays\n",
    "    dn = np.array([float(x) for x in dn_str.split(\",\")])\n",
    "    ds = np.array([float(x) for x in ds_str.split(\",\")])\n",
    "    \n",
    "    # --- mean of ratios ---\n",
    "    ratios = np.divide(dn, ds, out=np.full_like(dn, np.nan), where=ds!=0)\n",
    "    mean_dnds = np.nanmean(ratios)\n",
    "    \n",
    "    # --- mean dN and mean dS ---\n",
    "    mean_dn = np.mean(dn)\n",
    "    mean_ds = np.mean(ds)\n",
    "    \n",
    "    return mean_dnds, mean_dn, mean_ds\n",
    "\n",
    "\n",
    "# Apply row-wise\n",
    "bootstrap[[\"mean_dNdS\", \"mean_dN\", \"mean_dS\"]] = bootstrap.apply(\n",
    "    lambda row: pd.Series(calc_bootstrap_stats(row[\"dN_rates\"], row[\"dS_rates\"])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "def count_ratio_below_above_1(dn_str, ds_str):\n",
    "    # Parse comma-separated strings into float arrays (fast & robust)\n",
    "    dn = np.fromstring(dn_str, sep=\",\")\n",
    "    ds = np.fromstring(ds_str, sep=\",\")\n",
    "\n",
    "    # dN/dS with dS==0 -> +inf (including 0/0)\n",
    "    ratios = np.divide(dn, ds, out=np.full_like(dn, np.inf), where=ds != 0)\n",
    "\n",
    "    # Counts (NaNs won’t occur with the logic above; inf > 1 evaluates True)\n",
    "    below = int(np.sum(ratios < 1))\n",
    "    above = int(np.sum(ratios > 1))  # counts +inf as above 1 automatically\n",
    "\n",
    "    return below, above\n",
    "\n",
    "# Apply row-wise\n",
    "bootstrap[[\"dNdS_count_below1\", \"dNdS_count_above1\"]] = bootstrap.apply(\n",
    "    lambda row: pd.Series(count_ratio_below_above_1(row[\"dN_rates\"], row[\"dS_rates\"])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# bootstrap\n",
    "ALPHA   = 0.05\n",
    "BOOT_N  = 10000  # total bootstraps\n",
    "\n",
    "# Fractions\n",
    "bootstrap[\"frac_below1\"] = bootstrap[\"dNdS_count_below1\"] / BOOT_N\n",
    "bootstrap[\"frac_above1\"] = bootstrap[\"dNdS_count_above1\"] / BOOT_N\n",
    "\n",
    "# (optional) if you want to track the mass exactly at 1 (and any NaNs if present)\n",
    "# This assumes no double-counting across the *_count_* columns.\n",
    "if \"dNdS_count_nan\" in bootstrap.columns:\n",
    "    bootstrap[\"frac_equal1\"] = (BOOT_N - bootstrap[\"dNdS_count_below1\"]\n",
    "                                          - bootstrap[\"dNdS_count_above1\"]\n",
    "                                          - bootstrap[\"dNdS_count_nan\"]) / BOOT_N\n",
    "else:\n",
    "    bootstrap[\"frac_equal1\"] = (BOOT_N - bootstrap[\"dNdS_count_below1\"]\n",
    "                                          - bootstrap[\"dNdS_count_above1\"]) / BOOT_N\n",
    "\n",
    "bootstrap[[\"frac_below1\",\"frac_above1\",\"frac_equal1\"]] = \\\n",
    "    bootstrap[[\"frac_below1\",\"frac_above1\",\"frac_equal1\"]].clip(lower=0, upper=1)\n",
    "\n",
    ".\n",
    "positive   = bootstrap[\"frac_below1\"] <= ALPHA\n",
    "purifying  = bootstrap[\"frac_above1\"] <= ALPHA\n",
    "neutralish = positive & purifying      # e.g., ~all mass at exactly 1\n",
    "\n",
    "bootstrap[\"selection\"] = np.select(\n",
    "    [neutralish,            positive,     purifying],\n",
    "    [\"neutral (~1)\",        \"positive\",   \"purifying\"],\n",
    "    default=\"nonsignificant\"\n",
    ")\n",
    "\n",
    "#display\n",
    "cols_to_round = [\"frac_below1\",\"frac_above1\",\"frac_equal1\"]\n",
    "bootstrap[cols_to_round] = bootstrap[cols_to_round].round(4)\n",
    "bootstrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32566ba4-94ab-43ac-9cbe-73f7ffa78102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Species1</th>\n",
       "      <th>Species2</th>\n",
       "      <th>Mean_Syn</th>\n",
       "      <th>SD_Syn</th>\n",
       "      <th>Mean_Nonsyn</th>\n",
       "      <th>SD_Nonsyn</th>\n",
       "      <th>No_of_Codon</th>\n",
       "      <th>dNdS</th>\n",
       "      <th>Species1_num_copies</th>\n",
       "      <th>Species2_num_copies</th>\n",
       "      <th>Mean_Syn_count</th>\n",
       "      <th>SD_Syn_count</th>\n",
       "      <th>Mean_Nonsyn_count</th>\n",
       "      <th>SD_Nonsyn_count</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>517</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8.2500</td>\n",
       "      <td>1.4376</td>\n",
       "      <td>19.25</td>\n",
       "      <td>1.7701</td>\n",
       "      <td>CDY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PanPan</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>517</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5.5000</td>\n",
       "      <td>1.1952</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>CDY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>517</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>1.2910</td>\n",
       "      <td>15.75</td>\n",
       "      <td>0.9574</td>\n",
       "      <td>CDY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>517</td>\n",
       "      <td>0.8153</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>27.6667</td>\n",
       "      <td>1.0018</td>\n",
       "      <td>58.50</td>\n",
       "      <td>1.9813</td>\n",
       "      <td>CDY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>517</td>\n",
       "      <td>0.8102</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>27.7250</td>\n",
       "      <td>1.1276</td>\n",
       "      <td>58.30</td>\n",
       "      <td>1.6812</td>\n",
       "      <td>CDY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>203</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>2.8868</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.6458</td>\n",
       "      <td>isoenzyme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>PonAbe_PonPyg_cluster2</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>311</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5774</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>isoenzyme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>SymSyn_cluster1</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>isoenzyme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retrovirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>SymSyn_cluster2</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TATA-box</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cluster Species1 Species2  Mean_Syn  SD_Syn  Mean_Nonsyn  \\\n",
       "0                      CDY1   PanTro   HomSap    0.0191  0.0033       0.0172   \n",
       "1                      CDY1   PanTro   PanPan    0.0127  0.0028       0.0025   \n",
       "2                      CDY1   PanTro   GorGor    0.0219  0.0030       0.0141   \n",
       "3                      CDY1   PanTro   PonPyg    0.0641  0.0023       0.0523   \n",
       "4                      CDY1   PanTro   PonAbe    0.0643  0.0026       0.0521   \n",
       "..                      ...      ...      ...       ...     ...          ...   \n",
       "185  PonAbe_PonPyg_cluster1   PonAbe   PonAbe    0.0197  0.0170       0.0091   \n",
       "186  PonAbe_PonPyg_cluster2   PonAbe   PonAbe    0.0025  0.0021       0.0000   \n",
       "187         SymSyn_cluster1   SymSyn   SymSyn    0.0000     NaN       0.0000   \n",
       "188  PonAbe_PonPyg_cluster1   PonAbe   PonAbe    0.0000     NaN       0.0000   \n",
       "189         SymSyn_cluster2   SymSyn   SymSyn    0.0000     NaN       0.0077   \n",
       "\n",
       "     SD_Nonsyn  No_of_Codon    dNdS  Species1_num_copies  Species2_num_copies  \\\n",
       "0       0.0016          517  0.9031                    4                    4   \n",
       "1       0.0008          517  0.1935                    4                    2   \n",
       "2       0.0009          517  0.6419                    4                    1   \n",
       "3       0.0018          517  0.8153                    4                   12   \n",
       "4       0.0015          517  0.8102                    4                   20   \n",
       "..         ...          ...     ...                  ...                  ...   \n",
       "185     0.0060          203  0.4625                    3                    3   \n",
       "186     0.0000          311  0.0000                    3                    3   \n",
       "187        NaN          251     NaN                    2                    2   \n",
       "188        NaN          339     NaN                    2                    2   \n",
       "189        NaN          183     inf                    2                    2   \n",
       "\n",
       "     Mean_Syn_count  SD_Syn_count  Mean_Nonsyn_count  SD_Nonsyn_count  \\\n",
       "0            8.2500        1.4376              19.25           1.7701   \n",
       "1            5.5000        1.1952               2.75           0.8864   \n",
       "2            9.5000        1.2910              15.75           0.9574   \n",
       "3           27.6667        1.0018              58.50           1.9813   \n",
       "4           27.7250        1.1276              58.30           1.6812   \n",
       "..              ...           ...                ...              ...   \n",
       "185          3.3333        2.8868               4.00           2.6458   \n",
       "186          0.6667        0.5774               0.00           0.0000   \n",
       "187          0.0000           NaN               0.00              NaN   \n",
       "188          0.0000           NaN               0.00              NaN   \n",
       "189          0.0000           NaN               3.00              NaN   \n",
       "\n",
       "         Family  \n",
       "0          CDY1  \n",
       "1          CDY1  \n",
       "2          CDY1  \n",
       "3          CDY1  \n",
       "4          CDY1  \n",
       "..          ...  \n",
       "185   isoenzyme  \n",
       "186   isoenzyme  \n",
       "187   isoenzyme  \n",
       "188  retrovirus  \n",
       "189    TATA-box  \n",
       "\n",
       "[190 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dNdS pairwise dataframe \n",
    "y_between_overview = pd.read_csv(f'/home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/all_families_dN_dS_betweenspecies.tsv',sep=\"\\t\")\n",
    "y_within_overview = pd.read_csv(f'/home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/all_families_dN_dS_withinspecies.tsv',sep=\"\\t\")\n",
    "# merge the 2 dataframes\n",
    "y_within_modified = y_within_overview.copy()\n",
    "\n",
    "y_within_modified[\"Species1_num_copies\"] = y_within_modified[\"num_copies\"]\n",
    "y_within_modified[\"Species2_num_copies\"] = y_within_modified[\"num_copies\"]\n",
    "\n",
    "y_within_modified[\"Species1\"] = y_within_modified[\"Species\"]\n",
    "y_within_modified[\"Species2\"] = y_within_modified[\"Species\"]\n",
    "\n",
    "y_within_modified = y_within_modified.drop(columns=[\"num_copies\", \"Species\"])\n",
    "\n",
    "y_between_modified = y_between_overview.drop(columns=[\"pot_syn_sites\", \"adj_dNdS\"])\n",
    "\n",
    "# Ensure same column order\n",
    "y_within_modified = y_within_modified[y_between_modified.columns]\n",
    "\n",
    "# Concatenate\n",
    "merged_overview_y = pd.concat([y_between_modified, y_within_modified], ignore_index=True)\n",
    "merged_overview_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4142f1-8c47-4394-adcc-ca541298c6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Species1</th>\n",
       "      <th>Species2</th>\n",
       "      <th>Mean_Syn</th>\n",
       "      <th>SD_Syn</th>\n",
       "      <th>Mean_Nonsyn</th>\n",
       "      <th>SD_Nonsyn</th>\n",
       "      <th>No_of_Codon</th>\n",
       "      <th>dNdS</th>\n",
       "      <th>Species1_num_copies</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_Syn_count</th>\n",
       "      <th>Mean_Nonsyn_count</th>\n",
       "      <th>SD_Nonsyn_count</th>\n",
       "      <th>Family</th>\n",
       "      <th>mean_dNdS</th>\n",
       "      <th>mean_dN</th>\n",
       "      <th>mean_dS</th>\n",
       "      <th>frac_below1</th>\n",
       "      <th>frac_above1</th>\n",
       "      <th>selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>517</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4376</td>\n",
       "      <td>19.25</td>\n",
       "      <td>1.7701</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>1.005204</td>\n",
       "      <td>0.017221</td>\n",
       "      <td>0.019046</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PanPan</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>517</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1952</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>0.239645</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>517</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2910</td>\n",
       "      <td>15.75</td>\n",
       "      <td>0.9574</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>0.717800</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>0.8558</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>517</td>\n",
       "      <td>0.8153</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0018</td>\n",
       "      <td>58.50</td>\n",
       "      <td>1.9813</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>0.839586</td>\n",
       "      <td>0.052261</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>517</td>\n",
       "      <td>0.8102</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1276</td>\n",
       "      <td>58.30</td>\n",
       "      <td>1.6812</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>0.834389</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>0.064268</td>\n",
       "      <td>0.8384</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>203</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8868</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.6458</td>\n",
       "      <td>isoenzyme</td>\n",
       "      <td>0.599171</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>PonAbe_PonPyg_cluster2</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>311</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5774</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>isoenzyme</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.6374</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>SymSyn_cluster1</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>isoenzyme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retrovirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>SymSyn_cluster2</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TATA-box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cluster Species1 Species2  Mean_Syn  SD_Syn  Mean_Nonsyn  \\\n",
       "0                      CDY1   PanTro   HomSap    0.0191  0.0033       0.0172   \n",
       "1                      CDY1   PanTro   PanPan    0.0127  0.0028       0.0025   \n",
       "2                      CDY1   PanTro   GorGor    0.0219  0.0030       0.0141   \n",
       "3                      CDY1   PanTro   PonPyg    0.0641  0.0023       0.0523   \n",
       "4                      CDY1   PanTro   PonAbe    0.0643  0.0026       0.0521   \n",
       "..                      ...      ...      ...       ...     ...          ...   \n",
       "185  PonAbe_PonPyg_cluster1   PonAbe   PonAbe    0.0197  0.0170       0.0091   \n",
       "186  PonAbe_PonPyg_cluster2   PonAbe   PonAbe    0.0025  0.0021       0.0000   \n",
       "187         SymSyn_cluster1   SymSyn   SymSyn    0.0000     NaN       0.0000   \n",
       "188  PonAbe_PonPyg_cluster1   PonAbe   PonAbe    0.0000     NaN       0.0000   \n",
       "189         SymSyn_cluster2   SymSyn   SymSyn    0.0000     NaN       0.0077   \n",
       "\n",
       "     SD_Nonsyn  No_of_Codon    dNdS  Species1_num_copies  ...  SD_Syn_count  \\\n",
       "0       0.0016          517  0.9031                    4  ...        1.4376   \n",
       "1       0.0008          517  0.1935                    4  ...        1.1952   \n",
       "2       0.0009          517  0.6419                    4  ...        1.2910   \n",
       "3       0.0018          517  0.8153                    4  ...        1.0018   \n",
       "4       0.0015          517  0.8102                    4  ...        1.1276   \n",
       "..         ...          ...     ...                  ...  ...           ...   \n",
       "185     0.0060          203  0.4625                    3  ...        2.8868   \n",
       "186     0.0000          311  0.0000                    3  ...        0.5774   \n",
       "187        NaN          251     NaN                    2  ...           NaN   \n",
       "188        NaN          339     NaN                    2  ...           NaN   \n",
       "189        NaN          183     inf                    2  ...           NaN   \n",
       "\n",
       "     Mean_Nonsyn_count  SD_Nonsyn_count      Family  mean_dNdS   mean_dN  \\\n",
       "0                19.25           1.7701        CDY1   1.005204  0.017221   \n",
       "1                 2.75           0.8864        CDY1   0.239645  0.002482   \n",
       "2                15.75           0.9574        CDY1   0.717800  0.014045   \n",
       "3                58.50           1.9813        CDY1   0.839586  0.052261   \n",
       "4                58.30           1.6812        CDY1   0.834389  0.052064   \n",
       "..                 ...              ...         ...        ...       ...   \n",
       "185               4.00           2.6458   isoenzyme   0.599171  0.009121   \n",
       "186               0.00           0.0000   isoenzyme   0.000000  0.000000   \n",
       "187               0.00              NaN   isoenzyme        NaN  0.000000   \n",
       "188               0.00              NaN  retrovirus        NaN  0.000000   \n",
       "189               3.00              NaN    TATA-box        NaN  0.007596   \n",
       "\n",
       "      mean_dS  frac_below1  frac_above1       selection  \n",
       "0    0.019046       0.5920       0.4080  nonsignificant  \n",
       "1    0.012703       0.9882       0.0118       purifying  \n",
       "2    0.021878       0.8558       0.1442  nonsignificant  \n",
       "3    0.064113       0.8326       0.1674  nonsignificant  \n",
       "4    0.064268       0.8384       0.1616  nonsignificant  \n",
       "..        ...          ...          ...             ...  \n",
       "185  0.019669       0.8713       0.1287  nonsignificant  \n",
       "186  0.002465       0.6374       0.3626  nonsignificant  \n",
       "187  0.000000       0.0000       1.0000       purifying  \n",
       "188  0.000000       0.0000       1.0000       purifying  \n",
       "189  0.000000       0.0000       1.0000        positive  \n",
       "\n",
       "[190 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left horizontal merge of merged_overview and bootstrap dataframes\n",
    "\n",
    "# 1) Keep only the columns  from bootstrap\n",
    "boot_cols = [\n",
    "    \"family\", \"cluster\", \"species1\", \"species2\",\n",
    "    \"mean_dNdS\", \"mean_dN\", \"mean_dS\",\n",
    "    \"frac_below1\", \"frac_above1\", \"selection\"\n",
    "]\n",
    "boot_sub = bootstrap[boot_cols].copy()\n",
    "\n",
    "# 2) Rename bootstrap key columns to match merged_overview\n",
    "boot_sub = boot_sub.rename(columns={\n",
    "    \"family\": \"Family\",\n",
    "    \"cluster\": \"Cluster\",\n",
    "    \"species1\": \"Species1\",\n",
    "    \"species2\": \"Species2\"\n",
    "})\n",
    "\n",
    "# 2) Clean Cluster: keep only text after \"_cluster_\"\n",
    "boot_sub[\"Cluster\"] = (\n",
    "    boot_sub[\"Cluster\"].astype(str)\n",
    "    .str.split(pat=\"_cluster_\", n=1, expand=False)\n",
    "    .str[-1]\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "def with_canonical_species(df):\n",
    "    out = df.copy()\n",
    "    s1 = out[\"Species1\"].astype(str).str.strip()\n",
    "    s2 = out[\"Species2\"].astype(str).str.strip()\n",
    "    # sort the pair case-insensitively so A–B == B–A\n",
    "    order = s1.str.lower() <= s2.str.lower()\n",
    "    out[\"_SpeciesA\"] = s1.where(order, s2)\n",
    "    out[\"_SpeciesB\"] = s2.where(order, s1)\n",
    "    return out\n",
    "\n",
    "mo = with_canonical_species(merged_overview_y)\n",
    "bs = with_canonical_species(boot_sub)\n",
    "\n",
    "bs = bs.drop_duplicates(subset=[\"Family\", \"Cluster\", \"_SpeciesA\", \"_SpeciesB\"])\n",
    "\n",
    "# Merge on Family, Cluster, and canonical species\n",
    "final_df_y = pd.merge(\n",
    "    mo,\n",
    "    bs[[\n",
    "        \"Family\", \"Cluster\", \"_SpeciesA\", \"_SpeciesB\",\n",
    "        \"mean_dNdS\", \"mean_dN\", \"mean_dS\", \"frac_below1\", \"frac_above1\", \"selection\"\n",
    "    ]],\n",
    "    how=\"left\",\n",
    "    on=[\"Family\", \"Cluster\", \"_SpeciesA\", \"_SpeciesB\"]\n",
    ")\n",
    "\n",
    "# Drop helper columns\n",
    "final_df_y = final_df_y.drop(columns=[\"_SpeciesA\", \"_SpeciesB\"])\n",
    "mask_both_zero = (final_df_y[\"mean_dN\"] == 0) & (final_df_y[\"mean_dS\"] == 0)\n",
    "final_df_y.loc[mask_both_zero, \"selection\"] = \"purifying\"\n",
    "final_df_y\n",
    "final_df_y.to_csv(f\"/home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_y_updated/Bootstrap_all_families_dN_dS_between_within_species_y_updated2.csv\", index=False)\n",
    "final_df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554488f0-1ab6-4e7b-bf06-65c9c85b0c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Species1</th>\n",
       "      <th>Species2</th>\n",
       "      <th>Mean_Syn</th>\n",
       "      <th>SD_Syn</th>\n",
       "      <th>Mean_Nonsyn</th>\n",
       "      <th>SD_Nonsyn</th>\n",
       "      <th>No_of_Codon</th>\n",
       "      <th>dNdS</th>\n",
       "      <th>Species1_num_copies</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_Syn_count</th>\n",
       "      <th>Mean_Nonsyn_count</th>\n",
       "      <th>SD_Nonsyn_count</th>\n",
       "      <th>Family</th>\n",
       "      <th>mean_dNdS</th>\n",
       "      <th>mean_dN</th>\n",
       "      <th>mean_dS</th>\n",
       "      <th>frac_below1</th>\n",
       "      <th>frac_above1</th>\n",
       "      <th>selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>517</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4376</td>\n",
       "      <td>19.25</td>\n",
       "      <td>1.7701</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>1.005204</td>\n",
       "      <td>0.017221</td>\n",
       "      <td>0.019046</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PanPan</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>517</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1952</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>0.239645</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>517</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2910</td>\n",
       "      <td>15.75</td>\n",
       "      <td>0.9574</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>0.717800</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>0.8558</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>517</td>\n",
       "      <td>0.8153</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0018</td>\n",
       "      <td>58.50</td>\n",
       "      <td>1.9813</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>0.839586</td>\n",
       "      <td>0.052261</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDY1</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>517</td>\n",
       "      <td>0.8102</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1276</td>\n",
       "      <td>58.30</td>\n",
       "      <td>1.6812</td>\n",
       "      <td>CDY1</td>\n",
       "      <td>0.834389</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>0.064268</td>\n",
       "      <td>0.8384</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>203</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8868</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.6458</td>\n",
       "      <td>isoenzyme</td>\n",
       "      <td>0.599171</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>PonAbe_PonPyg_cluster2</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>311</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5774</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>isoenzyme</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.6374</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>SymSyn_cluster1</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>isoenzyme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retrovirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>SymSyn_cluster2</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TATA-box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cluster Species1 Species2  Mean_Syn  SD_Syn  Mean_Nonsyn  \\\n",
       "0                      CDY1   PanTro   HomSap    0.0191  0.0033       0.0172   \n",
       "1                      CDY1   PanTro   PanPan    0.0127  0.0028       0.0025   \n",
       "2                      CDY1   PanTro   GorGor    0.0219  0.0030       0.0141   \n",
       "3                      CDY1   PanTro   PonPyg    0.0641  0.0023       0.0523   \n",
       "4                      CDY1   PanTro   PonAbe    0.0643  0.0026       0.0521   \n",
       "..                      ...      ...      ...       ...     ...          ...   \n",
       "185  PonAbe_PonPyg_cluster1   PonAbe   PonAbe    0.0197  0.0170       0.0091   \n",
       "186  PonAbe_PonPyg_cluster2   PonAbe   PonAbe    0.0025  0.0021       0.0000   \n",
       "187         SymSyn_cluster1   SymSyn   SymSyn    0.0000     NaN       0.0000   \n",
       "188  PonAbe_PonPyg_cluster1   PonAbe   PonAbe    0.0000     NaN       0.0000   \n",
       "189         SymSyn_cluster2   SymSyn   SymSyn    0.0000     NaN       0.0077   \n",
       "\n",
       "     SD_Nonsyn  No_of_Codon    dNdS  Species1_num_copies  ...  SD_Syn_count  \\\n",
       "0       0.0016          517  0.9031                    4  ...        1.4376   \n",
       "1       0.0008          517  0.1935                    4  ...        1.1952   \n",
       "2       0.0009          517  0.6419                    4  ...        1.2910   \n",
       "3       0.0018          517  0.8153                    4  ...        1.0018   \n",
       "4       0.0015          517  0.8102                    4  ...        1.1276   \n",
       "..         ...          ...     ...                  ...  ...           ...   \n",
       "185     0.0060          203  0.4625                    3  ...        2.8868   \n",
       "186     0.0000          311  0.0000                    3  ...        0.5774   \n",
       "187        NaN          251     NaN                    2  ...           NaN   \n",
       "188        NaN          339     NaN                    2  ...           NaN   \n",
       "189        NaN          183     inf                    2  ...           NaN   \n",
       "\n",
       "     Mean_Nonsyn_count  SD_Nonsyn_count      Family  mean_dNdS   mean_dN  \\\n",
       "0                19.25           1.7701        CDY1   1.005204  0.017221   \n",
       "1                 2.75           0.8864        CDY1   0.239645  0.002482   \n",
       "2                15.75           0.9574        CDY1   0.717800  0.014045   \n",
       "3                58.50           1.9813        CDY1   0.839586  0.052261   \n",
       "4                58.30           1.6812        CDY1   0.834389  0.052064   \n",
       "..                 ...              ...         ...        ...       ...   \n",
       "185               4.00           2.6458   isoenzyme   0.599171  0.009121   \n",
       "186               0.00           0.0000   isoenzyme   0.000000  0.000000   \n",
       "187               0.00              NaN   isoenzyme        NaN  0.000000   \n",
       "188               0.00              NaN  retrovirus        NaN  0.000000   \n",
       "189               3.00              NaN    TATA-box        NaN  0.007596   \n",
       "\n",
       "      mean_dS  frac_below1  frac_above1       selection  \n",
       "0    0.019046       0.5920       0.4080  nonsignificant  \n",
       "1    0.012703       0.9882       0.0118       purifying  \n",
       "2    0.021878       0.8558       0.1442  nonsignificant  \n",
       "3    0.064113       0.8326       0.1674  nonsignificant  \n",
       "4    0.064268       0.8384       0.1616  nonsignificant  \n",
       "..        ...          ...          ...             ...  \n",
       "185  0.019669       0.8713       0.1287  nonsignificant  \n",
       "186  0.002465       0.6374       0.3626  nonsignificant  \n",
       "187  0.000000       0.0000       1.0000       purifying  \n",
       "188  0.000000       0.0000       1.0000       purifying  \n",
       "189  0.000000       0.0000       1.0000        positive  \n",
       "\n",
       "[190 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of the within species positive selection\n",
    "dnds_total = pd.read_csv(f\"{data_dir}/sequences_y_updated/Bootstrap_all_families_dN_dS_between_within_species_y_updated2.csv\")\n",
    "dnds_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7326f-cceb-4cdb-9281-0d00693e1190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}