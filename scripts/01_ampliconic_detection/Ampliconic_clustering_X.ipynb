{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "735104dc-95a0-4f45-aeb4-716ca5da1833",
   "metadata": {},
   "source": [
    "# X chromosome ampliconic clustering updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448d251-e9d4-4f32-abd2-0ee3cae0690a",
   "metadata": {},
   "source": [
    "Goal of script: Make ampliconic clusters based on nucleotide sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85cab59-b807-454f-981d-2881c83195a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import Phylo\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import re\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c988aff-6975-465b-9d18-61710684697c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PanTro',\n",
       " 'HomSap',\n",
       " 'PanPan',\n",
       " 'GorGor',\n",
       " 'PonPyg',\n",
       " 'PonAbe',\n",
       " 'SymSyn',\n",
       " 'MacFas']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1. Define species information\n",
    "\n",
    "# Define base directories\n",
    "data_dir = \"/home/emma/Amplicons/Workspaces/emma/downloaded_data\"\n",
    "work_dir = os.path.join(data_dir, \"work_dir\", \"x_multicopy\")\n",
    "\n",
    "#Define the list of dictionaries (data) containing genome information for different species\n",
    "data = [\n",
    "    {'species':'PanTro',\n",
    "     'data': {'chr_y': \"NC_072422.2\",\n",
    "              'chr_x': \"NC_072421.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic.gff\", \n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic_chrY.gff\", \n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028858775.2.gff3\",\n",
    "              'ref':  f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/GCF_028858775.2_NHGRI_mPanTro3-v2.0_pri_genomic.fna\", \n",
    "              'rna':  f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/rna.fna\", \n",
    "              'prot': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/protein.faa\",\n",
    "              'cds': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/cds_from_genomic.fna\",\n",
    "              'gff_x': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic_chrX.gff\", \n",
    "              'fasta_x': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/PanTro_X.fasta\", \n",
    "              'gff_x_cds': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.2/genomic_chrX_cds_isoform.gff\", \n",
    " }},\n",
    "    {'species':'HomSap',\n",
    "     'data': {'chr_y': \"NC_060948.1\",\n",
    "              'chr_x': \"NC_060947.1\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/hg38.gff3\",\n",
    "              'ref': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/GCF_009914755.1_T2T-CHM13v2.0_genomic.fna\",\n",
    "              'cds': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/cds_from_genomic.fna\",\n",
    "              'prot': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/protein.faa\",\n",
    "              'gff_x': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/HomSap_X.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic_chrX_cds_isoform.gff\",\n",
    "\n",
    "              }},\n",
    "     {'species':'PanPan',\n",
    "     'data': {'chr_y': \"NC_073273.2\",\n",
    "              'chr_x': \"NC_073272.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_029289425.2.gff3\",\n",
    "              'ref': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/GCF_029289425.2_NHGRI_mPanPan1-v2.0_pri_genomic.fna\",\n",
    "              'cds': f'{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/protein.faa',\n",
    "              'gff_x': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/PanPan_X.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.2/genomic_chrX_cds_isoform.gff\",\n",
    "              }},\n",
    "      {'species':'GorGor',\n",
    "     'data': {'chr_y': \"NC_073248.2\",\n",
    "              'chr_x': \"NC_073247.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_029281585.2.gff3\",\n",
    "              'ref': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/GCF_029281585.2_NHGRI_mGorGor1-v2.0_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/protein.faa',\n",
    "              'gff_x': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/GorGor_X.fasta\",\n",
    "                            'gff_x_cds': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.2/genomic_chrX_cds_isoform.gff\",\n",
    "              }},\n",
    "    {'species':'PonPyg',\n",
    "     'data': {'chr_y': \"NC_072397.2\",\n",
    "              'chr_x': \"NC_072396.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028885625.2.gff3\",\n",
    "              'ref': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/GCF_028885625.2_NHGRI_mPonPyg2-v2.0_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/protein.faa',\n",
    "              'gff_x': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/PonPyg_X.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.2/genomic_chrX_cds_isoform.gff\",\n",
    "              }},\n",
    "    {'species':'PonAbe',\n",
    "     'data': {'chr_y': \"NC_072009.2\",\n",
    "              'chr_x': \"NC_072008.2\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028885655.2.gff3\",\n",
    "              'ref': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/GCF_028885655.2_NHGRI_mPonAbe1-v2.0_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/protein.faa',\n",
    "              'gff_x': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic_chrX.gff\",\n",
    "              'fasta_x': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/PonAbe_X.fasta\",\n",
    "              'gff_x_cds': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.2/genomic_chrX_cds_isoform.gff\",\n",
    "              }},    \n",
    "    {'species':'SymSyn',\n",
    "      'data': {'chr_y': \"NC_072448.2\",\n",
    "               'chr_x': \"NC_072447.2\",\n",
    "               'ref': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/GCF_028878055.3_NHGRI_mSymSyn1-v2.1_pri_genomic.fna',\n",
    "               'path_to_annotation_NCBI': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic.gff\",\n",
    "               'path_to_annotation_NCBI_chry': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic_chrY.gff\",\n",
    "               'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028878055.3.gff3\",\n",
    "               'cds': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/cds_from_genomic.fna',\n",
    "               'prot': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/protein.faa',\n",
    "               'gff_x': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic_chrX.gff\",\n",
    "               'fasta_x': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/SymSyn_X.fasta\",\n",
    "               'gff_x_cds': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.3/genomic_chrX_cds_isoform.gff\",\n",
    "               }},\n",
    "    {'species':'MacFas',\n",
    "      'data': {'chr_y': \"NC_132903.1\",\n",
    "               'chr_x': \"NC_088395.1\",\n",
    "               'ref': f'{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/GCF_037993035.2_T2T-MFA8v1.1_genomic.fna',\n",
    "               'path_to_annotation_NCBI': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/genomic.gff\",\n",
    "               'cds': f'{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/cds_from_genomic.fna',\n",
    "               'prot': f'{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/protein.faa',\n",
    "               'gff_x': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/genomic_chrX.gff\",\n",
    "               'fasta_x': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/MacFas_X.fasta\",\n",
    "               'gff_x_cds': f\"{data_dir}/references/MacFas/ncbi_dataset/data/GCF_037993035.2/genomic_chrX_cds_isoform.gff\",\n",
    "               }},\n",
    "]\n",
    "\n",
    "# Maps species identifiers to their common name\n",
    "species_to_sequence_spec = {\n",
    "    'PanTro': 'chimpanzee',\n",
    "    'HomSap': 'human',\n",
    "    'PanPan': 'bonobo',\n",
    "    'GorGor': 'gorilla',\n",
    "    'PonPyg': 'b-orang',\n",
    "    'PonAbe': 's-orang',\n",
    "    'SymSyn': 'siamang',\n",
    "    'MacFas': 'macaque'\n",
    "\n",
    "}\n",
    "# Extracting species names -> list of species identifiers by iterating t\n",
    "species_info = {item['species']: item['data'] for item in data}\n",
    "species_list = [d['species'] for d in data]\n",
    "species_info\n",
    "species_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fed44d-4481-4173-985a-32370a6d6324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Gene_symbol</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Class</th>\n",
       "      <th>gene_family_symbol</th>\n",
       "      <th>in_palindrome</th>\n",
       "      <th>palindrome_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>colony stimulating factor 2 receptor subunit a...</td>\n",
       "      <td>LOC746936</td>\n",
       "      <td>1771418</td>\n",
       "      <td>1838874</td>\n",
       "      <td>+</td>\n",
       "      <td>PAR</td>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>sperm protein associated with the nucleus on t...</td>\n",
       "      <td>LOC129388397</td>\n",
       "      <td>3486949</td>\n",
       "      <td>3488083</td>\n",
       "      <td>+</td>\n",
       "      <td>AMPLICONIC</td>\n",
       "      <td>SPANXA1</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>SPANX A/D member 3</td>\n",
       "      <td>LOC493983</td>\n",
       "      <td>3566190</td>\n",
       "      <td>3567169</td>\n",
       "      <td>+</td>\n",
       "      <td>AMPLICONIC</td>\n",
       "      <td>SPANXA1</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>protein kinase X-linked</td>\n",
       "      <td>PRKX</td>\n",
       "      <td>4149880</td>\n",
       "      <td>4259574</td>\n",
       "      <td>-</td>\n",
       "      <td>ANCESTRAL</td>\n",
       "      <td>TBL1X</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PanTro</td>\n",
       "      <td>atherin-like</td>\n",
       "      <td>LOC740134</td>\n",
       "      <td>4370640</td>\n",
       "      <td>4405131</td>\n",
       "      <td>-</td>\n",
       "      <td>ANCESTRAL</td>\n",
       "      <td>TBL1X</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>cancer/testis antigen 1-like</td>\n",
       "      <td>LOC102119988</td>\n",
       "      <td>160766910</td>\n",
       "      <td>160770217</td>\n",
       "      <td>+</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>LAGE3</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>histone H2A-Bbd type 2/3-like</td>\n",
       "      <td>LOC123571317</td>\n",
       "      <td>161473449</td>\n",
       "      <td>161473969</td>\n",
       "      <td>+</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>H2AB3</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>40-kDa huntingtin-associated protein</td>\n",
       "      <td>LOC135969152</td>\n",
       "      <td>161474855</td>\n",
       "      <td>161476570</td>\n",
       "      <td>+</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>F8A2</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>40-kDa huntingtin-associated protein</td>\n",
       "      <td>LOC123571316</td>\n",
       "      <td>161507913</td>\n",
       "      <td>161509975</td>\n",
       "      <td>-</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>F8A2</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>MacFas</td>\n",
       "      <td>histone H2A-Bbd type 2/3-like</td>\n",
       "      <td>LOC135969154</td>\n",
       "      <td>161510534</td>\n",
       "      <td>161512971</td>\n",
       "      <td>-</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>H2AB3</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1702 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species                                               Gene   Gene_symbol  \\\n",
       "0     PanTro  colony stimulating factor 2 receptor subunit a...     LOC746936   \n",
       "1     PanTro  sperm protein associated with the nucleus on t...  LOC129388397   \n",
       "2     PanTro                                 SPANX A/D member 3     LOC493983   \n",
       "3     PanTro                            protein kinase X-linked          PRKX   \n",
       "4     PanTro                                       atherin-like     LOC740134   \n",
       "...      ...                                                ...           ...   \n",
       "1697  MacFas                       cancer/testis antigen 1-like  LOC102119988   \n",
       "1698  MacFas                      histone H2A-Bbd type 2/3-like  LOC123571317   \n",
       "1699  MacFas               40-kDa huntingtin-associated protein  LOC135969152   \n",
       "1700  MacFas               40-kDa huntingtin-associated protein  LOC123571316   \n",
       "1701  MacFas                      histone H2A-Bbd type 2/3-like  LOC135969154   \n",
       "\n",
       "          Start        End Strand       Class gene_family_symbol  \\\n",
       "0       1771418    1838874      +         PAR             CSF2RA   \n",
       "1       3486949    3488083      +  AMPLICONIC            SPANXA1   \n",
       "2       3566190    3567169      +  AMPLICONIC            SPANXA1   \n",
       "3       4149880    4259574      -   ANCESTRAL              TBL1X   \n",
       "4       4370640    4405131      -   ANCESTRAL              TBL1X   \n",
       "...         ...        ...    ...         ...                ...   \n",
       "1697  160766910  160770217      +     Unknown              LAGE3   \n",
       "1698  161473449  161473969      +     Unknown              H2AB3   \n",
       "1699  161474855  161476570      +     Unknown               F8A2   \n",
       "1700  161507913  161509975      -     Unknown               F8A2   \n",
       "1701  161510534  161512971      -     Unknown              H2AB3   \n",
       "\n",
       "     in_palindrome palindrome_name  \n",
       "0               no             NaN  \n",
       "1               no             NaN  \n",
       "2               no             NaN  \n",
       "3               no             NaN  \n",
       "4               no             NaN  \n",
       "...            ...             ...  \n",
       "1697            no             NaN  \n",
       "1698            no             NaN  \n",
       "1699            no             NaN  \n",
       "1700            no             NaN  \n",
       "1701            no             NaN  \n",
       "\n",
       "[1702 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Load dataframes with Gene coordinates and Family information\n",
    "genes = pd.read_csv(f\"{work_dir}/protein_extracted_longest/clusters_merged/gene_details_updated_with_palindromes_coordinates.tsv\", sep='\\t')\n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ffb337-ba7d-473a-8522-105ee079da90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CSF2RA' 'SPANXA1' 'TBL1X' 'VCX2' 'TMSB15B' 'MAGEB18'\n",
      " 'uncharacterized LOC129138873' 'TCEAL8' 'H2AB3'\n",
      " 'endogenous retrovirus group K member 6 Env polyprotein-like' 'SPACA5'\n",
      " 'SSX4B' 'GAGE1' 'NUDT10' 'CENPVL2' 'MAGED1'\n",
      " 'putative uncharacterized protein FLJ39060' 'XAGE1A' 'FAM156B' 'SPIN2A'\n",
      " 'ZXDA' 'CXorf49B' 'DMRTC1B' 'FAM236C' 'PABPC1L2B' 'RPL36A-HNRNPH2'\n",
      " 'ARMCX2' 'NXF2' 'TCP11X2' 'GPRASP2' 'RAB40A' 'H2BW2' 'CT47C1' 'RHOXF2B'\n",
      " 'SMIM10L2A' 'ETDA' 'SAGE1' 'CT45A8' 'CXorf51B' 'EOLA1' 'HSFX3' 'TMEM185A'\n",
      " 'CSAG1' 'PNMA6E' 'PWWP4' 'OPN1LW' 'TEX28' 'LAGE3' 'IKBKG' 'F8A2'\n",
      " 'collagen alpha-4(IV) chain-like' 'HSFX1' 'uncharacterized LOC129053094'\n",
      " 'uncharacterized LOC129476473']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vals = genes['gene_family_symbol'].unique()\n",
    "print(unique_vals)\n",
    "len(unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a7645-e920-46d5-9454-bb7be4f05ff6",
   "metadata": {},
   "source": [
    "## Extract coding sequences per family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db4421c-1bfb-436c-a8fc-820241b7a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left out because not ampliconic (looked at these individually before and are not ampliconic when 95% identity over 80% of their coverage) : 'uncharacterized LOC129138873\n",
    "\n",
    "# notes: \n",
    "#'endogenous retrovirus group K member 6 Env polyprotein-like' is called endogenous\n",
    "#'putative uncharacterized protein FLJ39060' is called FLJ39060\n",
    "#'collagen alpha-4(IV) chain-like' is called collages\n",
    "# 'uncharacterized LOC129475109' is called LOC129475109\n",
    "# 'uncharacterized LOC115932372' is called LOC115932372\n",
    "# INTSL6 contains SAGE gene family! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3453807e-2e6d-43d7-805e-34197a50e9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify which family to focus on -> this is called back later every time\n",
    "#families=['MAGED1']\n",
    "families = ['CSF2RA', 'SPANX', 'TBL1X' ,'VCX' ,'TMSB' ,'MAGEB',\n",
    " 'TCEAL8' ,'H2A','endogenous','SPACA5',\n",
    " 'SSX' ,'GAGE' ,'NUDT10' ,'CENPVL',\n",
    " 'FLJ39060' ,'XAGE1' ,'FAM156', 'SPIN',\n",
    " 'ZXD' ,'CXorf49' ,'DMRTC1' ,'FAM236', 'PABPC', 'RPL36A', 'ARMCX' ,'NXF',\n",
    " 'TCP11X2' ,'GPRASP', 'RAB40A' ,'H2BW', 'CT47' ,'RHOXF2' ,'SMIM10' ,'ETD',\n",
    " 'INTS6L', 'CT45A', 'CXorf51', 'EOLA' ,'HSFX' ,'TMEM185A', 'CSAG', 'PNMA',\n",
    " 'PWWP4', 'OPN1LW', 'TEX28', 'LAGE3', 'IKBKG' ,'F8A1',\n",
    " 'collagen' ,'LOC129475109','LOC115932372', 'MAGED1']\n",
    "len(families)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727c577-7976-4487-919c-5c34aab2c14d",
   "metadata": {},
   "source": [
    "### Extract the coding Regions\n",
    "From each gene extract the CDS and merge all the species together in one large fasta file. <br>\n",
    "Translate the sequence at the end so that the sequences can be checked with the protein files in the references genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d448325-0cb2-4121-8cbc-aac9bccefc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing family 'MAGED1' ===\n",
      "  • PanTro: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/PanTro_MAGED1.fa\n",
      "  • HomSap: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/HomSap_MAGED1.fa\n",
      "  • PanPan: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/PanPan_MAGED1.fa\n",
      "  • GorGor: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/GorGor_MAGED1.fa\n",
      "  • PonPyg: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/PonPyg_MAGED1.fa\n",
      "  • PonAbe: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/PonAbe_MAGED1.fa\n",
      "  • SymSyn: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/SymSyn_MAGED1.fa\n",
      "  • MacFas: wrote 5/5 genes → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/MacFas_MAGED1.fa\n"
     ]
    }
   ],
   "source": [
    "# Extract the sequences\n",
    "import re\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "def parse_attributes(attr_str):\n",
    "    attrs = {}\n",
    "    for part in attr_str.strip().split(\";\"):\n",
    "        if \"=\" in part:\n",
    "            k, v = part.split(\"=\", 1)\n",
    "            attrs[k.strip().lower()] = v.strip()\n",
    "    return attrs\n",
    "\n",
    "def get_isoform(attrs):\n",
    "    \"\"\"Extract isoform identifier from attributes.\"\"\"\n",
    "    prod = attrs.get(\"product\", \"\")\n",
    "    m = re.search(r'isoform\\s+(X\\d+|\\d+|[a-z])\\b', prod, re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).upper()  \n",
    "    \n",
    "    # Fallback to transcript_id or protein_id\n",
    "    for key in (\"transcript_id\", \"protein_id\"):\n",
    "        if key in attrs:\n",
    "            return attrs[key]\n",
    "    \n",
    "    return \"NA\"\n",
    "\n",
    "def select_best_isoform(isoforms_dict, refseq_iso):\n",
    "    \"\"\"Select best isoform according to priority rules.\"\"\"\n",
    "    cands = list(isoforms_dict.keys())\n",
    "    \n",
    "    # Priority 1: RefSeq Select\n",
    "    if refseq_iso and refseq_iso in cands:\n",
    "        return refseq_iso\n",
    "    \n",
    "    # Priority 2: NA (unnamed isoform)\n",
    "    if \"NA\" in cands:\n",
    "        return \"NA\"\n",
    "    \n",
    "    # Priority 3: X1 (exact match only!)\n",
    "    if \"X1\" in cands:\n",
    "        return \"X1\"\n",
    "    \n",
    "    # Priority 4: 1 or A\n",
    "    for iso in (\"1\", \"A\"):\n",
    "        if iso in cands:\n",
    "            return iso\n",
    "    \n",
    "    # Priority 5: Lowest number or alphabetically first\n",
    "    # Separate X-prefixed numbers, plain numbers, and alphabetic\n",
    "    x_numeric = []\n",
    "    plain_numeric = []\n",
    "    alpha_isos = []\n",
    "    \n",
    "    for iso in cands:\n",
    "        # Match X followed by numbers (X4, X10, X123)\n",
    "        m_x = re.match(r'^X(\\d+)$', iso, re.IGNORECASE)\n",
    "        if m_x:\n",
    "            x_numeric.append((int(m_x.group(1)), iso))\n",
    "            continue\n",
    "        \n",
    "        # Match plain numbers (2, 3, 10)\n",
    "        m_plain = re.match(r'^(\\d+)$', iso)\n",
    "        if m_plain:\n",
    "            plain_numeric.append((int(m_plain.group(1)), iso))\n",
    "            continue\n",
    "        \n",
    "        # Everything else is alphabetic\n",
    "        alpha_isos.append(iso)\n",
    "    \n",
    "    if x_numeric:\n",
    "        x_numeric.sort()\n",
    "        return x_numeric[0][1]\n",
    "    \n",
    "    if plain_numeric:\n",
    "        plain_numeric.sort()\n",
    "        return plain_numeric[0][1]\n",
    "    \n",
    "    if alpha_isos:\n",
    "        alpha_isos.sort()\n",
    "        return alpha_isos[0]\n",
    "    \n",
    "    return sorted(cands)[0]\n",
    "\n",
    "def extract_cds(genome_fasta, gff_file, gene_name):\n",
    "    \"\"\"Extract CDS for gene, selecting best isoform.\"\"\"\n",
    "    genome = SeqIO.to_dict(SeqIO.parse(genome_fasta, \"fasta\"))\n",
    "    records = {}      # isoform → list of CDS fragments\n",
    "    attrs_map = {}    # isoform → parsed attrs\n",
    "    refseq_iso = None\n",
    "    \n",
    "    # Collect all CDS features for this gene\n",
    "    with open(gff_file) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            cols = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            if len(cols) < 9 or cols[2] != \"CDS\":\n",
    "                continue\n",
    "            \n",
    "            seqid, _, _, start, end, _, strand, frame, attr_str = cols[:9]\n",
    "            attrs = parse_attributes(attr_str)\n",
    "            \n",
    "            if attrs.get(\"gene\") != gene_name:\n",
    "                continue\n",
    "            \n",
    "            iso = get_isoform(attrs)\n",
    "            \n",
    "            # Create a tuple representing this CDS fragment\n",
    "            fragment = (seqid, int(start) - 1, int(end), int(frame), strand)\n",
    "            \n",
    "            if iso not in records:\n",
    "                records[iso] = []\n",
    "            \n",
    "            fragment_coords = (fragment[0], fragment[1], fragment[2], fragment[4])  \n",
    "            existing_coords = [(f[0], f[1], f[2], f[4]) for f in records[iso]]\n",
    "            \n",
    "            if fragment_coords not in existing_coords:\n",
    "                records[iso].append(fragment)\n",
    "            \n",
    "            attrs_map[iso] = attrs\n",
    "            \n",
    "            # Check for RefSeq Select tag\n",
    "            if \"tag\" in attrs and \"refseq select\" in attrs[\"tag\"].lower():\n",
    "                refseq_iso = iso\n",
    "    \n",
    "    if not records:\n",
    "        return {}\n",
    "    \n",
    "    # Assemble CDS sequence for each isoform\n",
    "    isoform_sequences = {}\n",
    "    for iso, frags in records.items():\n",
    "        rev = (frags[0][4] == \"-\")\n",
    "        frags.sort(key=lambda x: x[1], reverse=rev)\n",
    "        \n",
    "        pieces = []\n",
    "        first = True\n",
    "        for sid, s, e, frm, strand in frags:\n",
    "            subseq = genome[sid].seq[s:e]\n",
    "            if strand == \"-\":\n",
    "                subseq = subseq.reverse_complement()\n",
    "            if first:\n",
    "                subseq = subseq[frm:]  \n",
    "                first = False\n",
    "            pieces.append(str(subseq))\n",
    "        \n",
    "        isoform_sequences[iso] = \"\".join(pieces)\n",
    "    \n",
    "    # Select best isoform\n",
    "    best_iso = select_best_isoform(isoform_sequences, refseq_iso)\n",
    "    \n",
    "    return {best_iso: (isoform_sequences[best_iso], attrs_map[best_iso])}\n",
    "\n",
    "# ========== Main processing loop ================\n",
    "for family in families:\n",
    "    print(f\"\\n=== Processing family {family!r} ===\")\n",
    "    filtered_genes = genes[\n",
    "        genes[\"gene_family_symbol\"].str.contains(family, na=False)\n",
    "    ]\n",
    "    \n",
    "    intermediate_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform\"\n",
    "    os.makedirs(intermediate_dir, exist_ok=True)\n",
    "    \n",
    "    for species in species_list:\n",
    "        info = species_info[species]\n",
    "        genome = info[\"fasta_x\"]\n",
    "        gff_file = info[\"gff_x_cds\"]\n",
    "        out_fa = f\"{intermediate_dir}/{species}_{family}.fa\"\n",
    "        \n",
    "        with open(out_fa, \"w\") as fout:\n",
    "            sp_genes = filtered_genes[filtered_genes[\"Species\"] == species]\n",
    "            written = 0\n",
    "            \n",
    "            for gene in sp_genes[\"Gene_symbol\"]:\n",
    "                iso_dict = extract_cds(genome, gff_file, gene)\n",
    "                \n",
    "                if not iso_dict:\n",
    "                    print(f\"    [!] No CDS for {gene} in {species}\")\n",
    "                    continue\n",
    "                \n",
    "                for iso, (seq, attrs) in iso_dict.items():\n",
    "                    pid = attrs.get(\"protein_id\", \"\")\n",
    "                    header = f\">{gene}_isoform_{iso}\"\n",
    "                    if pid:\n",
    "                        header += f\";protein_id={pid}\"\n",
    "                    fout.write(header + \"\\n\" + seq + \"\\n\")\n",
    "                    written += 1\n",
    "            \n",
    "            print(f\"  • {species}: wrote {written}/{len(sp_genes)} genes → {out_fa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "193bef1d-5ae4-4351-86fe-0075eadb3372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing family 'MAGED1'\n",
      "\n",
      "→ Combined FASTA for MAGED1 at /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/all_species_MAGED1.fa\n"
     ]
    }
   ],
   "source": [
    "# combine the fasta files\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing family {family!r}\\n\")\n",
    "\n",
    "    intermediate_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform\"\n",
    "    combined_fasta   = f\"{intermediate_dir}/all_species_{family}.fa\"\n",
    "    with open(combined_fasta, \"w\") as outfile:\n",
    "        for species in species_list:\n",
    "            species_fasta = f\"{intermediate_dir}/{species}_{family}.fa\"\n",
    "            try:\n",
    "                with open(species_fasta) as infile:\n",
    "                    for line in infile:\n",
    "                        if line.startswith(\">\"):\n",
    "                            header = line.strip()\n",
    "                            if not header.endswith(f\"_{species}\"):\n",
    "                                header += f\"_{species}\"\n",
    "                            outfile.write(header + \"\\n\")\n",
    "                        else:\n",
    "                            outfile.write(line)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"[Warning] {species_fasta} not found.\")\n",
    "    print(f\"→ Combined FASTA for {family} at {combined_fasta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b542c68-7372-48b8-abd2-3aedd9b3c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/all_species_MAGED1.fa → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/all_species_MAGED1_translated.fa\n"
     ]
    }
   ],
   "source": [
    "## Translate the coding sequence to check if there are stop codons within \n",
    "def translate_record(record, frame=0):\n",
    "    \"\"\"\n",
    "    Translates a SeqRecord's nucleotide sequence into a protein sequence.\n",
    "    \n",
    "    :param record: A SeqRecord object containing the nucleotide sequence.\n",
    "    :param frame: The reading frame (0, 1, or 2) to start translation.\n",
    "    :return: A new SeqRecord with the translated protein sequence.\n",
    "    \"\"\"\n",
    "    # Adjust the sequence for the reading frame\n",
    "    trimmed_seq = record.seq[frame:]\n",
    "    # Translate into protein (keeps '*' for stop codons)\n",
    "    protein_seq = trimmed_seq.translate(to_stop=False)\n",
    "    # Create a new SeqRecord for the protein\n",
    "    return SeqRecord(protein_seq, id=record.id, description=\"translated\")\n",
    "\n",
    "def translate_fasta(input_file, output_file, frame=0):\n",
    "    \"\"\"\n",
    "    Reads a FASTA file with nucleotide sequences, translates each sequence, \n",
    "    and writes the protein sequences to an output FASTA file.\n",
    "    \n",
    "    :param input_file: Path to the input FASTA file.\n",
    "    :param output_file: Path to the output FASTA file.\n",
    "    :param frame: The reading frame (0, 1, or 2) to start translation.\n",
    "    \"\"\"\n",
    "    # Parse the input FASTA file and translate each record\n",
    "    translated_records = []\n",
    "    for record in SeqIO.parse(input_file, \"fasta\"):\n",
    "        translated_records.append(translate_record(record, frame))\n",
    "    \n",
    "    # Write translated records to the output FASTA file\n",
    "    SeqIO.write(translated_records, output_file, \"fasta\")\n",
    "\n",
    "for family in families:\n",
    "    # 1) make the per-family directory\n",
    "    intermediate_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform\"\n",
    "    os.makedirs(intermediate_dir, exist_ok=True)\n",
    "\n",
    "    # 2) build input/output paths\n",
    "    in_fasta  = f\"{intermediate_dir}/all_species_{family}.fa\"\n",
    "    out_fasta = f\"{intermediate_dir}/all_species_{family}_translated.fa\"\n",
    "\n",
    "    # 3) translate\n",
    "    print(f\"Translating {in_fasta} → {out_fasta}\")\n",
    "    translate_fasta(in_fasta, out_fasta, frame=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a77913-5f0d-49a2-8b76-87ef4c80f3aa",
   "metadata": {},
   "source": [
    "## Create Ampliconic clustering across species using BLAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8624ca3-cfde-4b91-bb12-2116b90241ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ makeblastdb for 'MAGED1'\n",
      "\n",
      "\n",
      "Building a new DB, current time: 12/15/2025 14:43:50\n",
      "New DB name:   /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/blastdb\n",
      "New DB title:  /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/all_species_MAGED1.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 40 sequences in 0.118321 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create ampliconic clusters based on Identity using BLASTN\n",
    "for family in families:\n",
    "    print(f\"▶ makeblastdb for {family!r}\")\n",
    "    cmd = f\"makeblastdb \\\n",
    "            -in {data_dir}/sequences_x_updated/{family}_selected_isoform/all_species_{family}.fa \\\n",
    "            -dbtype nucl \\\n",
    "            -out {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/blastdb\"\n",
    "    subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2122e25-998c-4ce6-b36c-247a3905f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing family: MAGED1\n"
     ]
    }
   ],
   "source": [
    "# pairwise comparison of each gene coding sequence against all other genes in the database \n",
    "for family in families:\n",
    "    print(f\"Processing family: {family}\")\n",
    "    cmd = f\"blastn -query {data_dir}/sequences_x_updated/{family}_selected_isoform/all_species_{family}.fa \\\n",
    "    -db {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/blastdb \\\n",
    "    -out {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/results.blastp.tsv \\\n",
    "    -outfmt \\\"6 qseqid sseqid pident mismatch gapopen gaps qcovs qcovshsp evalue\\\" \"\n",
    "\n",
    "    subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88aa070b-a32a-4a02-8895-203ee58e0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing family: MAGED1\n"
     ]
    }
   ],
   "source": [
    "# Process the BLAST results to build a network of relationships (edges) between proteins based on similarity thresholds for identity, coverage, and score\n",
    "# # Collect edges for each protein with species-specific thresholds\n",
    "edges = {}\n",
    "identity_default = 95\n",
    "identity_macfas = 90  # More lenient threshold for MacFas because it is already 5% sequence identity away from the other species\n",
    "coverage = 80\n",
    "score = 0.001\n",
    "\n",
    "edges_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    print(f\"Processing family: {family}\")\n",
    "    edges = {}\n",
    "    file = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/results.blastp.tsv\"\n",
    "    \n",
    "    with open(file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            cols = line.strip().split(\"\\t\")\n",
    "            \n",
    "            # Determine which identity threshold to use\n",
    "            query_id = cols[0]\n",
    "            subject_id = cols[1]\n",
    "            \n",
    "            is_macfas_comparison = \"MacFas\" in query_id or \"MacFas\" in subject_id\n",
    "            \n",
    "            # Use appropriate identity threshold\n",
    "            identity_threshold = identity_macfas if is_macfas_comparison else identity_default\n",
    "            \n",
    "            # Apply filtering with the appropriate threshold\n",
    "            if (float(cols[2]) >= identity_threshold\n",
    "                and int(cols[6]) >= coverage\n",
    "                and float(cols[7]) < score):\n",
    "                \n",
    "                if cols[0] in edges:\n",
    "                    edges[cols[0]].append(cols[1])\n",
    "                else:\n",
    "                    edges[cols[0]] = [cols[1]]\n",
    "    \n",
    "    edges_per_family[family] = edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a942ad0-82d5-495d-a0b2-af73409bf88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7587555-7cba-4faf-9920-ffc1107d6b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing family: MAGED1\n"
     ]
    }
   ],
   "source": [
    "two_way_per_family = {}\n",
    "vertices_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    print(f\"Processing family: {family}\")\n",
    "    edges     = edges_per_family[family]\n",
    "    edges_2way = []\n",
    "    vertices   = set()\n",
    "\n",
    "    for node_A in edges:\n",
    "        for node_B in edges[node_A]:\n",
    "            if node_B in edges and node_A in edges[node_B]:\n",
    "                pair = tuple(sorted((node_A, node_B)))\n",
    "                if pair in edges_2way:\n",
    "                    continue\n",
    "                edges_2way.append(pair)\n",
    "                vertices.add(node_A)\n",
    "                vertices.add(node_B)\n",
    "\n",
    "    two_way_per_family[family] = edges_2way\n",
    "    vertices_per_family[family]   = vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050f77e4-820d-441d-8ed7-c3ed01a76676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Clustering for family 'MAGED1'\n"
     ]
    }
   ],
   "source": [
    "clusters_per_family = {}\n",
    "merged_clusters_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    print(f\"→ Clustering for family {family!r}\")\n",
    "    edges_2way = two_way_per_family[family]\n",
    "\n",
    "    # 1) transitive clustering\n",
    "    clusters = []\n",
    "    for edge in edges_2way:\n",
    "        found = False\n",
    "        for cluster in clusters:\n",
    "            if edge[0] in cluster or edge[1] in cluster:\n",
    "                cluster.add(edge[0])\n",
    "                cluster.add(edge[1])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            clusters.append(set(edge))\n",
    "\n",
    "    # 2) merge overlapping clusters\n",
    "    merged_clusters = []\n",
    "    for cluster in clusters:\n",
    "        found = False\n",
    "        for m in merged_clusters:\n",
    "            if cluster & m:       # any intersection?\n",
    "                m.update(cluster)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            merged_clusters.append(cluster)\n",
    "\n",
    "    # store and/or print\n",
    "    merged_clusters_per_family[family] = merged_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2fc1cf1-35b2-40be-b6c9-0111b1cb7c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  • Saved clustering table for 'MAGED1' → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/gene_clustering_MAGED1.csv\n"
     ]
    }
   ],
   "source": [
    "# Define which sequences belong into cluster together\n",
    "# take the list of clusters, extract gene name, and species and create a dataframe with a cluster number for each gene. \n",
    "for family in families:\n",
    "    clusters = merged_clusters_per_family.get(family, [])\n",
    "    if not clusters:\n",
    "        print(f\"No clusters for family {family!r}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Build list of (gene_name, species, cluster_id)\n",
    "    rows = [\n",
    "        (\n",
    "            gene,\n",
    "            gene.rsplit('_', 1)[1],      \n",
    "            cluster_id\n",
    "        )\n",
    "        for cluster_id, cluster in enumerate(clusters, start=1)\n",
    "        for gene in cluster\n",
    "    ]\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(rows, columns=['gene_name', 'species', 'cluster'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    out_csv = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/gene_clustering_{family}.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"  • Saved clustering table for {family!r} → {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce2e383d-76e0-41cb-be51-1c0799b6f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Naming clusters for family 'MAGED1'\n",
      "  • Saved auto-named clusters → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/MAGED1_clusters_named_auto.csv\n"
     ]
    }
   ],
   "source": [
    "# give cluster names automatically based on overal recognizable cluster name \n",
    "for family in families:\n",
    "    print(f\"→ Naming clusters for family {family!r}\")\n",
    "\n",
    "    # 1) per-family clustering table\n",
    "    csv_in = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/gene_clustering_{family}.csv\"\n",
    "    df = pd.read_csv(csv_in)\n",
    "\n",
    "    # 2) Auto-name each cluster\n",
    "    cluster_name = {}\n",
    "    species_combo_counts = {}\n",
    "\n",
    "    for cid, grp in df.groupby('cluster'):\n",
    "        # prefer non-LOC genes\n",
    "        non_loc = grp[~grp['gene_name'].str.startswith('LOC')]\n",
    "        if not non_loc.empty:\n",
    "            # take the shortest prefix before first '_'\n",
    "            prefs = non_loc['gene_name'].str.partition('_')[0]\n",
    "            base = prefs.loc[prefs.str.len().idxmin()]\n",
    "        else:\n",
    "            # fallback: name by species combination\n",
    "            combo = \"_\".join(sorted(grp['species'].unique()))\n",
    "            cnt = species_combo_counts.get(combo, 0) + 1\n",
    "            species_combo_counts[combo] = cnt\n",
    "            base = f\"{combo}_cluster{cnt}\"\n",
    "\n",
    "        cluster_name[cid] = base\n",
    "\n",
    "    # 3) big clusters keep the base name\n",
    "    sizes = df.groupby('cluster').size().to_dict()\n",
    "    dups = defaultdict(list)\n",
    "    for cid, name in cluster_name.items():\n",
    "        dups[name].append(cid)\n",
    "\n",
    "    for name, cids in dups.items():\n",
    "        if len(cids) > 1:\n",
    "            # largest cluster keeps the base name\n",
    "            cids.sort(key=lambda x: sizes[x], reverse=True)\n",
    "            for idx, cid in enumerate(cids[1:], start=2):\n",
    "                cluster_name[cid] = f\"{name}_{idx}\"\n",
    "\n",
    "    # 4) Map back and save\n",
    "    df['cluster_name'] = df['cluster'].map(cluster_name)\n",
    "    out_csv = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/{family}_clusters_named_auto.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"  • Saved auto-named clusters → {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e31494-f1b8-4097-aa89-dd59edb6a54b",
   "metadata": {},
   "source": [
    "## Show the cluster counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c8affeb-c5b9-4837-867b-eed293dd6a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Building species×cluster matrix for 'MAGED1'\n",
      "  • Saved species×cluster counts → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/species_cluster_counts_MAGED1.csv\n"
     ]
    }
   ],
   "source": [
    "# Show for each species (rows) and each cluster (columns), how many genes from that species are present in that cluster\n",
    "# group the gene-level dataframe and then bivor the results so that species are rows and cluster are the columns. \n",
    "\n",
    "for family in families:\n",
    "    print(f\"\\n→ Building species×cluster matrix for {family!r}\")\n",
    "\n",
    "    # 1) load the named‐cluster table\n",
    "    in_csv = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/{family}_clusters_named_auto.csv\"\n",
    "    df = pd.read_csv(in_csv)\n",
    "\n",
    "    # 2) count genes per (species, cluster)\n",
    "    grouped = (df.groupby(['species', 'cluster_name']).size().reset_index(name='count'))\n",
    "\n",
    "    # 3) pivot \n",
    "    cluster_species_df = (grouped.pivot(index='species', columns='cluster_name', values='count').fillna(0).sort_index().sort_index(axis=1))\n",
    "\n",
    "    # 4) save\n",
    "    #print(cluster_species_df) \n",
    "    out_csv = (f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/species_cluster_counts_{family}.csv\")\n",
    "    cluster_species_df.to_csv(out_csv)\n",
    "    print(f\"  • Saved species×cluster counts → {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06084e1e-4cee-4c7c-9747-8b5ff2d3c2d7",
   "metadata": {},
   "source": [
    "## Subset the fasta file of a gene family into its clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0375ec81-02bb-4281-b92f-38c5d77a50d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing family 'MAGED1'\n",
      "  Cluster: MAGED1, Number of genes: 8\n",
      "  Cluster: MAGED2, Number of genes: 8\n",
      "  Cluster: MAGED4, Number of genes: 16\n",
      "  Cluster: TRO, Number of genes: 8\n",
      "  Loaded 40 FASTA records\n",
      "    • Wrote 8 records → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/cluster_fastas/MAGED1_cluster_MAGED1.fa\n",
      "    • Wrote 8 records → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/cluster_fastas/MAGED1_cluster_MAGED2.fa\n",
      "    • Wrote 16 records → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/cluster_fastas/MAGED1_cluster_MAGED4.fa\n",
      "    • Wrote 8 records → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/cluster_fastas/MAGED1_cluster_TRO.fa\n"
     ]
    }
   ],
   "source": [
    "for family in families:\n",
    "    print(f\"\\n→ Processing family {family!r}\")\n",
    "\n",
    "    # 1) Load the auto‐named clusters table\n",
    "    csv_in = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/{family}_clusters_named_auto.csv\"\n",
    "    df = pd.read_csv(csv_in)\n",
    "\n",
    "    # 2) Build the cluster→genes map\n",
    "    cluster_to_genes = df.groupby(\"cluster_name\")[\"gene_name\"].apply(list).to_dict()\n",
    "\n",
    "    # summary\n",
    "    for cluster, genes in cluster_to_genes.items():\n",
    "        print(f\"  Cluster: {cluster}, Number of genes: {len(genes)}\")\n",
    "\n",
    "    # 3) Load the full family FASTA \n",
    "    fasta_in = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/all_species_{family}.fa\"\n",
    "    records = list(SeqIO.parse(fasta_in, \"fasta\"))\n",
    "    record_dict = {rec.id: rec for rec in records}\n",
    "    print(f\"  Loaded {len(record_dict)} FASTA records\")\n",
    "\n",
    "    # 4) Make output dir for per‐cluster FASTAs\n",
    "    cluster_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_fastas\"\n",
    "    os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "    # 5) Write one FASTA per cluster\n",
    "    for cluster, gene_list in cluster_to_genes.items():\n",
    "        selected = [record_dict[g] for g in gene_list if g in record_dict]\n",
    "        out_fa = f\"{cluster_dir}/{family}_cluster_{cluster}.fa\"\n",
    "        SeqIO.write(selected, out_fa, \"fasta\")\n",
    "        print(f\"    • Wrote {len(selected)} records → {out_fa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbd0f6-a98d-4e9f-9b28-2af88c61c8a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94cd63c1-d929-4c23-b9d2-ff7793e9c993",
   "metadata": {},
   "source": [
    "##  Make sure the correct gene names are in the coordinate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b4e827e-0440-4b36-a0e8-00c317c4102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Updating gene details for family 'MAGED1'\n",
      "  40 rows after merge (with new ‘cluster’ col)\n",
      "  • Saved → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/MAGED1_compl_gene_details_updated_with_palindromes_coordinates.tsv\n"
     ]
    }
   ],
   "source": [
    "# 1) Read once and filter out everything with no gene_family_symbol (check)\n",
    "gene_details_file = f\"{work_dir}/protein_extracted_longest/clusters_merged/gene_details_updated_with_palindromes_coordinates.tsv\"\n",
    "\n",
    "master_df = pd.read_csv(gene_details_file, sep=\"\\t\")\n",
    "master_df = master_df.dropna(subset=[\"gene_family_symbol\"])\n",
    "\n",
    "# 2) Loop over each family\n",
    "for family in families:\n",
    "    print(f\"\\n→ Updating gene details for family {family!r}\")\n",
    "\n",
    "    # Load family's auto-named clusters\n",
    "    cluster_file = os.path.join(\n",
    "        data_dir,\n",
    "        \"sequences_x_updated\",\n",
    "        f\"{family}_selected_isoform\",\n",
    "        \"blastdb\",\n",
    "        f\"{family}_clusters_named_auto.csv\"\n",
    "    )\n",
    "    cluster_df = pd.read_csv(cluster_file, sep=\",\")\n",
    "\n",
    "    # Subset the master table to only genes in this family\n",
    "    filt = master_df[\n",
    "        master_df['gene_family_symbol'].str.contains(family, na=False)\n",
    "    ]\n",
    "\n",
    "    # Prepare the merge keys\n",
    "    cluster_df['gene_prefix'] = cluster_df['gene_name'].str.split('_').str[0]\n",
    "    mapping = cluster_df[['gene_prefix', 'species', 'cluster_name']]\n",
    "\n",
    "    # Merge on Gene_symbol + Species → gene_prefix + species\n",
    "    merged = filt.merge(\n",
    "        mapping,\n",
    "        left_on=['Gene_symbol', 'Species'],\n",
    "        right_on=['gene_prefix', 'species'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Rename and drop helper columns\n",
    "    merged.rename(columns={'cluster_name': 'cluster'}, inplace=True)\n",
    "    drop_cols = [c for c in ('gene_prefix', 'species_y') if c in merged.columns]\n",
    "    if drop_cols:\n",
    "        merged.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    print(f\"  {len(merged)} rows after merge (with new ‘cluster’ col)\")\n",
    "\n",
    "    # Write out the updated table\n",
    "    out_tsv = os.path.join(\n",
    "        data_dir,\n",
    "        \"sequences_x_updated\",\n",
    "        f\"{family}_selected_isoform\",\n",
    "        \"blastdb\",\n",
    "        f\"{family}_compl_gene_details_updated_with_palindromes_coordinates.tsv\"\n",
    "    )\n",
    "    merged.to_csv(out_tsv, sep=\"\\t\", index=False)\n",
    "    print(f\"  • Saved → {out_tsv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d033ea4d-9620-4c0d-bad2-5ca28cbe0d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Wrote combined table with cluster info for all families → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/all_families_gene_details_with_clusters2.tsv\n"
     ]
    }
   ],
   "source": [
    "## one big file with all the information\n",
    "\n",
    "# 1) Load & pre-filter your master gene_details\n",
    "gene_details_file = f\"{work_dir}/protein_extracted_longest/clusters_merged/gene_details_updated_with_palindromes_coordinates.tsv\"\n",
    "\n",
    "master_df = pd.read_csv(gene_details_file, sep=\"\\t\")\n",
    "master_df = master_df.dropna(subset=[\"gene_family_symbol\"])\n",
    "\n",
    "\n",
    "# 2) Collect all per‐family cluster maps into one DataFrame\n",
    "maps = []\n",
    "for family in families:\n",
    "    fn = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/{family}_clusters_named_auto.csv\"\n",
    "    if not os.path.exists(fn):\n",
    "        print(f\"[!] missing cluster file for {family}, skipping\")\n",
    "        continue\n",
    "\n",
    "    cf = pd.read_csv(fn)\n",
    "    # extract the gene prefix (pre‐underscore) → Gene_symbol\n",
    "    cf[\"gene_prefix\"] = cf[\"gene_name\"].str.split(\"_\").str[0]\n",
    "    # keep only the columns we need\n",
    "    maps.append(cf[[\"gene_prefix\", \"species\", \"cluster_name\"]].rename(\n",
    "        columns={\"species\": \"Species\", \"cluster_name\": \"cluster\"}\n",
    "    ))\n",
    "\n",
    "# one big mapping table\n",
    "map_df = pd.concat(maps, ignore_index=True).drop_duplicates(\n",
    "    subset=[\"gene_prefix\", \"Species\"]\n",
    ")\n",
    "\n",
    "\n",
    "# 3) Merge once onto master_df\n",
    "#    left_on Gene_symbol + Species  → right_on gene_prefix + Species\n",
    "merged_all = master_df.merge(map_df,\n",
    "    left_on=[\"Gene_symbol\", \"Species\"],\n",
    "    right_on=[\"gene_prefix\", \"Species\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# clean up helper columns\n",
    "if \"gene_prefix\" in merged_all.columns:\n",
    "    merged_all.drop(columns=[\"gene_prefix\"], inplace=True)\n",
    "\n",
    "# 4) Save overview table\n",
    "out_file = f\"{data_dir}/sequences_x_updated/all_families_gene_details_with_clusters.tsv\"\n",
    "\n",
    "merged_all.to_csv(out_file, sep=\"\\t\", index=False)\n",
    "print(f\"→ Wrote combined table with cluster info for all families → {out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726fa19-d55c-4c8f-bbe3-8721c3c5144c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40fc278a-bd72-450d-9aff-4d6897868be8",
   "metadata": {},
   "source": [
    "## MEGA analysis dN & dS calculation per cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f6745-a866-4feb-8811-219b481a2e85",
   "metadata": {},
   "source": [
    "### Define all the clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76e5b9f3-0908-4b6e-b3f9-8c578e707507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAGED1: keeping 4 clusters\n"
     ]
    }
   ],
   "source": [
    "# define all the clusters\n",
    "# this dict will hold, for each family, the list of multi-seq clusters\n",
    "cluster_list_per_family = {}\n",
    "\n",
    "for family in families:\n",
    "    # ensure the alignments directory exists\n",
    "    cluster_alignments = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "    os.makedirs(cluster_alignments, exist_ok=True)\n",
    "\n",
    "    # grab every .fa basename in the cluster_fastas dir\n",
    "    cluster_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_fastas\"\n",
    "    all_clusters = [\n",
    "        os.path.splitext(fn)[0]\n",
    "        for fn in os.listdir(cluster_dir)\n",
    "        if fn.endswith(\".fa\")\n",
    "    ]\n",
    "\n",
    "    # filter out FASTAs with only one sequence\n",
    "    filtered = []\n",
    "    for name in all_clusters:\n",
    "        path = os.path.join(cluster_dir, f\"{name}.fa\")\n",
    "        with open(path) as f:\n",
    "            nseq = sum(1 for line in f if line.startswith(\">\"))\n",
    "        if nseq > 1:\n",
    "            filtered.append(name)\n",
    "\n",
    "    # check for duplicate IDs\n",
    "    for name in filtered:\n",
    "        path = os.path.join(cluster_dir, f\"{name}.fa\")\n",
    "        seen, dups = set(), set()\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\">\"):\n",
    "                    seqid = line[1:].split()[0]\n",
    "                    if seqid in seen:\n",
    "                        dups.add(seqid)\n",
    "                    else:\n",
    "                        seen.add(seqid)\n",
    "        if dups:\n",
    "            print(f\"[{family}] {name}.fa has duplicate IDs: {', '.join(dups)}\")\n",
    "\n",
    "    # store the filtered list for later\n",
    "    cluster_list_per_family[family] = filtered\n",
    "\n",
    "    print(f\"{family}: keeping {len(filtered)} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc2730-cf2c-4e2d-93f1-0900e50de9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6166fcd6-e4d1-4920-a1ef-479c6be38e81",
   "metadata": {},
   "source": [
    "### Make a Codon based Multi-Sequence Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b78ed5d-a4c4-47c5-9ca6-141dd530feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Aligning 4 clusters for family 'MAGED1'\n",
      "→ Done family 'MAGED1'\n"
     ]
    }
   ],
   "source": [
    "### Make a codon-based alignment\n",
    "# STEP 1: Align with MACSE\n",
    "\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "    \n",
    "for family, cluster_list in cluster_list_per_family.items():\n",
    "    print(f\"\\n→ Aligning {len(cluster_list)} clusters for family {family!r}\")\n",
    "    cluster_alignments = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "\n",
    "    for cluster in cluster_list:\n",
    "        cmd = (\n",
    "            f\"macse -prog alignSequences \"\n",
    "            f\"-seq {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_fastas/{cluster}.fa \"\n",
    "            f\"-out_NT {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-out_AA {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_AA.fa\"\n",
    "        )\n",
    "        subprocess.run(cmd, shell=True, check=True,stdout=subprocess.DEVNULL,stderr=subprocess.DEVNULL)\n",
    "\n",
    "    print(f\"→ Done family {family!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb502220-f599-4759-893f-eae6126e42b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Aligning 4 clusters for family 'MAGED1'\n",
      "→ Done family 'MAGED1'\n"
     ]
    }
   ],
   "source": [
    "## refine alignment in MACSE \n",
    "# run secondly+ seperately!! takes very long to run it at the same time\n",
    "\n",
    "for family, cluster_list in cluster_list_per_family.items():\n",
    "    print(f\"\\n→ Aligning {len(cluster_list)} clusters for family {family!r}\")\n",
    "    cluster_alignments = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "\n",
    "    # # Refine made alignment: for alignments that are difficult\n",
    "    for cluster in cluster_list:\n",
    "         cmd = (\n",
    "             f\"macse -prog refineAlignment \"\n",
    "             f\"-align {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "             f\"-out_NT {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "             f\"-out_AA {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_AA.fa\"\n",
    "         )\n",
    "         subprocess.run(cmd, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # run quietly \n",
    "    \n",
    "    print(f\"→ Done family {family!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86197499-f0e3-465d-a71f-70fd7863fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Aligning 4 clusters for family 'MAGED1'\n",
      "→ Done family 'MAGED1'\n"
     ]
    }
   ],
   "source": [
    "## clean alignment in MACSE \n",
    "## to make the alignment useable for after \n",
    "\n",
    "for family, cluster_list in cluster_list_per_family.items():\n",
    "    print(f\"\\n→ Aligning {len(cluster_list)} clusters for family {family!r}\")\n",
    "    cluster_alignments = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments\"\n",
    "\n",
    "    # # clean alignments with stopcodons in the middle of the sequence (MACSE output \"!\" with frameshift/stop codons. Replace by \"NNN\" for analysis)\n",
    "    for cluster in cluster_list:\n",
    "         cmd = (\n",
    "             f\"macse -prog exportAlignment \"\n",
    "             f\"-align {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "             f\"-codonForInternalStop NNN \"\n",
    "             f\"-codonForInternalFS --- \"\n",
    "             f\"-charForRemainingFS --- \"\n",
    "             f\"-out_NT {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "             f\"-out_AA {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_AA.fa\"\n",
    "         )\n",
    "         subprocess.run(cmd, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # run quietly \n",
    "    \n",
    "    print(f\"→ Done family {family!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea14aa5-dd33-4a8d-af0d-7c5988f0fd1b",
   "metadata": {},
   "source": [
    "### Calculate dN & dS and N & S counts for each pairwise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "705d677f-72fb-4fd0-bbd2-164cdd402c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate SYNonymous substitutions rate\n",
    "# Modified Nei-Gojobori with complete deletion\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dS\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    # 2) get the list of clusters for this family\n",
    "    clusters = cluster_list_per_family[family]\n",
    "\n",
    "    # 3) run megacc for each cluster\n",
    "    for cluster in clusters:\n",
    "        cmd = (\n",
    "            f\"megacc \"\n",
    "            f\"-a {data_dir}/gene_family/sequences/MAGE_isoform_X1/blastdb/compute_ds_modNG_compldel.mao \"\n",
    "            f\"-d {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-o {ds_dir}/{cluster}\"\n",
    "        )\n",
    "        subprocess.run(cmd,shell=True, check=True,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1d8b4fd-822c-4e3c-9889-6506c23ced93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate NONsynonymous substitutions rate\n",
    "# Modified Nei-Gojobori with complete deletion\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dN\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    # 2) get the list of clusters for this family\n",
    "    clusters = cluster_list_per_family[family]\n",
    "\n",
    "    # 3) run megacc for each cluster\n",
    "    for cluster in clusters:\n",
    "        cmd = (\n",
    "            f\"megacc \"\n",
    "            f\"-a {data_dir}/gene_family/sequences/MAGE_isoform_X1/blastdb/compute_dN_modNG_compldel.mao \"\n",
    "            f\"-d {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-o {ds_dir}/{cluster}\"\n",
    "        )\n",
    "        subprocess.run(cmd,shell=True, check=True,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c8ad309-64fc-4451-bc47-f2c58666c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate SYNonymous substitution COUNTS\n",
    "#actual counts of synonymous differences\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_syn_count\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    # 2) get the list of clusters for this family\n",
    "    clusters = cluster_list_per_family[family]\n",
    "\n",
    "    # 3) run megacc for each cluster\n",
    "    for cluster in clusters:\n",
    "        cmd = (\n",
    "            f\"megacc \"\n",
    "            f\"-a {data_dir}/gene_family/sequences/MAGE_isoform_X1/blastdb/compute_syn_count_modNG_compldel.mao \"\n",
    "            f\"-d {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-o {ds_dir}/{cluster}\"\n",
    "        )\n",
    "        subprocess.run(cmd,shell=True, check=True,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "783253c8-5454-490f-a331-e633e095cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate NONSYNonymous substitution COUNTS\n",
    "#actual counts of nonsynonymous differences\n",
    "for family in families:\n",
    "    # 1) ensure the output directory exists\n",
    "    ds_dir = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_nonsyn_count\"\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    # 2) get the list of clusters for this family\n",
    "    clusters = cluster_list_per_family[family]\n",
    "\n",
    "    # 3) run megacc for each cluster\n",
    "    for cluster in clusters:\n",
    "        cmd = (\n",
    "            f\"megacc \"\n",
    "            f\"-a {data_dir}/gene_family/sequences/MAGE_isoform_X1/blastdb/compute_nonsyn_count_modNG_compldel.mao \"\n",
    "            f\"-d {data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/cluster_alignments/{cluster}_NT.fa \"\n",
    "            f\"-o {ds_dir}/{cluster}\"\n",
    "        )\n",
    "        subprocess.run(cmd,shell=True, check=True,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ea256-5455-4ed9-a7f0-d8d13bd32698",
   "metadata": {},
   "source": [
    "### Turn .meg files into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae73b078-be73-4c66-aaea-1df19c2911e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  parser \n",
    "def parse_meg_file(path: Path) -> pd.DataFrame:\n",
    "    text = path.read_text().splitlines()\n",
    "    labels = []\n",
    "    for line in text:\n",
    "        s = line.strip()\n",
    "        if re.match(r\"^\\[\\s*\\d\", s) and \"#\" not in s:\n",
    "            break\n",
    "        m = re.match(r\"^\\[\\s*(\\d+)\\]\\s*#\\s*(.+)$\", s)\n",
    "        if m:\n",
    "            labels.append(m.group(2).strip())\n",
    "    n = len(labels)\n",
    "    full = np.zeros((n, n), float)\n",
    "    for line in text:\n",
    "        s = line.strip()\n",
    "        m = re.match(r\"^\\[\\s*(\\d+)\\]\\s*(.*)$\", s)\n",
    "        if not m: continue\n",
    "        i = int(m.group(1))\n",
    "        if not (1 <= i <= n): continue\n",
    "        rest = m.group(2)\n",
    "        nums = re.findall(r\"[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?\", rest)\n",
    "        if len(nums) != i - 1: continue\n",
    "        for k, tok in enumerate(nums):\n",
    "            j = k + 1\n",
    "            v = float(tok)\n",
    "            full[i-1, j-1] = full[j-1, i-1] = v\n",
    "    np.fill_diagonal(full, 0.0)\n",
    "    df = pd.DataFrame(full, index=labels, columns=labels)\n",
    "    mask = np.tril(np.ones(df.shape, bool), k=-1)\n",
    "    return df.where(mask)\n",
    "\n",
    "# base data directory\n",
    "data_dir = Path(\"/home/emma/Amplicons/Workspaces/emma/downloaded_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c74c6ac-61dd-4ad3-8350-42ef638c8189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing dS matrices for family 'MAGED1'\n"
     ]
    }
   ],
   "source": [
    "# the per‐family loop SYNONYMOUS RATE\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing dS matrices for family {family!r}\")\n",
    "    \n",
    "    in_dir  = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dS\"\n",
    "    out_dir = in_dir / \"matrix_csvs\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for meg in sorted(in_dir.glob(\"*.meg\")):\n",
    "        df_lower = parse_meg_file(meg)\n",
    "        out_file = out_dir / f\"{meg.stem}_dS.csv\"\n",
    "        df_lower.to_csv(out_file)\n",
    "        #print(f\"   • wrote {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58f43800-20ef-42e7-8d38-78b997b96316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing dN matrices for family 'MAGED1'\n"
     ]
    }
   ],
   "source": [
    "# the per‐family loop NONSYNONYMOUS RATE\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing dN matrices for family {family!r}\")\n",
    "    \n",
    "    in_dir  = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dN\"\n",
    "    out_dir = in_dir / \"matrix_csvs\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for meg in sorted(in_dir.glob(\"*.meg\")):\n",
    "        df_lower = parse_meg_file(meg)\n",
    "        out_file = out_dir / f\"{meg.stem}_dN.csv\"\n",
    "        df_lower.to_csv(out_file)\n",
    "        #print(f\"   • wrote {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ab2c0e3-86d5-4fc4-a73c-ebc312418932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing dS matrices for family 'MAGED1'\n"
     ]
    }
   ],
   "source": [
    "#  the per‐family loop SYNONYMOUS RATE\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing dS matrices for family {family!r}\")\n",
    "    \n",
    "    in_dir  = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_syn_count\"\n",
    "    out_dir = in_dir / \"matrix_csvs\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for meg in sorted(in_dir.glob(\"*.meg\")):\n",
    "        df_lower = parse_meg_file(meg)\n",
    "        out_file = out_dir / f\"{meg.stem}_S_count.csv\"\n",
    "        df_lower.to_csv(out_file)\n",
    "        #print(f\"   • wrote {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d71e89da-aa2b-45a7-ba68-22e5bf3227e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing dS matrices for family 'MAGED1'\n"
     ]
    }
   ],
   "source": [
    "# now, the per‐family loop NONSYNONYMOUS RATE\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing dS matrices for family {family!r}\")\n",
    "    \n",
    "    in_dir  = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_nonsyn_count\"\n",
    "    out_dir = in_dir / \"matrix_csvs\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for meg in sorted(in_dir.glob(\"*.meg\")):\n",
    "        df_lower = parse_meg_file(meg)\n",
    "        out_file = out_dir / f\"{meg.stem}_N_count.csv\"\n",
    "        df_lower.to_csv(out_file)\n",
    "        #print(f\"   • wrote {out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec97d9df-2a31-4cee-a008-7d208fe4a2b8",
   "metadata": {},
   "source": [
    "### Combine all the synonymous and nonsynonymous tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5e3e2b0-fc61-421e-aae5-214811615124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to extract the number of codons -> this will be called afterwards om the big table below\n",
    "def get_num_sites(cluster):\n",
    "    \"\"\"\n",
    "    Try to pull the reported “No. of Sites=” from the .meg file.\n",
    "    If that fails, parse the alignment itself and return length/3.\n",
    "    \"\"\"\n",
    "    meg_path = (\n",
    "        data_dir\n",
    "        / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dN\"\n",
    "        / f\"{family}_cluster_{cluster}.meg\"\n",
    "    )\n",
    "    text = meg_path.read_text()\n",
    "    # 1) look for “No. of Sites = 123” with any spacing\n",
    "    m = re.search(r\"No\\.?\\s*of\\s*Sites\\s*=\\s*(\\d+)\", text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    # 2) fallback: parse the alignment and count columns\n",
    "    try:\n",
    "        aln = AlignIO.read(str(meg_path), \"mega\")\n",
    "        # alignment.get_alignment_length() gives total columns;\n",
    "        # since this is codon‐alignment file, divide by 3\n",
    "        return aln.get_alignment_length() // 3\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b3582-8f83-4888-bd43-297af1bb7ece",
   "metadata": {},
   "source": [
    "### Between species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c83d8a1b-f9b3-4950-8fb3-d6b5ebb24b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Processing between‐species stats for family MAGED1\n",
      "  Found clusters: ['MAGED1', 'MAGED2', 'MAGED4', 'TRO']\n",
      "  → saved /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/MAGED1_dN_dS_betweenspecies.tsv\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for family in families:\n",
    "    print(f\"\\n→ Processing between‐species stats for family {family}\")\n",
    "\n",
    "    # 1) define syn/nonsyn CSV directories\n",
    "    syn_dir    = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dS/matrix_csvs\"\n",
    "    nonsyn_dir = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dN/matrix_csvs\"\n",
    "\n",
    "    # 2) cluster IDs\n",
    "    clusters = []\n",
    "    for f in syn_dir.glob(f\"{family}_cluster_*_dS.csv\"):\n",
    "        m = re.match(rf\"{family}_cluster_(.+)_dS\\.csv\", f.name)\n",
    "        if m:\n",
    "            clusters.append(m.group(1))\n",
    "    clusters = sorted(set(clusters))\n",
    "    print(\"  Found clusters:\", clusters)\n",
    "\n",
    "    # helper: compute stats for a species pair in a lower‐triangle df\n",
    "    def pair_stats(df, a, b):\n",
    "        r = df.index.to_series().str.contains\n",
    "        c = df.columns.to_series().str.contains\n",
    "        mask = np.outer(r(a), c(b)) | np.outer(r(b), c(a))\n",
    "        vals = df.where(mask).stack()\n",
    "        return vals.mean(), vals.std(ddof=1)\n",
    "\n",
    "    # 3) load syn/nonsyn matrices and compute mean/SD\n",
    "    records = []\n",
    "    for cluster in clusters:\n",
    "        syn_df    = (pd.read_csv(syn_dir/f\"{family}_cluster_{cluster}_dS.csv\", index_col=0)\n",
    "                       .sort_index().sort_index(axis=1))\n",
    "        nonsyn_df = (pd.read_csv(nonsyn_dir/f\"{family}_cluster_{cluster}_dN.csv\", index_col=0)\n",
    "                       .sort_index().sort_index(axis=1))\n",
    "        for sp1, sp2 in itertools.combinations(species_list, 2):\n",
    "            m_s, sd_s = pair_stats(syn_df,    sp1, sp2)\n",
    "            m_n, sd_n = pair_stats(nonsyn_df, sp1, sp2)\n",
    "            records.append({\n",
    "                \"Cluster\":      cluster,\n",
    "                \"Species1\":     sp1,\n",
    "                \"Species2\":     sp2,\n",
    "                \"Mean_Syn\":     m_s,\n",
    "                \"SD_Syn\":       sd_s,\n",
    "                \"Mean_Nonsyn\":  m_n,\n",
    "                \"SD_Nonsyn\":    sd_n\n",
    "            })\n",
    "\n",
    "    master = pd.DataFrame(records)\n",
    "    cols = [\"Mean_Syn\",\"SD_Syn\",\"Mean_Nonsyn\",\"SD_Nonsyn\"]\n",
    "    master_clean = master.dropna(subset=cols, how=\"all\")\n",
    "\n",
    "    # 4) pull “No. of Sites” (codons) from each cluster's .meg\n",
    "    site_map = {cl: get_num_sites(cl) for cl in master_clean[\"Cluster\"].unique()}\n",
    "    master_clean[\"No_of_Codon\"] = master_clean[\"Cluster\"].map(site_map)\n",
    "\n",
    "    # 5) compute dN/dS ratio\n",
    "    master_clean[\"dNdS\"] = master_clean[\"Mean_Nonsyn\"] / master_clean[\"Mean_Syn\"]\n",
    "\n",
    "    # 6) annotate copy‐numbers\n",
    "    counts_csv = (\n",
    "        data_dir\n",
    "        / f\"sequences_x_updated/{family}_selected_isoform/blastdb/species_cluster_counts_{family}.csv\"\n",
    "    )\n",
    "    counts_df = pd.read_csv(counts_csv).set_index(\"species\")\n",
    "    master_clean[\"Species1_num_copies\"] = [\n",
    "        counts_df.at[s, c]\n",
    "        for s, c in zip(master_clean[\"Species1\"], master_clean[\"Cluster\"])\n",
    "    ]\n",
    "    master_clean[\"Species2_num_copies\"] = [\n",
    "        counts_df.at[s, c]\n",
    "        for s, c in zip(master_clean[\"Species2\"], master_clean[\"Cluster\"])\n",
    "    ]\n",
    "\n",
    "    # 7) build S/N counts table and merge\n",
    "    rec2 = []\n",
    "    syn_cnt_dir    = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_syn_count/matrix_csvs\"\n",
    "    nonsyn_cnt_dir = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_nonsyn_count/matrix_csvs\"\n",
    "    for cluster in clusters:\n",
    "        s_df = (pd.read_csv(syn_cnt_dir/f\"{family}_cluster_{cluster}_S_count.csv\", index_col=0)\n",
    "                  .sort_index().sort_index(axis=1))\n",
    "        n_df = (pd.read_csv(nonsyn_cnt_dir/f\"{family}_cluster_{cluster}_N_count.csv\", index_col=0)\n",
    "                  .sort_index().sort_index(axis=1))\n",
    "        for sp1, sp2 in itertools.combinations(species_list, 2):\n",
    "            ms, ss = pair_stats(s_df, sp1, sp2)\n",
    "            mn, sn = pair_stats(n_df, sp1, sp2)\n",
    "            rec2.append({\n",
    "                \"Cluster\":           cluster,\n",
    "                \"Species1\":          sp1,\n",
    "                \"Species2\":          sp2,\n",
    "                \"Mean_Syn_count\":    ms,\n",
    "                \"SD_Syn_count\":      ss,\n",
    "                \"Mean_Nonsyn_count\": mn,\n",
    "                \"SD_Nonsyn_count\":   sn\n",
    "            })\n",
    "\n",
    "    counts_total = (\n",
    "        pd.DataFrame(rec2)\n",
    "        .dropna(subset=[\"Mean_Syn_count\",\"SD_Syn_count\",\"Mean_Nonsyn_count\",\"SD_Nonsyn_count\"], how=\"all\")\n",
    "    )\n",
    "\n",
    "    final = (\n",
    "        master_clean\n",
    "        .merge(counts_total, on=[\"Cluster\",\"Species1\",\"Species2\"], how=\"left\")\n",
    "        .round(4)\n",
    "    )\n",
    "    final[[\"Species1_num_copies\",\"Species2_num_copies\"]] = final[[\"Species1_num_copies\",\"Species2_num_copies\"]].astype(int)\n",
    "\n",
    "    # 8) compute “potential synonymous sites” and adjusted dN/dS\n",
    "    final[\"pot_syn_sites\"] = final[\"Mean_Syn_count\"] / final[\"Mean_Syn\"]\n",
    "    final[\"adj_dNdS\"]      = (final[\"Mean_Nonsyn\"]) / (\n",
    "        (final[\"Mean_Syn_count\"] + 1) / final[\"pot_syn_sites\"]\n",
    "    )\n",
    "    \n",
    "    # 9) save\n",
    "    out_tsv = (\n",
    "        data_dir\n",
    "        / f\"sequences_x_updated/{family}_selected_isoform/blastdb/{family}_dN_dS_betweenspecies.tsv\"\n",
    "    )\n",
    "    final.to_csv(out_tsv, sep=\"\\t\", index=False)\n",
    "    print(f\"  → saved {out_tsv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a11b15-6a34-46f2-bc63-ceec140adf12",
   "metadata": {},
   "source": [
    "### Within species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b700e508-cfd5-4eb5-8250-66ef10c95891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Within‐species summary for family 'MAGED1'\n",
      "  clusters: ['MAGED1', 'MAGED2', 'MAGED4', 'TRO']\n",
      "  • saved combined within‐species table → /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/MAGED1_selected_isoform/blastdb/MAGED1_dN_dS_withinspecies.tsv\n"
     ]
    }
   ],
   "source": [
    "for family in families:\n",
    "    print(f\"\\n→ Within‐species summary for family {family!r}\")\n",
    "\n",
    "    # 1) Directories for dS and dN matrices\n",
    "    syn_dir    = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dS/matrix_csvs\"\n",
    "    nonsyn_dir = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_dN/matrix_csvs\"\n",
    "\n",
    "    # 2) cluster IDs from the dS filenames\n",
    "    clusters = sorted({\n",
    "        re.match(rf\"{family}_cluster_(.+)_dS\\.csv\", p.name).group(1)\n",
    "        for p in syn_dir.glob(f\"{family}_cluster_*_dS.csv\")\n",
    "        if re.match(rf\"{family}_cluster_(.+)_dS\\.csv\", p.name)\n",
    "    })\n",
    "    print(\"  clusters:\", clusters)\n",
    "\n",
    "    # Helper to get mean & SD for a species in a lower‐triangle matrix\n",
    "    def pair_stats(df, a, b):\n",
    "        idx0 = df.index.to_series().str.contains\n",
    "        idx1 = df.columns.to_series().str.contains\n",
    "        mask = np.outer(idx0(a), idx1(b)) | np.outer(idx0(b), idx1(a))\n",
    "        vals = df.where(mask).stack()\n",
    "        return vals.mean(), vals.std(ddof=1)\n",
    "\n",
    "    # 3) Build within‐species dS/dN rates table\n",
    "    rate_records = []\n",
    "    for cluster in clusters:\n",
    "        s_df = (pd.read_csv(syn_dir/f\"{family}_cluster_{cluster}_dS.csv\", index_col=0)\n",
    "                  .sort_index().sort_index(axis=1))\n",
    "        n_df = (pd.read_csv(nonsyn_dir/f\"{family}_cluster_{cluster}_dN.csv\", index_col=0)\n",
    "                  .sort_index().sort_index(axis=1))\n",
    "        for sp in species_list:\n",
    "            m_s, sd_s = pair_stats(s_df, sp, sp)\n",
    "            m_n, sd_n = pair_stats(n_df, sp, sp)\n",
    "            rate_records.append({\n",
    "                \"Cluster\":      cluster,\n",
    "                \"Species\":      sp,\n",
    "                \"Mean_Syn\":     m_s,\n",
    "                \"SD_Syn\":       sd_s,\n",
    "                \"Mean_Nonsyn\":  m_n,\n",
    "                \"SD_Nonsyn\":    sd_n\n",
    "            })\n",
    "    within_rates = pd.DataFrame(rate_records).dropna(\n",
    "        subset=[\"Mean_Syn\",\"SD_Syn\",\"Mean_Nonsyn\",\"SD_Nonsyn\"],\n",
    "        how=\"all\"\n",
    "    )\n",
    "\n",
    "    # 4) Extract “No. of Sites” (codons) from each cluster’s .meg\n",
    "    site_map = {c: get_num_sites(c) for c in within_rates[\"Cluster\"].unique()}\n",
    "    within_rates[\"No_of_Codon\"] = within_rates[\"Cluster\"].map(site_map)\n",
    "\n",
    "    # 5) Compute dN/dS ratio\n",
    "    within_rates[\"dNdS\"] = within_rates[\"Mean_Nonsyn\"] / within_rates[\"Mean_Syn\"]\n",
    "\n",
    "    # 6) Annotate copy‐number from species×cluster counts\n",
    "    cnt_csv = (data_dir\n",
    "               / f\"sequences_x_updated/{family}_selected_isoform/blastdb/\"\n",
    "               / f\"species_cluster_counts_{family}.csv\")\n",
    "    cnt_df = pd.read_csv(cnt_csv).set_index(\"species\")\n",
    "    within_rates[\"num_copies\"] = [\n",
    "        cnt_df.at[row.Species, row.Cluster]\n",
    "        for _, row in within_rates.iterrows()\n",
    "    ]\n",
    "\n",
    "    # 7) Build within‐species raw count table (S_count / N_count)\n",
    "    count_records = []\n",
    "    syn_cnt_dir    = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_syn_count/matrix_csvs\"\n",
    "    nonsyn_cnt_dir = data_dir / f\"sequences_x_updated/{family}_selected_isoform/blastdb/cluster_nonsyn_count/matrix_csvs\"\n",
    "    for cluster in clusters:\n",
    "        sf = syn_cnt_dir   / f\"{family}_cluster_{cluster}_S_count.csv\"\n",
    "        nf = nonsyn_cnt_dir/ f\"{family}_cluster_{cluster}_N_count.csv\"\n",
    "        if not (sf.exists() and nf.exists()):\n",
    "            print(f\"  ⚠ skipping counts for {cluster}: missing file\")\n",
    "            continue\n",
    "        s_df = pd.read_csv(sf, index_col=0).sort_index().sort_index(axis=1)\n",
    "        n_df = pd.read_csv(nf, index_col=0).sort_index().sort_index(axis=1)\n",
    "        for sp in species_list:\n",
    "            ms, ss = pair_stats(s_df, sp, sp)\n",
    "            mn, sn = pair_stats(n_df, sp, sp)\n",
    "            count_records.append({\n",
    "                \"Cluster\":           cluster,\n",
    "                \"Species\":           sp,\n",
    "                \"Mean_Syn_count\":    ms,\n",
    "                \"SD_Syn_count\":      ss,\n",
    "                \"Mean_Nonsyn_count\": mn,\n",
    "                \"SD_Nonsyn_count\":   sn\n",
    "            })\n",
    "    within_counts = pd.DataFrame(count_records).dropna(\n",
    "        subset=[\"Mean_Syn_count\",\"SD_Syn_count\",\"Mean_Nonsyn_count\",\"SD_Nonsyn_count\"],\n",
    "        how=\"all\"\n",
    "    )\n",
    "\n",
    "    # 8) Merge rates + counts into one within‐species table\n",
    "    within_species = within_rates.merge(\n",
    "        within_counts,\n",
    "        on=[\"Cluster\",\"Species\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "     # 9) Round decimals to 4 places, integers for codons & copies\n",
    "    dec_cols = [\n",
    "        \"Mean_Syn\",\"SD_Syn\",\"Mean_Nonsyn\",\"SD_Nonsyn\",\n",
    "        \"Mean_Syn_count\",\"SD_Syn_count\",\n",
    "        \"Mean_Nonsyn_count\",\"SD_Nonsyn_count\",\"dNdS\"\n",
    "    ]\n",
    "    within_species[dec_cols] = within_species[dec_cols].round(4)\n",
    "    int_cols = [\"No_of_Codon\",\"num_copies\"]\n",
    "    within_species[int_cols] = within_species[int_cols].round(0).astype(int)\n",
    "\n",
    "    # 10) Save the combined table\n",
    "    out_file = (data_dir\n",
    "                / f\"sequences_x_updated/{family}_selected_isoform/blastdb/\"\n",
    "                / f\"{family}_dN_dS_withinspecies.tsv\")\n",
    "    within_species.to_csv(out_file, sep=\"\\t\", index=False)\n",
    "    print(f\"  • saved combined within‐species table → {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb91991-34cf-4074-8e3e-e5c52446aeec",
   "metadata": {},
   "source": [
    "### Combine all tables together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7db1a6a5-fbe1-4cf8-a4a2-d27725a3dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Wrote combined table with 2491 rows to /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/all_families_dN_dS_betweenspecies.tsv\n"
     ]
    }
   ],
   "source": [
    "# BETWEEN SPECIES \n",
    "\n",
    "# 1) Read each per-family TSV, add a \"Family\" column, collect into a list\n",
    "tables = []\n",
    "for family in families:\n",
    "    path = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/{family}_dN_dS_betweenspecies.tsv\"\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    df[\"Family\"] = family\n",
    "    tables.append(df)\n",
    "\n",
    "# 2) Concatenate them all into one DataFrame\n",
    "combined = pd.concat(tables, ignore_index=True)\n",
    "\n",
    "# 3) Save the big table\n",
    "out = f\"{data_dir}/sequences_x_updated/all_families_dN_dS_betweenspecies.tsv\"\n",
    "combined.to_csv(out, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"→ Wrote combined table with {len(combined)} rows to {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17dbefcd-c0a1-4083-906f-1d02f630b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Wrote combined table with 346 rows to /home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/all_families_dN_dS_withinspecies.tsv\n"
     ]
    }
   ],
   "source": [
    "# WITHIN SPECIES \n",
    "\n",
    "# 1) Read each per-family TSV, add a \"Family\" column, collect into a list\n",
    "tables = []\n",
    "for family in families:\n",
    "    path = f\"{data_dir}/sequences_x_updated/{family}_selected_isoform/blastdb/{family}_dN_dS_withinspecies.tsv\"\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    df[\"Family\"] = family\n",
    "    tables.append(df)\n",
    "\n",
    "# 2) Concatenate all into one DataFrame\n",
    "combined = pd.concat(tables, ignore_index=True)\n",
    "\n",
    "# 3) Save the big table\n",
    "out = f\"{data_dir}/sequences_x_updated/all_families_dN_dS_withinspecies.tsv\"\n",
    "combined.to_csv(out, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"→ Wrote combined table with {len(combined)} rows to {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172b71bb-e2f3-4c08-b9ff-d306434fb39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cluster counts overview\n",
    "# DataFrame with gene coordinates and other details (adjust filename if needed)\n",
    "genes_y = pd.read_csv(f\"{data_dir}/sequences_y_updated/all_families_gene_details_with_clusters.tsv\", sep='\\t')\n",
    "genes_x = pd.read_csv(f\"{data_dir}/sequences_x_updated/all_families_gene_details_with_clusters.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04454d9c-9949-44f2-8fcc-161b401dad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dataframe into Family, cluster, species counts\n",
    "# 1) Count how many genes per Family + Cluster + Species\n",
    "counts_y = (\n",
    "    genes_y\n",
    "      .groupby(['gene_family_symbol', 'cluster', 'Species'])\n",
    "      .size()                                # number of rows in each group\n",
    "      .unstack(fill_value=0)                # turn Species into columns\n",
    "      .reset_index()                        # bring family & cluster back as cols\n",
    ")\n",
    "\n",
    "# 2) Rename for clarity\n",
    "counts_y = counts_y.rename(\n",
    "    columns={\n",
    "      'gene_family_symbol': 'Family',\n",
    "      'cluster':            'Cluster'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3) View result\n",
    "counts_y\n",
    "\n",
    "# save\n",
    "counts_y.to_csv(f\"{data_dir}/sequences_y_updated/cluster_counts_perspecies.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884e1bd2-4e75-4686-bfcb-89bc9e649e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dataframe into Family, cluster, species counts\n",
    "# 1) Count how many genes per Family + Cluster + Species\n",
    "counts_x = (\n",
    "    genes_x\n",
    "      .groupby(['gene_family_symbol', 'cluster', 'Species'])\n",
    "      .size()                                # number of rows in each group\n",
    "      .unstack(fill_value=0)                # turn Species into columns\n",
    "      .reset_index()                        # bring family & cluster back as cols\n",
    ")\n",
    "\n",
    "# 2) Rename for clarity\n",
    "counts_x = counts_x.rename(\n",
    "    columns={\n",
    "      'gene_family_symbol': 'Family',\n",
    "      'cluster':            'Cluster'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3) View result\n",
    "counts_x\n",
    "\n",
    "# save\n",
    "counts_x.to_csv(f\"{data_dir}/sequences_x_updated/cluster_counts_perspecies.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e38d73-3bff-441f-9053-b22f79895935",
   "metadata": {},
   "source": [
    "## After bootstrapping merge dNdS analysis\n",
    "#### The bootstrapping is done by is another script ! Run this first and load in the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b552645-ec24-4e87-a5f1-ca2861d3fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/10751321/ipykernel_1505586/998498019.py:31: RuntimeWarning: Mean of empty slice\n",
      "  mean_dnds = np.nanmean(ratios)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>cluster</th>\n",
       "      <th>species1</th>\n",
       "      <th>species2</th>\n",
       "      <th>dS_rates</th>\n",
       "      <th>dN_rates</th>\n",
       "      <th>dN_fraction_zeros</th>\n",
       "      <th>dS_fraction_zeros</th>\n",
       "      <th>mean_dNdS</th>\n",
       "      <th>mean_dN</th>\n",
       "      <th>mean_dS</th>\n",
       "      <th>dNdS_count_below1</th>\n",
       "      <th>dNdS_count_above1</th>\n",
       "      <th>frac_below1</th>\n",
       "      <th>frac_above1</th>\n",
       "      <th>frac_equal1</th>\n",
       "      <th>selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>CSF2RA_cluster_CSF2RA</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>0.06789973,0.0859429,0.09672656,0.05561149,0.0...</td>\n",
       "      <td>0.05008497,0.06891908,0.04930081,0.04719188,0....</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.635154</td>\n",
       "      <td>0.048339</td>\n",
       "      <td>0.077072</td>\n",
       "      <td>9972</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>CSF2RA_cluster_CSF2RA</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.13629428500000002,0.158028365,0.128367795,0....</td>\n",
       "      <td>0.07127067,0.088134195,0.07107223,0.066987915,...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.563346</td>\n",
       "      <td>0.071971</td>\n",
       "      <td>0.129173</td>\n",
       "      <td>9997</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>CSF2RA_cluster_CSF2RA</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.11960867,0.13310075,0.115627725,0.1223074500...</td>\n",
       "      <td>0.057915560000000005,0.088197885,0.073990345,0...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.542411</td>\n",
       "      <td>0.064419</td>\n",
       "      <td>0.120351</td>\n",
       "      <td>9998</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>CSF2RA_cluster_CSF2RA</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>0.08044856,0.10019249,0.07548101,0.05920863,0....</td>\n",
       "      <td>0.06653347,0.07508073,0.0556802,0.04812574,0.0...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.829041</td>\n",
       "      <td>0.058825</td>\n",
       "      <td>0.072319</td>\n",
       "      <td>8588</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>CSF2RA_cluster_CSF2RA</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>0.07221813,0.08220816,0.09219331,0.0698385,0.0...</td>\n",
       "      <td>0.05557215,0.07637806,0.05984733,0.04736746,0....</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.703722</td>\n",
       "      <td>0.052492</td>\n",
       "      <td>0.076298</td>\n",
       "      <td>9596</td>\n",
       "      <td>403</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>purifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>LOC115932372</td>\n",
       "      <td>LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.02452316,0.03256446,0.026763290000000002,0.0...</td>\n",
       "      <td>0.01409774,0.01376728,0.008444625,0.01405547,0...</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.463549</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>0.035674</td>\n",
       "      <td>9106</td>\n",
       "      <td>894</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>LOC115932372</td>\n",
       "      <td>LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>0.02452316,0.03254679,0.026751595,0.03143007,0...</td>\n",
       "      <td>0.018327065,0.01101625,0.0070389499999999995,0...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.463048</td>\n",
       "      <td>0.012576</td>\n",
       "      <td>0.035665</td>\n",
       "      <td>9110</td>\n",
       "      <td>890</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>LOC115932372</td>\n",
       "      <td>LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.032520325,0.057142874999999996,0.07219039499...</td>\n",
       "      <td>0.03107345,0.03576291,0.031037844999999998,0.0...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.699719</td>\n",
       "      <td>0.029644</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>8436</td>\n",
       "      <td>1564</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>LOC115932372</td>\n",
       "      <td>LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.032520325,0.05711178,0.07215189999999999,0.1...</td>\n",
       "      <td>0.035310735,0.03301844,0.029633109999999997,0....</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.699599</td>\n",
       "      <td>0.029626</td>\n",
       "      <td>0.051601</td>\n",
       "      <td>8421</td>\n",
       "      <td>1579</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>LOC115932372</td>\n",
       "      <td>LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.04065041,0.05711178,0.06870229,0.13366531,0....</td>\n",
       "      <td>0.03389831,0.03301844,0.03380282,0.03372523,0....</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.541135</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.071726</td>\n",
       "      <td>9302</td>\n",
       "      <td>698</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nonsignificant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2717 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            family                                            cluster  \\\n",
       "0           CSF2RA                              CSF2RA_cluster_CSF2RA   \n",
       "1           CSF2RA                              CSF2RA_cluster_CSF2RA   \n",
       "2           CSF2RA                              CSF2RA_cluster_CSF2RA   \n",
       "3           CSF2RA                              CSF2RA_cluster_CSF2RA   \n",
       "4           CSF2RA                              CSF2RA_cluster_CSF2RA   \n",
       "...            ...                                                ...   \n",
       "2712  LOC115932372  LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...   \n",
       "2713  LOC115932372  LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...   \n",
       "2714  LOC115932372  LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...   \n",
       "2715  LOC115932372  LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...   \n",
       "2716  LOC115932372  LOC115932372_cluster_GorGor_PonAbe_PonPyg_SymS...   \n",
       "\n",
       "     species1 species2                                           dS_rates  \\\n",
       "0      HomSap   PanTro  0.06789973,0.0859429,0.09672656,0.05561149,0.0...   \n",
       "1      PanTro   SymSyn  0.13629428500000002,0.158028365,0.128367795,0....   \n",
       "2      HomSap   SymSyn  0.11960867,0.13310075,0.115627725,0.1223074500...   \n",
       "3      GorGor   PanTro  0.08044856,0.10019249,0.07548101,0.05920863,0....   \n",
       "4      GorGor   HomSap  0.07221813,0.08220816,0.09219331,0.0698385,0.0...   \n",
       "...       ...      ...                                                ...   \n",
       "2712   GorGor   PonAbe  0.02452316,0.03256446,0.026763290000000002,0.0...   \n",
       "2713   GorGor   PonPyg  0.02452316,0.03254679,0.026751595,0.03143007,0...   \n",
       "2714   PonAbe   SymSyn  0.032520325,0.057142874999999996,0.07219039499...   \n",
       "2715   PonPyg   SymSyn  0.032520325,0.05711178,0.07215189999999999,0.1...   \n",
       "2716   GorGor   SymSyn  0.04065041,0.05711178,0.06870229,0.13366531,0....   \n",
       "\n",
       "                                               dN_rates  dN_fraction_zeros  \\\n",
       "0     0.05008497,0.06891908,0.04930081,0.04719188,0....             0.0000   \n",
       "1     0.07127067,0.088134195,0.07107223,0.066987915,...             0.0000   \n",
       "2     0.057915560000000005,0.088197885,0.073990345,0...             0.0000   \n",
       "3     0.06653347,0.07508073,0.0556802,0.04812574,0.0...             0.0000   \n",
       "4     0.05557215,0.07637806,0.05984733,0.04736746,0....             0.0000   \n",
       "...                                                 ...                ...   \n",
       "2712  0.01409774,0.01376728,0.008444625,0.01405547,0...             0.0209   \n",
       "2713  0.018327065,0.01101625,0.0070389499999999995,0...             0.0200   \n",
       "2714  0.03107345,0.03576291,0.031037844999999998,0.0...             0.0001   \n",
       "2715  0.035310735,0.03301844,0.029633109999999997,0....             0.0000   \n",
       "2716  0.03389831,0.03301844,0.03380282,0.03372523,0....             0.0000   \n",
       "\n",
       "      dS_fraction_zeros  mean_dNdS   mean_dN   mean_dS  dNdS_count_below1  \\\n",
       "0                0.0000   0.635154  0.048339  0.077072               9972   \n",
       "1                0.0000   0.563346  0.071971  0.129173               9997   \n",
       "2                0.0000   0.542411  0.064419  0.120351               9998   \n",
       "3                0.0000   0.829041  0.058825  0.072319               8588   \n",
       "4                0.0000   0.703722  0.052492  0.076298               9596   \n",
       "...                 ...        ...       ...       ...                ...   \n",
       "2712             0.0072   0.463549  0.012596  0.035674               9106   \n",
       "2713             0.0072   0.463048  0.012576  0.035665               9110   \n",
       "2714             0.0009   0.699719  0.029644  0.051616               8436   \n",
       "2715             0.0009   0.699599  0.029626  0.051601               8421   \n",
       "2716             0.0001   0.541135  0.033825  0.071726               9302   \n",
       "\n",
       "      dNdS_count_above1  frac_below1  frac_above1  frac_equal1       selection  \n",
       "0                    28       0.9972       0.0028       0.0000       purifying  \n",
       "1                     3       0.9997       0.0003       0.0000       purifying  \n",
       "2                     2       0.9998       0.0002       0.0000       purifying  \n",
       "3                  1412       0.8588       0.1412       0.0000  nonsignificant  \n",
       "4                   403       0.9596       0.0403       0.0001       purifying  \n",
       "...                 ...          ...          ...          ...             ...  \n",
       "2712                894       0.9106       0.0894       0.0000  nonsignificant  \n",
       "2713                890       0.9110       0.0890       0.0000  nonsignificant  \n",
       "2714               1564       0.8436       0.1564       0.0000  nonsignificant  \n",
       "2715               1579       0.8421       0.1579       0.0000  nonsignificant  \n",
       "2716                698       0.9302       0.0698       0.0000  nonsignificant  \n",
       "\n",
       "[2717 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## bootstrap information\n",
    "bootstrap_y = pd.read_csv(f'/home/emma/Amplicons/Workspaces/emma/downloaded_data/X_updated_bootstrap_results_20251101_140844/bootstrap_results.csv',sep=\",\")\n",
    "bootstrap_y\n",
    "\n",
    "bootstrap = bootstrap_y\n",
    "# add new columns that state the amount of times you have \"0\" in the bootstrapped list\n",
    "\n",
    "def frac_zeros(val):\n",
    "    # split by comma, convert to float\n",
    "    arr = np.array([float(x) for x in val.split(\",\")])\n",
    "    return np.mean(arr == 0)\n",
    "\n",
    "# Apply to each column\n",
    "bootstrap[\"dN_fraction_zeros\"] = bootstrap[\"dN_rates\"].apply(frac_zeros)\n",
    "bootstrap[\"dS_fraction_zeros\"] = bootstrap[\"dS_rates\"].apply(frac_zeros)\n",
    "\n",
    "# calculate mean dNdS + mean dS + mean dN\n",
    "def calc_bootstrap_stats(dn_str, ds_str):\n",
    "    # Parse strings into float arrays\n",
    "    dn = np.array([float(x) for x in dn_str.split(\",\")])\n",
    "    ds = np.array([float(x) for x in ds_str.split(\",\")])\n",
    "    \n",
    "    # --- mean of ratios ---\n",
    "    ratios = np.divide(dn, ds, out=np.full_like(dn, np.nan), where=ds!=0)\n",
    "    mean_dnds = np.nanmean(ratios)\n",
    "    \n",
    "    # --- mean dN and mean dS ---\n",
    "    mean_dn = np.mean(dn)\n",
    "    mean_ds = np.mean(ds)\n",
    "    \n",
    "    return mean_dnds, mean_dn, mean_ds\n",
    "\n",
    "\n",
    "# Apply row-wise\n",
    "bootstrap[[\"mean_dNdS\", \"mean_dN\", \"mean_dS\"]] = bootstrap.apply(\n",
    "    lambda row: pd.Series(calc_bootstrap_stats(row[\"dN_rates\"], row[\"dS_rates\"])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "def count_ratio_below_above_1(dn_str, ds_str):\n",
    "    dn = np.fromstring(dn_str, sep=\",\")\n",
    "    ds = np.fromstring(ds_str, sep=\",\")\n",
    "\n",
    "    ratios = np.divide(dn, ds, out=np.full_like(dn, np.inf), where=ds != 0)\n",
    "\n",
    "    below = int(np.sum(ratios < 1))\n",
    "    above = int(np.sum(ratios > 1))  \n",
    "\n",
    "    return below, above\n",
    "\n",
    "# Apply row-wise\n",
    "bootstrap[[\"dNdS_count_below1\", \"dNdS_count_above1\"]] = bootstrap.apply(\n",
    "    lambda row: pd.Series(count_ratio_below_above_1(row[\"dN_rates\"], row[\"dS_rates\"])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# bootstrap\n",
    "ALPHA   = 0.05\n",
    "BOOT_N  = 10000  # total bootstraps\n",
    "\n",
    "# Fractions\n",
    "bootstrap[\"frac_below1\"] = bootstrap[\"dNdS_count_below1\"] / BOOT_N\n",
    "bootstrap[\"frac_above1\"] = bootstrap[\"dNdS_count_above1\"] / BOOT_N\n",
    "\n",
    "if \"dNdS_count_nan\" in bootstrap.columns:\n",
    "    bootstrap[\"frac_equal1\"] = (BOOT_N - bootstrap[\"dNdS_count_below1\"]\n",
    "                                          - bootstrap[\"dNdS_count_above1\"]\n",
    "                                          - bootstrap[\"dNdS_count_nan\"]) / BOOT_N\n",
    "else:\n",
    "    bootstrap[\"frac_equal1\"] = (BOOT_N - bootstrap[\"dNdS_count_below1\"]\n",
    "                                          - bootstrap[\"dNdS_count_above1\"]) / BOOT_N\n",
    "\n",
    "bootstrap[[\"frac_below1\",\"frac_above1\",\"frac_equal1\"]] = \\\n",
    "    bootstrap[[\"frac_below1\",\"frac_above1\",\"frac_equal1\"]].clip(lower=0, upper=1)\n",
    "\n",
    "positive   = bootstrap[\"frac_below1\"] <= ALPHA\n",
    "purifying  = bootstrap[\"frac_above1\"] <= ALPHA\n",
    "neutralish = positive & purifying      # e.g., ~all mass at exactly 1\n",
    "\n",
    "bootstrap[\"selection\"] = np.select(\n",
    "    [neutralish,            positive,     purifying],\n",
    "    [\"neutral (~1)\",        \"positive\",   \"purifying\"],\n",
    "    default=\"nonsignificant\"\n",
    ")\n",
    "\n",
    "# display\n",
    "cols_to_round = [\"frac_below1\",\"frac_above1\",\"frac_equal1\"]\n",
    "bootstrap[cols_to_round] = bootstrap[cols_to_round].round(4)\n",
    "bootstrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8acac3c8-11be-46a0-98af-9adbd35c5259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Species1</th>\n",
       "      <th>Species2</th>\n",
       "      <th>Mean_Syn</th>\n",
       "      <th>SD_Syn</th>\n",
       "      <th>Mean_Nonsyn</th>\n",
       "      <th>SD_Nonsyn</th>\n",
       "      <th>No_of_Codon</th>\n",
       "      <th>dNdS</th>\n",
       "      <th>Species1_num_copies</th>\n",
       "      <th>Species2_num_copies</th>\n",
       "      <th>Mean_Syn_count</th>\n",
       "      <th>SD_Syn_count</th>\n",
       "      <th>Mean_Nonsyn_count</th>\n",
       "      <th>SD_Nonsyn_count</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.5833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.4167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSF2RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>PanPan</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393</td>\n",
       "      <td>1.0252</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSF2RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>GorGor</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.8333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.1667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSF2RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>SymSyn</td>\n",
       "      <td>0.1293</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>393</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44.3333</td>\n",
       "      <td>4.9497</td>\n",
       "      <td>60.1667</td>\n",
       "      <td>2.8284</td>\n",
       "      <td>CSF2RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSF2RA</td>\n",
       "      <td>PanTro</td>\n",
       "      <td>MacFas</td>\n",
       "      <td>0.2304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSF2RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>MacFas_PonAbe_PonPyg_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F8A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>HomSap_cluster1</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>HomSap</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>436</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5774</td>\n",
       "      <td>collagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>PanPan_cluster1</td>\n",
       "      <td>PanPan</td>\n",
       "      <td>PanPan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOC129475109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>GorGor_PonAbe_PonPyg_SymSyn_cluster1</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>PonPyg</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOC115932372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>GorGor_PonAbe_PonPyg_SymSyn_cluster1</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>PonAbe</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160</td>\n",
       "      <td>0.3544</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOC115932372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2717 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Cluster Species1 Species2  Mean_Syn  \\\n",
       "0                                   CSF2RA   PanTro   HomSap    0.0773   \n",
       "1                                   CSF2RA   PanTro   PanPan    0.0467   \n",
       "2                                   CSF2RA   PanTro   GorGor    0.0724   \n",
       "3                                   CSF2RA   PanTro   SymSyn    0.1293   \n",
       "4                                   CSF2RA   PanTro   MacFas    0.2304   \n",
       "...                                    ...      ...      ...       ...   \n",
       "2712         MacFas_PonAbe_PonPyg_cluster1   PonAbe   PonAbe    0.0000   \n",
       "2713                       HomSap_cluster1   HomSap   HomSap    0.0000   \n",
       "2714                       PanPan_cluster1   PanPan   PanPan    0.0000   \n",
       "2715  GorGor_PonAbe_PonPyg_SymSyn_cluster1   PonPyg   PonPyg    0.0080   \n",
       "2716  GorGor_PonAbe_PonPyg_SymSyn_cluster1   PonAbe   PonAbe    0.0080   \n",
       "\n",
       "      SD_Syn  Mean_Nonsyn  SD_Nonsyn  No_of_Codon    dNdS  \\\n",
       "0        NaN       0.0484        NaN          393  0.6258   \n",
       "1        NaN       0.0478        NaN          393  1.0252   \n",
       "2        NaN       0.0588        NaN          393  0.8119   \n",
       "3     0.0141       0.0720     0.0035          393  0.5565   \n",
       "4        NaN       0.0969        NaN          393  0.4205   \n",
       "...      ...          ...        ...          ...     ...   \n",
       "2712     NaN       0.0000        NaN          481     NaN   \n",
       "2713  0.0000       0.0007     0.0006          436     inf   \n",
       "2714     NaN       0.0086        NaN          217     inf   \n",
       "2715     NaN       0.0028        NaN          160  0.3547   \n",
       "2716     NaN       0.0028        NaN          160  0.3544   \n",
       "\n",
       "      Species1_num_copies  Species2_num_copies  Mean_Syn_count  SD_Syn_count  \\\n",
       "0                       1                    1         26.5833           NaN   \n",
       "1                       1                    1         16.0000           NaN   \n",
       "2                       1                    1         24.8333           NaN   \n",
       "3                       1                    2         44.3333        4.9497   \n",
       "4                       1                    1         79.0000           NaN   \n",
       "...                   ...                  ...             ...           ...   \n",
       "2712                    2                    2          0.0000           NaN   \n",
       "2713                    3                    3          0.0000        0.0000   \n",
       "2714                    2                    2          0.0000           NaN   \n",
       "2715                    2                    2          1.0000           NaN   \n",
       "2716                    2                    2          1.0000           NaN   \n",
       "\n",
       "      Mean_Nonsyn_count  SD_Nonsyn_count        Family  \n",
       "0               40.4167              NaN        CSF2RA  \n",
       "1               40.0000              NaN        CSF2RA  \n",
       "2               49.1667              NaN        CSF2RA  \n",
       "3               60.1667           2.8284        CSF2RA  \n",
       "4               81.0000              NaN        CSF2RA  \n",
       "...                 ...              ...           ...  \n",
       "2712             0.0000              NaN          F8A1  \n",
       "2713             0.6667           0.5774      collagen  \n",
       "2714             4.0000              NaN  LOC129475109  \n",
       "2715             1.0000              NaN  LOC115932372  \n",
       "2716             1.0000              NaN  LOC115932372  \n",
       "\n",
       "[2717 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dNdS pairwise dataframe \n",
    "y_between_overview = pd.read_csv(f'/home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/all_families_dN_dS_betweenspecies.tsv',sep=\"\\t\")\n",
    "y_within_overview = pd.read_csv(f'/home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/all_families_dN_dS_withinspecies.tsv',sep=\"\\t\")\n",
    "# merge the 2 dataframes\n",
    "y_within_modified = y_within_overview.copy()\n",
    "\n",
    "y_within_modified[\"Species1_num_copies\"] = y_within_modified[\"num_copies\"]\n",
    "y_within_modified[\"Species2_num_copies\"] = y_within_modified[\"num_copies\"]\n",
    "\n",
    "y_within_modified[\"Species1\"] = y_within_modified[\"Species\"]\n",
    "y_within_modified[\"Species2\"] = y_within_modified[\"Species\"]\n",
    "\n",
    "y_within_modified = y_within_modified.drop(columns=[\"num_copies\", \"Species\"])\n",
    "\n",
    "y_between_modified = y_between_overview.drop(columns=[\"pot_syn_sites\", \"adj_dNdS\"])\n",
    "\n",
    "# Align and merge \n",
    "y_within_modified = y_within_modified[y_between_modified.columns]\n",
    "\n",
    "# Concatenate\n",
    "merged_overview_y = pd.concat([y_between_modified, y_within_modified], ignore_index=True)\n",
    "merged_overview_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ba1be3-96c5-484e-a06a-87a37835d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns you need from bootstrap\n",
    "boot_cols = [\n",
    "    \"family\", \"cluster\", \"species1\", \"species2\",\n",
    "    \"mean_dNdS\", \"mean_dN\", \"mean_dS\",\n",
    "    \"frac_below1\", \"frac_above1\", \"selection\"\n",
    "]\n",
    "boot_sub = bootstrap[boot_cols].copy()\n",
    "\n",
    "boot_sub = boot_sub.rename(columns={\n",
    "    \"family\": \"Family\",\n",
    "    \"cluster\": \"Cluster\",\n",
    "    \"species1\": \"Species1\",\n",
    "    \"species2\": \"Species2\"\n",
    "})\n",
    "\n",
    "# Clean Cluster\n",
    "boot_sub[\"Cluster\"] = (\n",
    "    boot_sub[\"Cluster\"].astype(str)\n",
    "    .str.split(pat=\"_cluster_\", n=1, expand=False)\n",
    "    .str[-1]\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "def with_canonical_species(df):\n",
    "    out = df.copy()\n",
    "    s1 = out[\"Species1\"].astype(str).str.strip()\n",
    "    s2 = out[\"Species2\"].astype(str).str.strip()\n",
    "    # sort the pair case-insensitively so A–B == B–A\n",
    "    order = s1.str.lower() <= s2.str.lower()\n",
    "    out[\"_SpeciesA\"] = s1.where(order, s2)\n",
    "    out[\"_SpeciesB\"] = s2.where(order, s1)\n",
    "    return out\n",
    "\n",
    "mo = with_canonical_species(merged_overview_y)\n",
    "bs = with_canonical_species(boot_sub)\n",
    "\n",
    "bs = bs.drop_duplicates(subset=[\"Family\", \"Cluster\", \"_SpeciesA\", \"_SpeciesB\"])\n",
    "\n",
    "final_df_y = pd.merge(\n",
    "    mo,\n",
    "    bs[[\n",
    "        \"Family\", \"Cluster\", \"_SpeciesA\", \"_SpeciesB\",\n",
    "        \"mean_dNdS\", \"mean_dN\", \"mean_dS\", \"frac_below1\", \"frac_above1\", \"selection\"\n",
    "    ]],\n",
    "    how=\"left\",\n",
    "    on=[\"Family\", \"Cluster\", \"_SpeciesA\", \"_SpeciesB\"]\n",
    ")\n",
    "\n",
    "final_df_y = final_df_y.drop(columns=[\"_SpeciesA\", \"_SpeciesB\"])\n",
    "mask_both_zero = (final_df_y[\"mean_dN\"] == 0) & (final_df_y[\"mean_dS\"] == 0)\n",
    "final_df_y.loc[mask_both_zero, \"selection\"] = \"purifying\"\n",
    "final_df_y\n",
    "final_df_y.to_csv(f\"/home/emma/Amplicons/Workspaces/emma/downloaded_data/sequences_x_updated/Bootstrap_all_families_dN_dS_between_within_species_x_updated2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b957b1-79a2-4bf3-8755-d534a6c41cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
